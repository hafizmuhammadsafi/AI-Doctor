{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URvB-671Uyxy"
      },
      "source": [
        "# **Step 1.** Install Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzDyBvmVnYZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e8060dc-2e5d-4c54-ef37-c67e783788c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting xformers\n",
            "  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from xformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->xformers) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1->xformers) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->xformers) (3.0.2)\n",
            "Installing collected packages: xformers\n",
            "Successfully installed xformers-0.0.29.post1\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (24.2)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.3.tar.gz (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trl\n",
            "  Downloading trl-0.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Using cached ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Downloading trl-0.13.0-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.3-cp311-cp311-linux_x86_64.whl size=191363917 sha256=b1243e9b86687348a5ab03a073abacdf8e3d5e9e4b7e5326a183f47348c5dfba\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/a3/f9/48d2706cb2eac05ec0dc144bf6954fe47bb3c2cd0de280765e\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: trl, ninja, flash-attn, bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.1 flash-attn-2.7.3 ninja-1.11.1.3 trl-0.13.0\n",
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-mzk2wns9/unsloth_6439cd41bfb14c6e9cf005a234d34867\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-mzk2wns9/unsloth_6439cd41bfb14c6e9cf005a234d34867\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit bdf0cd6033595be4e7ed23d0d002bb176d343152\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unsloth_zoo>=2025.1.4 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading unsloth_zoo-2025.1.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n",
            "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading tyro-0.9.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.47.1)\n",
            "Collecting datasets>=2.16.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
            "Collecting protobuf<4.0.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.27.1)\n",
            "Collecting hf_transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: bitsandbytes>=0.43.3 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
            "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.5.2)\n",
            "Requirement already satisfied: triton<3.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.1)\n",
            "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.14.0)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.1.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.1.5-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.13-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.1.7-py3-none-any.whl size=174896 sha256=1fb8124ae2f3cffa3ee88096925a69d044049a6f3c26082267081ddea59cb55b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g_kdg11u/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
            "Successfully built unsloth\n",
            "Installing collected packages: xxhash, unsloth, shtab, protobuf, hf_transfer, fsspec, dill, multiprocess, tyro, datasets, cut_cross_entropy, unsloth_zoo\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 hf_transfer-0.1.9 multiprocess-0.70.16 protobuf-3.20.3 shtab-1.7.1 tyro-0.9.13 unsloth-2025.1.7 unsloth_zoo-2025.1.5 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "62d6f0a3d91c4098a53b016f1db06ae3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install --no-deps packaging ninja einops flash-attn trl peft accelerate bitsandbytes\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfpimFpNSIlS",
        "outputId": "2cfd1a88-c370-4c4b-fd2c-7c2c6804def4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qnUA8cVU73A"
      },
      "source": [
        "# **Step 2.** Import Python Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sl1jjxFMeVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae86cad2-e434-4fe7-8b89-1290e5c47bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import notebook_login\n",
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from unsloth import FastLanguageModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BvjU9GZVBsl"
      },
      "source": [
        "# **Step 3.** Login to Your Hugging Face with hf_token. (write access token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMu8Tb8cVKpo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "7dfdb12c74ca4eeea305f90593c1138b",
            "9e9ff66367714ecb8188d80801f53c0f",
            "94694a7098bb4d66b06b5c8ad43ab2f6",
            "ed02f7bea2cf43648aacffe7c2603ad4",
            "97246b9da03b4cd38c19205eae614c80",
            "21c5b73d7b3545dc9f9ee9ff1570e33c",
            "e49d9cea7b2c493c80877bf0f6cbeefa",
            "a0643030eff84999819f51b4c92fe513",
            "b898a3d3b1d44894a228ccca88f3e455",
            "d717d95f1bd049d38f79caa1971bf131",
            "8f089f50f25d4425a5fa5ecc7b31bd67",
            "d576220bcfa040fbb8d3b263f0996f21",
            "6659e558d21048d9930f716ff4d1c0db",
            "7bf38cfe137e4ae6b0fba6b73d430fb9",
            "5c20541932c84d64b94a349f4d95b1a7",
            "b4fb9d9d830045e4a8f8a653924a5830",
            "0e9e373cae1a4b0296f33c39adaae8d8",
            "9336ec6fae054724b42572918e5528cf",
            "9e6d7f0c8bea46ed890b3f4cb2c928ba",
            "b24f1432475042eab4eed559e39f27f5"
          ]
        },
        "outputId": "84ea465a-f1da-47de-b1f6-c5c5cfaf1b50"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dfdb12c74ca4eeea305f90593c1138b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz-0HCyjYoZ-"
      },
      "source": [
        "# **Step 4.** Convert your JSON dataset to Llama3 finetuning format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6ZzbDEmYna3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "a5b4197a7ab1462188e489adcc88009d",
            "11ddd49ae7674fa4b6b3215476a28155",
            "148290f9e1704924b1d9553f7a77cf15",
            "0dc600bc6e944c4c9eebee44de5b1e3c",
            "29ca68f8993d4f1685dc373a66f83500",
            "f37058b2a42944d1b8fd54e162d8f123",
            "963a19dcd88c4806840e645ce1437437",
            "d81c916b78d7406498719427f5bedfe3",
            "9b77a87881e944b0b72ff3ec25457f0b",
            "7dde4d8916044d48bcd7511af087176c",
            "3ef9b06f01ae4d81bc594715b48108de",
            "41dec095472b4bb18deabc2c9e491759",
            "0edd1289ccf44e818a02a6f6fb8b5216",
            "8f5ff27e9ed541ce9d000af6c485a6b2",
            "553b468e050849b3b85954db3c45e328",
            "f409e24ae3174ce1a816251efa99ca8f",
            "60696cf29e44466aa566313b60d14c84",
            "821ef85ba74a468e9d810a4830eda45f",
            "4c0c57adac56417e8f629935433b942c",
            "85020806ee734f5ea45d8d757872b4a3",
            "c296d17808014828bda6e03b356d9854",
            "a867d494ebe24f2b90686a23d9522bbf",
            "d2094841520545a481405eafe51c8d32",
            "85cf8cd9b8b44474b4e84ccdd5c12377",
            "2958b35e8d8b43d791006b3ac99c9cfa",
            "b6ca5135623d49df83ad94e7db800bf2",
            "3194c2981cd544a9a0904c80eb142607",
            "b18abb18c4c44b8dad749aefe6c69505",
            "8bbb0b328d2c46ebb5bbc583fd0edb9b",
            "eb16b5503fd0431f8e9635ddae281567",
            "140be330bbc54c2c998554ea4c8ca879",
            "c29e17ba967f4e44bc84c7851dc38c02",
            "91d8936fa4b74f7faf793211ccc05f07"
          ]
        },
        "outputId": "29fec8e3-f8ec-49df-96c6-126a9ffad6a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/4498 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5b4197a7ab1462188e489adcc88009d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41dec095472b4bb18deabc2c9e491759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2094841520545a481405eafe51c8d32"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "huggingface_user = \"ahsannadir\"\n",
        "dataset_name = \"disease-symptoms\"\n",
        "\n",
        "class Llama3InstructDataset:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.prompts = []\n",
        "        self.create_prompts()\n",
        "\n",
        "    def create_prompt(self, row):\n",
        "        prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{row['instruction']}<|eot_id|><|start_header_id|>user<|end_header_id|>{row['input']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>{row['output']}<|eot_id|>\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def create_prompts(self):\n",
        "        for row in self.data:\n",
        "            prompt = self.create_prompt(row)\n",
        "            self.prompts.append(prompt)\n",
        "\n",
        "    def get_dataset(self):\n",
        "        df = pd.DataFrame({'prompt': self.prompts})\n",
        "        return df\n",
        "\n",
        "def create_dataset_hf(dataset):\n",
        "    dataset.reset_index(drop=True, inplace=True)\n",
        "    return DatasetDict({\"train\": Dataset.from_pandas(dataset)})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with open('/content/dataset.json', 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    dataset = Llama3InstructDataset(data)\n",
        "    df = dataset.get_dataset()\n",
        "\n",
        "    processed_data_path = 'processed_data'\n",
        "    os.makedirs(processed_data_path, exist_ok=True)\n",
        "\n",
        "    llama3_dataset = create_dataset_hf(df)\n",
        "    llama3_dataset.save_to_disk(os.path.join(processed_data_path, \"llama3_dataset\"))\n",
        "    llama3_dataset.push_to_hub(f\"{huggingface_user}/{dataset_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_WiE8XYVXqQ"
      },
      "source": [
        "# **Step 5.** LoRa Finetuning Configurations\n",
        "- \"finetuned_model\" sets your models name on HF\n",
        "- \"num_train_epochs\" sets the number of epochs for training\n",
        "\n",
        "    (epoch = 1 pass through your entire dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQQN-uSUzB8h"
      },
      "outputs": [],
      "source": [
        "# Defining the configuration for the base model, LoRA and training\n",
        "config = {\n",
        "    \"hugging_face_username\":huggingface_user,\n",
        "    \"model_config\": {\n",
        "        \"base_model\":\"unsloth/llama-3-8b-Instruct-bnb-4bit\", # The base model\n",
        "        \"finetuned_model\":\"llama-3-8b-instruct-aidoctor\", # The finetuned model\n",
        "        \"max_seq_length\": 2048, # The maximum sequence length\n",
        "        \"dtype\":torch.float16, # The data type\n",
        "        \"load_in_4bit\": True, # Load the model in 4-bit\n",
        "    },\n",
        "    \"lora_config\": {\n",
        "      \"r\": 16, # The number of LoRA layers 8, 16, 32, 64\n",
        "      \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"], # The target modules\n",
        "      \"lora_alpha\":16, # The alpha value for LoRA\n",
        "      \"lora_dropout\":0, # The dropout value for LoRA\n",
        "      \"bias\":\"none\", # The bias for LoRA\n",
        "      \"use_gradient_checkpointing\":True, # Use gradient checkpointing\n",
        "      \"use_rslora\":False, # Use RSLora\n",
        "      \"use_dora\":False, # Use DoRa\n",
        "      \"loftq_config\":None # The LoFTQ configuration\n",
        "    },\n",
        "    \"training_dataset\":{\n",
        "        \"name\":f\"{huggingface_user}/{dataset_name}\", # The dataset name(huggingface/datasets)\n",
        "        \"split\":\"train\", # The dataset split\n",
        "        \"input_field\":\"prompt\", # The input field\n",
        "    },\n",
        "    \"training_config\": {\n",
        "        \"per_device_train_batch_size\": 2, # The batch size\n",
        "        \"gradient_accumulation_steps\": 4, # The gradient accumulation steps\n",
        "        \"warmup_steps\": 5, # The warmup steps\n",
        "        \"max_steps\":0, # The maximum steps (0 if the epochs are defined)\n",
        "        \"num_train_epochs\": 5, # The number of training epochs(0 if the maximum steps are defined)\n",
        "        \"learning_rate\": 2e-4, # The learning rate\n",
        "        \"fp16\": not torch.cuda.is_bf16_supported(),  # The fp16\n",
        "        \"bf16\": torch.cuda.is_bf16_supported(), # The bf16\n",
        "        \"logging_steps\": 1, # The logging steps\n",
        "        \"optim\" :\"adamw_8bit\", # The optimizer\n",
        "        \"weight_decay\" : 0.01,  # The weight decay\n",
        "        \"lr_scheduler_type\": \"linear\", # The learning rate scheduler\n",
        "        \"seed\" : 42, # The seed\n",
        "        \"output_dir\" : \"outputs\", # The output directory\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcpVNM_7ZGbi"
      },
      "source": [
        "# **Step 6.** Load Llama3-8B, QLoRA & Trainer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4wxJAgnM2W0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444,
          "referenced_widgets": [
            "91e9d39938b144eca849be877c35e5f7",
            "90219a7e124c4b178ca2d36e6bb3dc1e",
            "36b6d3e0a21844699fb5adb10a24a446",
            "0638ff4b22ec42e49ebc3ea9912109ca",
            "4d56883cd1eb4a1790c268ca7f79dee6",
            "238c1f59e451402d91b79abf1bff7eec",
            "90087f381e074a0bbd7b3cac877af981",
            "720f3f4e46644dcdac97c152bd5faf9d",
            "d805afce5965460a87f771bce8338520",
            "db099a7ab1c74347a0bfdc144d1d9e47",
            "be3b88a2a84447f48f944aa645c3ba74",
            "86c4916b80a9421fb1a48fb5728b4e72",
            "c204e3259f6a44d294615444ed3fdf25",
            "145628d4f8a94019a51d61169d4e0e5e",
            "777ab2fb4e2e4fd59568cf3840d67e71",
            "17c148ccfc8c45e2ade3ea1736048abf",
            "6966502f0d0d47a38616196346833050",
            "77d249451eaf47e2bbb71c091bf85f46",
            "80c81851c4ce4cf595ba6d75998b9321",
            "daf0f4781be74fd6ba9c4d8cf0302a9e",
            "2b1ebe639118400bbbd5c4efd27a26b0",
            "37c8aa32c227444f85f80986182fdc64",
            "ede9b06919a44f6e863ca4dc0d67682e",
            "2248c8b07e1a4e9eb35bc068ed671cf7",
            "9cee739f893540f3b3257799ac8d4314",
            "5a74886c8f2a402eab007033fa67917c",
            "184d2714db2b42c2b8f5e1adc8f975d1",
            "dc567edc728241299b471c7217cb7418",
            "86438563cff24404b09ebb27ff690366",
            "d13bf6e1288240aa80b26f421c3b864b",
            "0c68bd97ca214f058fffdace64a3d548",
            "d06ff415c63744f58be1d9941b0776d4",
            "64ab2e46975c4cb199eb166f248e8df3",
            "5c03d3fcfcb240d6b2729df803e3d4d3",
            "5a3f398f5234435b8e0e0c35221668d0",
            "ac4cb4ddf5604cdaaaad4f5304f41d70",
            "51d4eb371cbf404fada8fc9c6ee59226",
            "cfa0aa8422d04e4b9054ee5ca369a107",
            "a971792e64364463a13707c1840cd036",
            "1fde592b082b41718d45ada7848b580c",
            "e21b243d21a9474fb9f7b9cc876a8ec1",
            "91427ea1905e43c0b88089f913b233df",
            "dbde99507d0b417fa41e7af7e159fec0",
            "292e9c1e313b42f6a312c17c7c741bde",
            "1c1584b5984b4a5f908c5aa0699f1b34",
            "2d5373b409e94b3984e38a20edf2369f",
            "710b37d67ec54e6892e9b21ababbaf9d",
            "767e711bac95474e9832c24bedb78277",
            "9d10f6884a134f77a84c8c7d9f9a4d87",
            "2d1b74dcff414934a77f57466c2b1810",
            "4e8c383b18794414a6ad85b0168295d6",
            "368c49bdfa7e4373bd1cd912d3c1574d",
            "355979e4f53b4ec28b462a2106b6f141",
            "780609f8ed894da78584e671c244ac75",
            "a904fc7303be469dae60bbfbe6466ca6",
            "5aa95242276c4678802ada573cb37a46",
            "4473ef293228402f9fca32a9c8b2d781",
            "60feab04bc554d36b8c96a52cf8599dc",
            "da247cc9c7d0467caf82dacb1c735604",
            "54cdee82b2e24abc9754129d30b8c79e",
            "c5bcdadc1020447a83adf85e0190fb8f",
            "25977ed6bd70434ca02b07997391b5a7",
            "68a7375b3c444f95ba705f4a55b8b5f4",
            "bbf5837e13144542a6c916f7b0f62f32",
            "47591d80a2a547b8babd9b9c976ba284",
            "a8fe79d37f8843a390de1b9fa6cb0a7b",
            "b5436e03bced4a7882eadbe153214033",
            "00dfaa5bfcde42cab80e69e3d13b4e51",
            "4ca4b081c83443b881199c316697915c",
            "075852d911a24197b19910fdca9bf9b9",
            "b0e14bcede7b49d796325951d097b24a",
            "27b87d1de2ec48729b1ac83d9e9b1b2a",
            "590b6e8c8e8b4a56bb9f0518e4f5d552",
            "a8ce3c60c8be44609a4b3f053cfa9840",
            "edc79eaa30fa48d3a506ebabaddd5989",
            "d66085ea10264bc0892fc95bcab5b7a1",
            "4b8014d8b1644ffc8ee419ea499b9e2c",
            "48373ed854884291adead1bb48b3427b",
            "10c30ecaa4694fb59dc346728afc0485",
            "ccda34ab82f24fda9c007eb6edfca4c3",
            "abbc189f0dd149c6a4eae645e65b90da",
            "d878cf6fddc54811a83287ea786015a1",
            "bbfde19e343b4b44b3c03e8d9b07ee4b",
            "22fc5d48287c4707902a520d4a535c83",
            "c30520da64ae41f981b5e750878fb331",
            "16f6e0b4a8224ff38ab713e94320118b",
            "6f4fa4261a3348158dcf0c1d876d5ba3",
            "61cf23180bc349ab993c00d2e9e3916b",
            "c4add5556045419f9e137cb072f41176",
            "37b823b3a873404aa4e3303258609ce3",
            "5433e28631f24d1ab31ed3306f91dd3d",
            "88ac8fb11c66447095c3682abfb8645e",
            "4fa2f4921f7b481bb285e5b807e97f4a",
            "fd165494e9f24ec08b34f6ef0b55389d",
            "3fe8ce8c5cd24809a26431b801e20bc4",
            "b4fe071865ab45fe9bff0983818953af",
            "ae4e2565dc104fd1a0ad56496233ad4e",
            "e88df3b174d542b4a717e8189e6b4472",
            "6effde9d9f1c43c8a3605930415e07cb"
          ]
        },
        "outputId": "8627bf5a-42e7-4cd9-9d8d-77e7e64404e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.1.7: Fast Llama patching. Transformers: 4.47.1.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post1. FA2 = True]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device supports bfloat16 but you selected float16. Will change to bfloat16.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91e9d39938b144eca849be877c35e5f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86c4916b80a9421fb1a48fb5728b4e72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ede9b06919a44f6e863ca4dc0d67682e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c03d3fcfcb240d6b2729df803e3d4d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c1584b5984b4a5f908c5aa0699f1b34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.1.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/275 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aa95242276c4678802ada573cb37a46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/409k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5436e03bced4a7882eadbe153214033"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4498 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48373ed854884291adead1bb48b3427b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/4498 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4add5556045419f9e137cb072f41176"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Loading the model and the tokinizer for the model\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = config.get(\"model_config\").get(\"base_model\"),\n",
        "    max_seq_length = config.get(\"model_config\").get(\"max_seq_length\"),\n",
        "    dtype = config.get(\"model_config\").get(\"dtype\"),\n",
        "    load_in_4bit = config.get(\"model_config\").get(\"load_in_4bit\"),\n",
        ")\n",
        "\n",
        "# Setup for QLoRA/LoRA peft of the base model\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = config.get(\"lora_config\").get(\"r\"),\n",
        "    target_modules = config.get(\"lora_config\").get(\"target_modules\"),\n",
        "    lora_alpha = config.get(\"lora_config\").get(\"lora_alpha\"),\n",
        "    lora_dropout = config.get(\"lora_config\").get(\"lora_dropout\"),\n",
        "    bias = config.get(\"lora_config\").get(\"bias\"),\n",
        "    use_gradient_checkpointing = config.get(\"lora_config\").get(\"use_gradient_checkpointing\"),\n",
        "    random_state = 42,\n",
        "    use_rslora = config.get(\"lora_config\").get(\"use_rslora\"),\n",
        "    use_dora = config.get(\"lora_config\").get(\"use_dora\"),\n",
        "    loftq_config = config.get(\"lora_config\").get(\"loftq_config\"),\n",
        ")\n",
        "\n",
        "# Loading the training dataset\n",
        "dataset_train = load_dataset(config.get(\"training_dataset\").get(\"name\"), split = config.get(\"training_dataset\").get(\"split\"))\n",
        "\n",
        "# Setting up the trainer for the model\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset_train,\n",
        "    dataset_text_field = config.get(\"training_dataset\").get(\"input_field\"),\n",
        "    max_seq_length = config.get(\"model_config\").get(\"max_seq_length\"),\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = config.get(\"training_config\").get(\"per_device_train_batch_size\"),\n",
        "        gradient_accumulation_steps = config.get(\"training_config\").get(\"gradient_accumulation_steps\"),\n",
        "        warmup_steps = config.get(\"training_config\").get(\"warmup_steps\"),\n",
        "        max_steps = config.get(\"training_config\").get(\"max_steps\"),\n",
        "        num_train_epochs= config.get(\"training_config\").get(\"num_train_epochs\"),\n",
        "        learning_rate = config.get(\"training_config\").get(\"learning_rate\"),\n",
        "        fp16 = config.get(\"training_config\").get(\"fp16\"),\n",
        "        bf16 = config.get(\"training_config\").get(\"bf16\"),\n",
        "        logging_steps = config.get(\"training_config\").get(\"logging_steps\"),\n",
        "        optim = config.get(\"training_config\").get(\"optim\"),\n",
        "        weight_decay = config.get(\"training_config\").get(\"weight_decay\"),\n",
        "        lr_scheduler_type = config.get(\"training_config\").get(\"lr_scheduler_type\"),\n",
        "        seed = 42,\n",
        "        output_dir = config.get(\"training_config\").get(\"output_dir\"),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u-v9ArEnYZb"
      },
      "source": [
        "# **Step 7.** Train Your Finetuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI9mEQ7ZOUx2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38a565b0-3982-45f6-a6c8-2eb084301415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 4,498 | Num Epochs = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 2,810\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250127_160735-lo9xp5mw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ahsannadir-nutech/huggingface/runs/lo9xp5mw' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/ahsannadir-nutech/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ahsannadir-nutech/huggingface' target=\"_blank\">https://wandb.ai/ahsannadir-nutech/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ahsannadir-nutech/huggingface/runs/lo9xp5mw' target=\"_blank\">https://wandb.ai/ahsannadir-nutech/huggingface/runs/lo9xp5mw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2810' max='2810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2810/2810 1:16:11, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.538700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.239700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.251400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.149300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.549600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.798700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.302600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.811300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.452600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.238700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.184900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.811600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.823900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.820200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.683300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.973400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.974900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.269600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.733600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.329700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.562300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.617900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.707500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.602500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.726500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.459600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.570000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.177500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.576600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.654300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.399100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.542200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.614200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.026500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.402400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.458500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.543400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.931000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.573800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.664700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.443100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.568300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.709900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.785400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.436900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.319700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.316600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.347900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.505900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.596200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.599800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.658600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.209200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.163900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.565200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.347700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.205000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.517200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.310300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.264900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.230800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.439300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.651600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.243600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.377000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.304300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.363000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.560400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.816300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.798200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.326900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.723500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.190200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.114200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.437000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.354400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.463700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.196100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.290200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.130300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.213500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.941400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.453500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.124000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.215200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.185500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.349800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.236900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.361600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.253800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.424000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.164500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.382400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.228400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.141600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.143300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.981300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.102900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.541400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.099800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.200700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.097300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>1.216600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.891200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.204300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.090700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.661000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.103500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.083000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.149700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.112000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.331100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.171000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.464700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.239800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.177900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.112900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.245600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.091400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>0.660800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.193700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.637000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>1.092800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.117000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.380900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.101900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.346600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>0.151700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.181700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.311500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.102900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.320800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.438100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.158100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.159100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.466600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.240800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.633100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.234900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.112800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.631100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.460900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.137900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.095200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.220600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.162700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.183700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.211000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.153700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.103000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.250400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.192700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.088300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.674700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.177700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>0.675200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.465500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.373200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.109300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.509300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.369400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.427500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.088700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.619500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.494900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.099900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.092400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.282500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.214300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.178000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.525300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>0.400800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>0.172900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.276100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.527500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.578100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>0.077700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.495200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.172700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.151400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.282800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.089500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.094300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.085800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>0.188800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.248100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.478800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>0.114600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.667100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.090100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.394400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>0.181200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.607500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.083800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>0.102300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>0.081300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.507500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.276900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>0.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.227000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.186000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>0.093800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.102000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>0.310500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>0.260300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>0.220400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>0.346900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.373600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.371000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>0.086600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>0.167400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>0.103100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.201100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>0.143200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>0.423500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>0.083900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>0.338300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.605800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>0.409500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>0.548600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>0.240300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>0.431600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.120200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>0.994600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>0.094700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>0.796800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.165000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>0.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>0.359800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>0.274600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>0.312400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>0.435900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.294500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>0.464100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>0.161800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>0.267300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.107500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.182400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>0.401200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>0.088600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>0.091500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>0.174600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.091800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>0.123100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>0.143600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>0.408700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>0.783100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.391100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>256</td>\n",
              "      <td>0.268800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>257</td>\n",
              "      <td>0.324900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>0.998000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>259</td>\n",
              "      <td>0.310600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.100600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>0.290200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>262</td>\n",
              "      <td>0.092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>263</td>\n",
              "      <td>0.163200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>0.210400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>0.171800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>0.138400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>0.672700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>268</td>\n",
              "      <td>0.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>269</td>\n",
              "      <td>0.197900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.211700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>271</td>\n",
              "      <td>0.380400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>0.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>0.501500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>274</td>\n",
              "      <td>0.105000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.074900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>0.156700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>277</td>\n",
              "      <td>0.474900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>278</td>\n",
              "      <td>0.072200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.440900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.087700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>281</td>\n",
              "      <td>0.517400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>0.271200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>283</td>\n",
              "      <td>0.939800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>284</td>\n",
              "      <td>0.689300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.512600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>0.089700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>287</td>\n",
              "      <td>0.098800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.082600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>0.630100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.294700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>0.117200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>292</td>\n",
              "      <td>0.123000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>293</td>\n",
              "      <td>0.869900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>0.505800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.146400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>296</td>\n",
              "      <td>0.186300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>0.283400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>298</td>\n",
              "      <td>0.358000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>0.363500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.318300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>301</td>\n",
              "      <td>0.293000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>302</td>\n",
              "      <td>0.340300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>303</td>\n",
              "      <td>0.190500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>304</td>\n",
              "      <td>0.670300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>0.307300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>306</td>\n",
              "      <td>0.129900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>307</td>\n",
              "      <td>0.088600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>308</td>\n",
              "      <td>0.670600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>309</td>\n",
              "      <td>0.536700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.069900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>311</td>\n",
              "      <td>0.340900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>0.318300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>313</td>\n",
              "      <td>0.204900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>314</td>\n",
              "      <td>0.856800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>0.182000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>316</td>\n",
              "      <td>0.313800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>317</td>\n",
              "      <td>0.249900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>318</td>\n",
              "      <td>0.763700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>319</td>\n",
              "      <td>0.092800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.136700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>321</td>\n",
              "      <td>0.288800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>322</td>\n",
              "      <td>0.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>323</td>\n",
              "      <td>0.288800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>324</td>\n",
              "      <td>0.282300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.149300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>326</td>\n",
              "      <td>0.196200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>327</td>\n",
              "      <td>0.076800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>328</td>\n",
              "      <td>0.194800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>329</td>\n",
              "      <td>0.445500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.741100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>331</td>\n",
              "      <td>0.454000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>332</td>\n",
              "      <td>0.097100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>333</td>\n",
              "      <td>0.086100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>334</td>\n",
              "      <td>0.390900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>0.175500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>0.203300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>337</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>338</td>\n",
              "      <td>0.092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>339</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.776100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>341</td>\n",
              "      <td>0.436100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>342</td>\n",
              "      <td>0.198900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>343</td>\n",
              "      <td>0.227400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>344</td>\n",
              "      <td>0.575400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.202500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>346</td>\n",
              "      <td>0.461100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>347</td>\n",
              "      <td>0.283000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>348</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>349</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.375800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>351</td>\n",
              "      <td>0.427600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>352</td>\n",
              "      <td>0.259900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>353</td>\n",
              "      <td>0.657800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>354</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>0.132100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>356</td>\n",
              "      <td>0.067000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>357</td>\n",
              "      <td>0.547300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>358</td>\n",
              "      <td>0.398900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>359</td>\n",
              "      <td>0.143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.516700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>361</td>\n",
              "      <td>0.087000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>362</td>\n",
              "      <td>0.225100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>363</td>\n",
              "      <td>0.068900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>364</td>\n",
              "      <td>0.743900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>1.110900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>366</td>\n",
              "      <td>0.535200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>367</td>\n",
              "      <td>0.088900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>368</td>\n",
              "      <td>0.383300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>369</td>\n",
              "      <td>0.287400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.719900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>371</td>\n",
              "      <td>0.421300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.214600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>373</td>\n",
              "      <td>0.250600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>374</td>\n",
              "      <td>0.397000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.280300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>376</td>\n",
              "      <td>0.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>377</td>\n",
              "      <td>0.094200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>378</td>\n",
              "      <td>0.099900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>379</td>\n",
              "      <td>0.178300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.404900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>381</td>\n",
              "      <td>0.388200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>382</td>\n",
              "      <td>0.688800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>383</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>384</td>\n",
              "      <td>0.330700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>385</td>\n",
              "      <td>0.710200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>386</td>\n",
              "      <td>0.090200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>387</td>\n",
              "      <td>0.216200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>388</td>\n",
              "      <td>0.594100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>389</td>\n",
              "      <td>0.466100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.359200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>391</td>\n",
              "      <td>0.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>392</td>\n",
              "      <td>0.554800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>393</td>\n",
              "      <td>0.381300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>394</td>\n",
              "      <td>0.098900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>395</td>\n",
              "      <td>0.105300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>396</td>\n",
              "      <td>0.521600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>397</td>\n",
              "      <td>1.045400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>398</td>\n",
              "      <td>0.185500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>399</td>\n",
              "      <td>0.084700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.097600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>401</td>\n",
              "      <td>0.101200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>402</td>\n",
              "      <td>0.286900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>403</td>\n",
              "      <td>0.820700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>404</td>\n",
              "      <td>0.329000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>0.267300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>406</td>\n",
              "      <td>0.244900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>407</td>\n",
              "      <td>0.263000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>408</td>\n",
              "      <td>0.718900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>409</td>\n",
              "      <td>0.488100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.241500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>411</td>\n",
              "      <td>0.325400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>412</td>\n",
              "      <td>0.238300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>413</td>\n",
              "      <td>0.596000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>414</td>\n",
              "      <td>0.076500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>415</td>\n",
              "      <td>0.240600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>416</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>417</td>\n",
              "      <td>0.664700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>418</td>\n",
              "      <td>0.124500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>419</td>\n",
              "      <td>0.337800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.077800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>421</td>\n",
              "      <td>0.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>422</td>\n",
              "      <td>0.090600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>423</td>\n",
              "      <td>0.271500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>424</td>\n",
              "      <td>0.264500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.480600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>426</td>\n",
              "      <td>0.087000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>427</td>\n",
              "      <td>0.175300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>428</td>\n",
              "      <td>0.323100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>429</td>\n",
              "      <td>0.292500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.084700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>431</td>\n",
              "      <td>0.105400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>432</td>\n",
              "      <td>0.178800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>433</td>\n",
              "      <td>0.511900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>434</td>\n",
              "      <td>0.085400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>435</td>\n",
              "      <td>0.370800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>436</td>\n",
              "      <td>1.142200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>437</td>\n",
              "      <td>0.510900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>438</td>\n",
              "      <td>0.201800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>439</td>\n",
              "      <td>0.368100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.248100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>441</td>\n",
              "      <td>0.658200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>442</td>\n",
              "      <td>0.162900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>443</td>\n",
              "      <td>0.074100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>444</td>\n",
              "      <td>0.298000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>445</td>\n",
              "      <td>0.676900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>446</td>\n",
              "      <td>0.082400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>447</td>\n",
              "      <td>0.205900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>448</td>\n",
              "      <td>0.085100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>449</td>\n",
              "      <td>0.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.538900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>451</td>\n",
              "      <td>0.386300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>452</td>\n",
              "      <td>0.152400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>453</td>\n",
              "      <td>0.450100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>454</td>\n",
              "      <td>0.087800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>455</td>\n",
              "      <td>0.138800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>456</td>\n",
              "      <td>0.673700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>457</td>\n",
              "      <td>0.339400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>458</td>\n",
              "      <td>0.364900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>459</td>\n",
              "      <td>0.305100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.354300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>461</td>\n",
              "      <td>0.196900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>462</td>\n",
              "      <td>0.119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>463</td>\n",
              "      <td>0.547800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>464</td>\n",
              "      <td>0.132500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.149500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>466</td>\n",
              "      <td>0.085300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>467</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.085700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>469</td>\n",
              "      <td>0.373200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.084700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>471</td>\n",
              "      <td>0.127600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>472</td>\n",
              "      <td>0.538700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>473</td>\n",
              "      <td>0.086400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>474</td>\n",
              "      <td>0.135800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>0.066800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>476</td>\n",
              "      <td>0.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>477</td>\n",
              "      <td>0.139200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>478</td>\n",
              "      <td>0.087900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>479</td>\n",
              "      <td>0.083000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.133600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>481</td>\n",
              "      <td>0.438400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>482</td>\n",
              "      <td>0.233900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>483</td>\n",
              "      <td>0.207800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>484</td>\n",
              "      <td>0.082600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>485</td>\n",
              "      <td>0.355700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>486</td>\n",
              "      <td>0.093700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>487</td>\n",
              "      <td>0.262700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>488</td>\n",
              "      <td>0.147300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>489</td>\n",
              "      <td>0.154800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.176700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>491</td>\n",
              "      <td>0.098500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>492</td>\n",
              "      <td>0.634700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>493</td>\n",
              "      <td>0.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>494</td>\n",
              "      <td>0.184200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>495</td>\n",
              "      <td>0.150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>496</td>\n",
              "      <td>0.130600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>497</td>\n",
              "      <td>0.594400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>498</td>\n",
              "      <td>0.092700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>499</td>\n",
              "      <td>0.392200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.282400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>501</td>\n",
              "      <td>0.630600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>502</td>\n",
              "      <td>0.258400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>503</td>\n",
              "      <td>0.097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>504</td>\n",
              "      <td>0.717200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>505</td>\n",
              "      <td>0.121300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>506</td>\n",
              "      <td>0.231500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>507</td>\n",
              "      <td>0.082200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>508</td>\n",
              "      <td>0.432000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>509</td>\n",
              "      <td>0.097800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.214000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>511</td>\n",
              "      <td>0.106700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>512</td>\n",
              "      <td>0.107300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>513</td>\n",
              "      <td>0.093700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>514</td>\n",
              "      <td>0.161200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>515</td>\n",
              "      <td>0.383400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>516</td>\n",
              "      <td>0.636000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>517</td>\n",
              "      <td>0.111500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>518</td>\n",
              "      <td>0.616200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>519</td>\n",
              "      <td>0.087600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>521</td>\n",
              "      <td>0.211300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>522</td>\n",
              "      <td>0.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>523</td>\n",
              "      <td>0.205800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>524</td>\n",
              "      <td>0.109000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>526</td>\n",
              "      <td>0.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>527</td>\n",
              "      <td>0.814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>528</td>\n",
              "      <td>0.072800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>529</td>\n",
              "      <td>0.691200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.139100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>531</td>\n",
              "      <td>0.225800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>532</td>\n",
              "      <td>0.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>533</td>\n",
              "      <td>0.267500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>534</td>\n",
              "      <td>0.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>535</td>\n",
              "      <td>0.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>536</td>\n",
              "      <td>0.709400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>537</td>\n",
              "      <td>0.810200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>538</td>\n",
              "      <td>0.158100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>539</td>\n",
              "      <td>0.129600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>541</td>\n",
              "      <td>0.114500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>542</td>\n",
              "      <td>0.162900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>543</td>\n",
              "      <td>0.061500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>544</td>\n",
              "      <td>0.244200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>545</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>546</td>\n",
              "      <td>0.234600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>547</td>\n",
              "      <td>0.510500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>548</td>\n",
              "      <td>0.883500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>549</td>\n",
              "      <td>0.591700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.182600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>551</td>\n",
              "      <td>0.449700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>552</td>\n",
              "      <td>0.117800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>553</td>\n",
              "      <td>0.467800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>554</td>\n",
              "      <td>0.325100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>555</td>\n",
              "      <td>0.202200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>556</td>\n",
              "      <td>0.650800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>557</td>\n",
              "      <td>0.374400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.248100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>559</td>\n",
              "      <td>0.744900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>561</td>\n",
              "      <td>0.622200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>562</td>\n",
              "      <td>0.540800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>563</td>\n",
              "      <td>0.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>564</td>\n",
              "      <td>0.135500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>565</td>\n",
              "      <td>0.078600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>566</td>\n",
              "      <td>0.135600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>567</td>\n",
              "      <td>0.132100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>568</td>\n",
              "      <td>0.084200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>569</td>\n",
              "      <td>0.375600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.083200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>571</td>\n",
              "      <td>0.177400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>572</td>\n",
              "      <td>0.898700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>573</td>\n",
              "      <td>0.571100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>574</td>\n",
              "      <td>0.284200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.290800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>576</td>\n",
              "      <td>0.129600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>577</td>\n",
              "      <td>0.184300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>578</td>\n",
              "      <td>0.310800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>579</td>\n",
              "      <td>0.143300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.153300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>581</td>\n",
              "      <td>0.145900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>582</td>\n",
              "      <td>0.120300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>583</td>\n",
              "      <td>0.129900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>584</td>\n",
              "      <td>0.204900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>585</td>\n",
              "      <td>0.128100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>586</td>\n",
              "      <td>0.343300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>587</td>\n",
              "      <td>0.504200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>588</td>\n",
              "      <td>0.189800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>589</td>\n",
              "      <td>0.771400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.085500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>591</td>\n",
              "      <td>0.303100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>592</td>\n",
              "      <td>0.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>593</td>\n",
              "      <td>0.496800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>594</td>\n",
              "      <td>0.135900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>595</td>\n",
              "      <td>0.274900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>596</td>\n",
              "      <td>0.073000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>597</td>\n",
              "      <td>0.328300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>598</td>\n",
              "      <td>0.078600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>599</td>\n",
              "      <td>0.494300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.071400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>601</td>\n",
              "      <td>0.411000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>602</td>\n",
              "      <td>0.411500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>603</td>\n",
              "      <td>0.320900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>604</td>\n",
              "      <td>0.167700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>605</td>\n",
              "      <td>0.060900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>606</td>\n",
              "      <td>0.275400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>607</td>\n",
              "      <td>0.718500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>608</td>\n",
              "      <td>0.369000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>609</td>\n",
              "      <td>0.604600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.122400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>611</td>\n",
              "      <td>0.126200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>612</td>\n",
              "      <td>0.090600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>613</td>\n",
              "      <td>0.266800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>614</td>\n",
              "      <td>0.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>615</td>\n",
              "      <td>0.389400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>616</td>\n",
              "      <td>0.492100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>617</td>\n",
              "      <td>0.081300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>618</td>\n",
              "      <td>0.133500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>619</td>\n",
              "      <td>0.157200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.217000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>621</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>622</td>\n",
              "      <td>0.568800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>623</td>\n",
              "      <td>0.081100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>624</td>\n",
              "      <td>0.172600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.139900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>626</td>\n",
              "      <td>0.102600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>627</td>\n",
              "      <td>0.264500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>628</td>\n",
              "      <td>0.161000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>629</td>\n",
              "      <td>0.157500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.254000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>631</td>\n",
              "      <td>0.170800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>632</td>\n",
              "      <td>0.331400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>633</td>\n",
              "      <td>0.261000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>634</td>\n",
              "      <td>0.129400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>635</td>\n",
              "      <td>0.274200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>636</td>\n",
              "      <td>0.145500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>637</td>\n",
              "      <td>0.362900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>638</td>\n",
              "      <td>0.254100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>639</td>\n",
              "      <td>0.079800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.172600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>641</td>\n",
              "      <td>0.330900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>642</td>\n",
              "      <td>0.291700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>643</td>\n",
              "      <td>0.165000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>644</td>\n",
              "      <td>0.083800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>645</td>\n",
              "      <td>0.083000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>646</td>\n",
              "      <td>0.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>647</td>\n",
              "      <td>0.430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>648</td>\n",
              "      <td>0.083400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>649</td>\n",
              "      <td>0.128300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.527200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.069700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>652</td>\n",
              "      <td>0.348100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>653</td>\n",
              "      <td>0.552400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>654</td>\n",
              "      <td>0.079700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>655</td>\n",
              "      <td>0.252000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>656</td>\n",
              "      <td>0.074900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>657</td>\n",
              "      <td>0.105700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>658</td>\n",
              "      <td>0.332100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>659</td>\n",
              "      <td>0.213000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>661</td>\n",
              "      <td>0.464100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>662</td>\n",
              "      <td>0.348400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>663</td>\n",
              "      <td>0.159300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>664</td>\n",
              "      <td>0.281600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>665</td>\n",
              "      <td>0.384100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>666</td>\n",
              "      <td>0.272400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>667</td>\n",
              "      <td>0.120600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>668</td>\n",
              "      <td>0.483100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>669</td>\n",
              "      <td>0.807300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.376200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>671</td>\n",
              "      <td>0.168000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>672</td>\n",
              "      <td>0.261600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>673</td>\n",
              "      <td>0.074600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>674</td>\n",
              "      <td>0.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.089000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>676</td>\n",
              "      <td>0.104700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>677</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>678</td>\n",
              "      <td>0.514600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>679</td>\n",
              "      <td>0.265400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.088100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>681</td>\n",
              "      <td>0.129000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>682</td>\n",
              "      <td>0.066300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>683</td>\n",
              "      <td>0.076500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>684</td>\n",
              "      <td>0.133200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>685</td>\n",
              "      <td>0.163300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>686</td>\n",
              "      <td>0.556400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>687</td>\n",
              "      <td>0.127500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>688</td>\n",
              "      <td>0.188200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>689</td>\n",
              "      <td>0.302700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.210900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>691</td>\n",
              "      <td>0.282300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>692</td>\n",
              "      <td>0.306900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>693</td>\n",
              "      <td>0.324400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>694</td>\n",
              "      <td>0.151100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>695</td>\n",
              "      <td>0.575300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>696</td>\n",
              "      <td>0.140700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>697</td>\n",
              "      <td>0.443100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>698</td>\n",
              "      <td>0.128600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>699</td>\n",
              "      <td>0.104300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>701</td>\n",
              "      <td>0.209200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.271900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>703</td>\n",
              "      <td>0.350400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>704</td>\n",
              "      <td>0.078500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>705</td>\n",
              "      <td>0.136000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>706</td>\n",
              "      <td>0.074900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>707</td>\n",
              "      <td>0.245900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>708</td>\n",
              "      <td>0.140500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>709</td>\n",
              "      <td>0.347000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.131400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>711</td>\n",
              "      <td>0.313100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>712</td>\n",
              "      <td>0.388900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>713</td>\n",
              "      <td>0.142000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>714</td>\n",
              "      <td>0.147400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>715</td>\n",
              "      <td>0.182000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>716</td>\n",
              "      <td>0.411700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>717</td>\n",
              "      <td>0.123900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>718</td>\n",
              "      <td>0.131300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>719</td>\n",
              "      <td>0.192600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>721</td>\n",
              "      <td>0.086300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>722</td>\n",
              "      <td>0.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>723</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>724</td>\n",
              "      <td>0.408700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>0.334400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>726</td>\n",
              "      <td>0.188300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>727</td>\n",
              "      <td>0.127500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>728</td>\n",
              "      <td>0.383100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>729</td>\n",
              "      <td>0.443700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.105100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>731</td>\n",
              "      <td>0.135900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>732</td>\n",
              "      <td>0.133100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>733</td>\n",
              "      <td>0.195600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>734</td>\n",
              "      <td>0.275700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>735</td>\n",
              "      <td>0.233900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>736</td>\n",
              "      <td>0.079000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>737</td>\n",
              "      <td>0.163300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>738</td>\n",
              "      <td>0.476500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>739</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.276700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>741</td>\n",
              "      <td>0.088500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>742</td>\n",
              "      <td>0.210400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>743</td>\n",
              "      <td>0.273200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>1.046400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>745</td>\n",
              "      <td>0.269800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>746</td>\n",
              "      <td>0.416500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>747</td>\n",
              "      <td>0.414700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>748</td>\n",
              "      <td>0.138300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>749</td>\n",
              "      <td>0.154300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.299300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>751</td>\n",
              "      <td>0.075100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>752</td>\n",
              "      <td>0.350500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>753</td>\n",
              "      <td>0.314600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>754</td>\n",
              "      <td>0.131400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>755</td>\n",
              "      <td>0.650600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>756</td>\n",
              "      <td>0.067700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>757</td>\n",
              "      <td>0.092700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>758</td>\n",
              "      <td>0.079500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>759</td>\n",
              "      <td>0.108200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.142900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>761</td>\n",
              "      <td>0.201400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>762</td>\n",
              "      <td>0.109000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>763</td>\n",
              "      <td>0.516100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>764</td>\n",
              "      <td>0.248600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>765</td>\n",
              "      <td>0.151200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>766</td>\n",
              "      <td>0.250900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>767</td>\n",
              "      <td>0.135700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>768</td>\n",
              "      <td>0.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>769</td>\n",
              "      <td>0.130900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.454500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>771</td>\n",
              "      <td>0.662200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>772</td>\n",
              "      <td>0.384700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>773</td>\n",
              "      <td>0.388200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>774</td>\n",
              "      <td>0.090700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>0.087200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>776</td>\n",
              "      <td>0.120400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>777</td>\n",
              "      <td>0.340300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>778</td>\n",
              "      <td>0.136200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>779</td>\n",
              "      <td>0.628700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.101900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>781</td>\n",
              "      <td>0.111500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>782</td>\n",
              "      <td>0.308900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>783</td>\n",
              "      <td>0.239900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>784</td>\n",
              "      <td>0.347500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>785</td>\n",
              "      <td>0.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>786</td>\n",
              "      <td>0.117800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>787</td>\n",
              "      <td>0.212800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>788</td>\n",
              "      <td>0.176100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>789</td>\n",
              "      <td>0.145500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.220700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>791</td>\n",
              "      <td>0.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>792</td>\n",
              "      <td>0.211000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>793</td>\n",
              "      <td>0.166100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>794</td>\n",
              "      <td>0.169900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>795</td>\n",
              "      <td>0.079000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>796</td>\n",
              "      <td>0.214800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>797</td>\n",
              "      <td>0.464300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>798</td>\n",
              "      <td>0.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>799</td>\n",
              "      <td>0.986200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.316500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>801</td>\n",
              "      <td>0.885300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>802</td>\n",
              "      <td>0.293400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>803</td>\n",
              "      <td>0.104100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>804</td>\n",
              "      <td>0.136200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>805</td>\n",
              "      <td>0.061200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>806</td>\n",
              "      <td>0.120200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>807</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>808</td>\n",
              "      <td>0.313100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>809</td>\n",
              "      <td>0.102500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.345300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>811</td>\n",
              "      <td>0.198700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>812</td>\n",
              "      <td>0.321000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>813</td>\n",
              "      <td>0.713200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>814</td>\n",
              "      <td>0.097500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>815</td>\n",
              "      <td>0.249200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>816</td>\n",
              "      <td>0.233500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>817</td>\n",
              "      <td>0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>818</td>\n",
              "      <td>0.150100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>819</td>\n",
              "      <td>0.172600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.086100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>821</td>\n",
              "      <td>0.331300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>822</td>\n",
              "      <td>0.273800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>823</td>\n",
              "      <td>0.276200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>824</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>0.088000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>826</td>\n",
              "      <td>0.107800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>827</td>\n",
              "      <td>0.106500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>828</td>\n",
              "      <td>0.194300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>829</td>\n",
              "      <td>0.109200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.400700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>831</td>\n",
              "      <td>0.274700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>832</td>\n",
              "      <td>0.210600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>833</td>\n",
              "      <td>0.068100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>834</td>\n",
              "      <td>0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>835</td>\n",
              "      <td>0.126800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>836</td>\n",
              "      <td>0.254700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.467800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>838</td>\n",
              "      <td>0.776600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>839</td>\n",
              "      <td>0.066200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.650200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>841</td>\n",
              "      <td>0.378100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>842</td>\n",
              "      <td>0.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>843</td>\n",
              "      <td>0.362100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>844</td>\n",
              "      <td>0.122200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>845</td>\n",
              "      <td>0.269000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>846</td>\n",
              "      <td>0.311700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>847</td>\n",
              "      <td>0.098500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>848</td>\n",
              "      <td>0.572900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>849</td>\n",
              "      <td>0.186000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.072300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>851</td>\n",
              "      <td>0.255000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>852</td>\n",
              "      <td>0.263300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>853</td>\n",
              "      <td>0.271800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>854</td>\n",
              "      <td>0.140500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>855</td>\n",
              "      <td>0.356600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>856</td>\n",
              "      <td>0.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>857</td>\n",
              "      <td>0.182000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>858</td>\n",
              "      <td>0.336100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>859</td>\n",
              "      <td>0.162900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>861</td>\n",
              "      <td>0.640400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>862</td>\n",
              "      <td>0.073200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>863</td>\n",
              "      <td>0.090800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>864</td>\n",
              "      <td>0.250500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>865</td>\n",
              "      <td>0.093100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>866</td>\n",
              "      <td>0.084100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>867</td>\n",
              "      <td>0.170900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>868</td>\n",
              "      <td>0.224600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>869</td>\n",
              "      <td>0.064600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.287900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>871</td>\n",
              "      <td>0.489800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>872</td>\n",
              "      <td>0.247300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>873</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>874</td>\n",
              "      <td>0.055600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.129400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>876</td>\n",
              "      <td>0.382800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>877</td>\n",
              "      <td>0.208200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>878</td>\n",
              "      <td>0.129700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>879</td>\n",
              "      <td>0.146300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.361400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>881</td>\n",
              "      <td>0.132400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>882</td>\n",
              "      <td>0.411200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>883</td>\n",
              "      <td>0.451900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>884</td>\n",
              "      <td>0.579700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>885</td>\n",
              "      <td>0.150800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>886</td>\n",
              "      <td>0.318500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>887</td>\n",
              "      <td>0.376300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>888</td>\n",
              "      <td>0.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>889</td>\n",
              "      <td>0.152600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.121000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>891</td>\n",
              "      <td>0.111100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>892</td>\n",
              "      <td>0.123800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>893</td>\n",
              "      <td>0.154400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>894</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>895</td>\n",
              "      <td>0.135400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>896</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>897</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>898</td>\n",
              "      <td>0.123800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>899</td>\n",
              "      <td>0.084600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.321500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>901</td>\n",
              "      <td>0.309700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>902</td>\n",
              "      <td>0.187200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>903</td>\n",
              "      <td>0.432100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>904</td>\n",
              "      <td>0.225200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>905</td>\n",
              "      <td>0.112600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>906</td>\n",
              "      <td>0.123200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>907</td>\n",
              "      <td>0.266600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>908</td>\n",
              "      <td>0.460300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>909</td>\n",
              "      <td>0.589700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.058900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>911</td>\n",
              "      <td>0.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>912</td>\n",
              "      <td>0.167200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>913</td>\n",
              "      <td>0.260600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>914</td>\n",
              "      <td>0.131900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>915</td>\n",
              "      <td>0.180200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>916</td>\n",
              "      <td>0.563500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>917</td>\n",
              "      <td>0.349100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>918</td>\n",
              "      <td>0.506300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>919</td>\n",
              "      <td>0.312900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.111000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>921</td>\n",
              "      <td>0.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>922</td>\n",
              "      <td>0.158100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>923</td>\n",
              "      <td>0.316700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>924</td>\n",
              "      <td>0.296800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>0.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>926</td>\n",
              "      <td>0.175100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>927</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>928</td>\n",
              "      <td>0.312800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>929</td>\n",
              "      <td>0.096600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.284500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>931</td>\n",
              "      <td>0.272700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>932</td>\n",
              "      <td>0.157000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>933</td>\n",
              "      <td>0.401700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>934</td>\n",
              "      <td>0.124900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>935</td>\n",
              "      <td>0.079800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>937</td>\n",
              "      <td>0.112800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>938</td>\n",
              "      <td>0.139600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>939</td>\n",
              "      <td>0.098300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>1.140300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>941</td>\n",
              "      <td>0.129600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>942</td>\n",
              "      <td>0.173100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>943</td>\n",
              "      <td>0.400200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>944</td>\n",
              "      <td>0.120500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>945</td>\n",
              "      <td>0.074400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>946</td>\n",
              "      <td>0.391500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>947</td>\n",
              "      <td>0.171700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>948</td>\n",
              "      <td>0.424900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>949</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.083500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>951</td>\n",
              "      <td>0.510800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>952</td>\n",
              "      <td>0.116600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>953</td>\n",
              "      <td>0.178500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>954</td>\n",
              "      <td>0.081300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>955</td>\n",
              "      <td>0.258300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>956</td>\n",
              "      <td>0.353800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>957</td>\n",
              "      <td>0.310200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>958</td>\n",
              "      <td>0.098700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>959</td>\n",
              "      <td>0.124900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.075400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>961</td>\n",
              "      <td>0.233300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>962</td>\n",
              "      <td>0.547400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>963</td>\n",
              "      <td>0.125900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>964</td>\n",
              "      <td>0.204500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>965</td>\n",
              "      <td>0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>966</td>\n",
              "      <td>0.070600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>967</td>\n",
              "      <td>0.065100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>968</td>\n",
              "      <td>0.145100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>969</td>\n",
              "      <td>0.082100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.098700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>971</td>\n",
              "      <td>0.405100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>972</td>\n",
              "      <td>0.079500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>973</td>\n",
              "      <td>0.338900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>974</td>\n",
              "      <td>0.111400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>0.170400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>976</td>\n",
              "      <td>0.193200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>977</td>\n",
              "      <td>0.063400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>978</td>\n",
              "      <td>0.126500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>979</td>\n",
              "      <td>0.241300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.391300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>981</td>\n",
              "      <td>0.117800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>982</td>\n",
              "      <td>0.515500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>983</td>\n",
              "      <td>0.373300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>984</td>\n",
              "      <td>0.071400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>985</td>\n",
              "      <td>0.126300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>986</td>\n",
              "      <td>0.135500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>987</td>\n",
              "      <td>0.070200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>988</td>\n",
              "      <td>0.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>989</td>\n",
              "      <td>0.524300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>991</td>\n",
              "      <td>0.159300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>992</td>\n",
              "      <td>0.062300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>993</td>\n",
              "      <td>0.151100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>994</td>\n",
              "      <td>0.163100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>995</td>\n",
              "      <td>0.260500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>996</td>\n",
              "      <td>0.223300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>997</td>\n",
              "      <td>0.113300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>998</td>\n",
              "      <td>0.083200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>999</td>\n",
              "      <td>0.095000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.176300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1001</td>\n",
              "      <td>0.132700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1002</td>\n",
              "      <td>0.067400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1003</td>\n",
              "      <td>0.118300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1004</td>\n",
              "      <td>0.788800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1005</td>\n",
              "      <td>0.063700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1006</td>\n",
              "      <td>0.504500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1007</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1008</td>\n",
              "      <td>0.061900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1009</td>\n",
              "      <td>0.288400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.158200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1011</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1012</td>\n",
              "      <td>0.149900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1013</td>\n",
              "      <td>0.502600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1014</td>\n",
              "      <td>0.513900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1015</td>\n",
              "      <td>0.175500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1016</td>\n",
              "      <td>0.402200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1017</td>\n",
              "      <td>0.104600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1018</td>\n",
              "      <td>0.364200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1019</td>\n",
              "      <td>0.214900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.233500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1021</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1022</td>\n",
              "      <td>0.277000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1023</td>\n",
              "      <td>0.303600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1024</td>\n",
              "      <td>0.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>0.081500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1026</td>\n",
              "      <td>0.168500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1027</td>\n",
              "      <td>0.123200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1028</td>\n",
              "      <td>0.071900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1029</td>\n",
              "      <td>0.112100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1031</td>\n",
              "      <td>0.351100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1032</td>\n",
              "      <td>0.213200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1033</td>\n",
              "      <td>0.145600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1034</td>\n",
              "      <td>0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1035</td>\n",
              "      <td>0.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1036</td>\n",
              "      <td>0.104900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1037</td>\n",
              "      <td>0.185300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1038</td>\n",
              "      <td>0.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1039</td>\n",
              "      <td>0.460700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.416700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1041</td>\n",
              "      <td>0.066200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1042</td>\n",
              "      <td>0.079600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1043</td>\n",
              "      <td>0.412200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1044</td>\n",
              "      <td>0.428000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1045</td>\n",
              "      <td>0.735800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1046</td>\n",
              "      <td>0.208800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1047</td>\n",
              "      <td>0.129500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1048</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1049</td>\n",
              "      <td>0.070200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1051</td>\n",
              "      <td>0.184600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1052</td>\n",
              "      <td>0.159800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1053</td>\n",
              "      <td>0.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1054</td>\n",
              "      <td>0.068500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1055</td>\n",
              "      <td>0.101400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1056</td>\n",
              "      <td>0.125700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1057</td>\n",
              "      <td>0.266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1058</td>\n",
              "      <td>0.071800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1059</td>\n",
              "      <td>0.344200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.281700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1061</td>\n",
              "      <td>0.156400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1062</td>\n",
              "      <td>0.174500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1063</td>\n",
              "      <td>0.201500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1064</td>\n",
              "      <td>0.316100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1065</td>\n",
              "      <td>0.422000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1066</td>\n",
              "      <td>0.076900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1067</td>\n",
              "      <td>0.167500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1068</td>\n",
              "      <td>0.212900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1069</td>\n",
              "      <td>0.275800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.446000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1071</td>\n",
              "      <td>0.800900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1072</td>\n",
              "      <td>0.579500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1073</td>\n",
              "      <td>0.182200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1074</td>\n",
              "      <td>0.560900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>0.077600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1076</td>\n",
              "      <td>0.213300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1077</td>\n",
              "      <td>0.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1078</td>\n",
              "      <td>0.600900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1079</td>\n",
              "      <td>0.651500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.510200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1081</td>\n",
              "      <td>0.062300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1082</td>\n",
              "      <td>0.132900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1083</td>\n",
              "      <td>0.267600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1084</td>\n",
              "      <td>0.081300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1085</td>\n",
              "      <td>0.189700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1086</td>\n",
              "      <td>0.082400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1087</td>\n",
              "      <td>0.310100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1088</td>\n",
              "      <td>0.213400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1089</td>\n",
              "      <td>0.082500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1091</td>\n",
              "      <td>0.180900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1092</td>\n",
              "      <td>0.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1093</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1094</td>\n",
              "      <td>0.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1095</td>\n",
              "      <td>0.393700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1096</td>\n",
              "      <td>0.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1097</td>\n",
              "      <td>0.095500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1098</td>\n",
              "      <td>0.160500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1099</td>\n",
              "      <td>0.389500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.152800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1101</td>\n",
              "      <td>0.066000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1102</td>\n",
              "      <td>0.230400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1103</td>\n",
              "      <td>0.389000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1104</td>\n",
              "      <td>0.128200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1105</td>\n",
              "      <td>0.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1106</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1107</td>\n",
              "      <td>0.133100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1108</td>\n",
              "      <td>0.223900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1109</td>\n",
              "      <td>0.139900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.517300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1111</td>\n",
              "      <td>0.895500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1112</td>\n",
              "      <td>0.555100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1113</td>\n",
              "      <td>0.598500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1114</td>\n",
              "      <td>0.105400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1115</td>\n",
              "      <td>0.259400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1116</td>\n",
              "      <td>0.115900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1117</td>\n",
              "      <td>0.091900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1118</td>\n",
              "      <td>0.148000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1119</td>\n",
              "      <td>0.104000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.068300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1121</td>\n",
              "      <td>0.325600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1122</td>\n",
              "      <td>0.106800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1123</td>\n",
              "      <td>0.071300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1124</td>\n",
              "      <td>0.538300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.124000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1126</td>\n",
              "      <td>0.085600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1127</td>\n",
              "      <td>0.354200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1128</td>\n",
              "      <td>0.186400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1129</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1131</td>\n",
              "      <td>0.089400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1132</td>\n",
              "      <td>0.075600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1133</td>\n",
              "      <td>0.216300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1134</td>\n",
              "      <td>0.067700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1135</td>\n",
              "      <td>0.248500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1136</td>\n",
              "      <td>0.177200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1137</td>\n",
              "      <td>0.212200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1138</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1139</td>\n",
              "      <td>0.112400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1141</td>\n",
              "      <td>0.064600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1142</td>\n",
              "      <td>0.228800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1143</td>\n",
              "      <td>0.096700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1144</td>\n",
              "      <td>0.131300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1145</td>\n",
              "      <td>0.151600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1146</td>\n",
              "      <td>0.072500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1147</td>\n",
              "      <td>0.077600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1148</td>\n",
              "      <td>0.126100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1149</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.199200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1151</td>\n",
              "      <td>0.256400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1152</td>\n",
              "      <td>0.131500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1153</td>\n",
              "      <td>0.113700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1154</td>\n",
              "      <td>0.126900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1155</td>\n",
              "      <td>0.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1156</td>\n",
              "      <td>0.416600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1157</td>\n",
              "      <td>0.341100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1158</td>\n",
              "      <td>0.100700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1159</td>\n",
              "      <td>0.670700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.281100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1161</td>\n",
              "      <td>0.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1162</td>\n",
              "      <td>0.228700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1163</td>\n",
              "      <td>0.203100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1164</td>\n",
              "      <td>0.213300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1165</td>\n",
              "      <td>0.234000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1166</td>\n",
              "      <td>0.118600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1167</td>\n",
              "      <td>0.229100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1168</td>\n",
              "      <td>0.073700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1169</td>\n",
              "      <td>0.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.259700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1171</td>\n",
              "      <td>0.208900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1172</td>\n",
              "      <td>0.209400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1173</td>\n",
              "      <td>0.120400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1174</td>\n",
              "      <td>0.111400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>0.077800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1176</td>\n",
              "      <td>0.071000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1177</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1178</td>\n",
              "      <td>0.105600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1179</td>\n",
              "      <td>0.473200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.060200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1181</td>\n",
              "      <td>0.103200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1182</td>\n",
              "      <td>0.302900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1183</td>\n",
              "      <td>0.194100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1184</td>\n",
              "      <td>0.076800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1185</td>\n",
              "      <td>0.439600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1186</td>\n",
              "      <td>0.069300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1187</td>\n",
              "      <td>0.136100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1188</td>\n",
              "      <td>0.136300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1189</td>\n",
              "      <td>0.086000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.291300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1191</td>\n",
              "      <td>0.223400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1192</td>\n",
              "      <td>0.485300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1193</td>\n",
              "      <td>0.144700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1194</td>\n",
              "      <td>0.105000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1195</td>\n",
              "      <td>0.139200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1196</td>\n",
              "      <td>0.146600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1197</td>\n",
              "      <td>0.113200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1198</td>\n",
              "      <td>0.380800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1199</td>\n",
              "      <td>0.085500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.158700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1201</td>\n",
              "      <td>0.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1202</td>\n",
              "      <td>0.069300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1203</td>\n",
              "      <td>0.194000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1204</td>\n",
              "      <td>0.353000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1205</td>\n",
              "      <td>0.092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1206</td>\n",
              "      <td>0.447300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1207</td>\n",
              "      <td>0.233600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1208</td>\n",
              "      <td>0.113900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1209</td>\n",
              "      <td>0.077800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1211</td>\n",
              "      <td>0.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1212</td>\n",
              "      <td>0.213900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1213</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1214</td>\n",
              "      <td>0.072600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1215</td>\n",
              "      <td>0.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1216</td>\n",
              "      <td>0.145600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1217</td>\n",
              "      <td>0.169400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1218</td>\n",
              "      <td>0.119500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1219</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.204600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1221</td>\n",
              "      <td>0.109700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1222</td>\n",
              "      <td>0.118400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1223</td>\n",
              "      <td>0.182700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1224</td>\n",
              "      <td>0.209200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>0.108300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1226</td>\n",
              "      <td>0.132200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1227</td>\n",
              "      <td>0.128700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1228</td>\n",
              "      <td>0.077900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1229</td>\n",
              "      <td>0.253100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.061200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1231</td>\n",
              "      <td>0.112500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1232</td>\n",
              "      <td>0.107900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1233</td>\n",
              "      <td>0.077800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1234</td>\n",
              "      <td>0.100100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1235</td>\n",
              "      <td>0.069300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1236</td>\n",
              "      <td>0.119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1237</td>\n",
              "      <td>0.170600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1238</td>\n",
              "      <td>0.124200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1239</td>\n",
              "      <td>0.197100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.149000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1241</td>\n",
              "      <td>0.397500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1242</td>\n",
              "      <td>0.181900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1243</td>\n",
              "      <td>0.164300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1244</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1245</td>\n",
              "      <td>0.069800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1246</td>\n",
              "      <td>0.195100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1247</td>\n",
              "      <td>0.184100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1248</td>\n",
              "      <td>0.242500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1249</td>\n",
              "      <td>0.225000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.251100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1251</td>\n",
              "      <td>0.119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1252</td>\n",
              "      <td>0.092900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1253</td>\n",
              "      <td>0.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1254</td>\n",
              "      <td>0.159500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1255</td>\n",
              "      <td>0.109300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1256</td>\n",
              "      <td>0.115700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1257</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1258</td>\n",
              "      <td>0.302200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1259</td>\n",
              "      <td>0.125400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.276900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1261</td>\n",
              "      <td>0.115100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1262</td>\n",
              "      <td>0.158400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1263</td>\n",
              "      <td>0.111900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1264</td>\n",
              "      <td>0.153100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1265</td>\n",
              "      <td>0.238800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1266</td>\n",
              "      <td>0.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1267</td>\n",
              "      <td>0.074800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1268</td>\n",
              "      <td>0.096200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1269</td>\n",
              "      <td>0.085700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.081300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1271</td>\n",
              "      <td>0.090100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1272</td>\n",
              "      <td>0.124000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1273</td>\n",
              "      <td>0.126800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1274</td>\n",
              "      <td>0.091500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>0.072300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1276</td>\n",
              "      <td>0.132200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1277</td>\n",
              "      <td>0.206000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1278</td>\n",
              "      <td>0.137600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1279</td>\n",
              "      <td>0.061200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.054700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1281</td>\n",
              "      <td>0.080100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1282</td>\n",
              "      <td>0.172400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1283</td>\n",
              "      <td>0.193400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1284</td>\n",
              "      <td>0.095100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1285</td>\n",
              "      <td>0.086600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1286</td>\n",
              "      <td>0.079000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1287</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1288</td>\n",
              "      <td>0.161100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1289</td>\n",
              "      <td>0.212600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1291</td>\n",
              "      <td>0.106700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1292</td>\n",
              "      <td>0.161800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1293</td>\n",
              "      <td>0.272800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1294</td>\n",
              "      <td>0.090400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1295</td>\n",
              "      <td>0.493800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1296</td>\n",
              "      <td>0.120700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1297</td>\n",
              "      <td>0.065300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1298</td>\n",
              "      <td>0.124600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1299</td>\n",
              "      <td>0.129000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.073300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1301</td>\n",
              "      <td>0.098500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1302</td>\n",
              "      <td>0.147300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1303</td>\n",
              "      <td>0.159600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1304</td>\n",
              "      <td>0.132600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1305</td>\n",
              "      <td>0.444300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1306</td>\n",
              "      <td>0.224400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1307</td>\n",
              "      <td>0.521100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1308</td>\n",
              "      <td>0.172800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1309</td>\n",
              "      <td>0.073200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.176800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1311</td>\n",
              "      <td>0.246500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1312</td>\n",
              "      <td>0.188900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1313</td>\n",
              "      <td>0.623400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1314</td>\n",
              "      <td>0.161200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1315</td>\n",
              "      <td>0.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1316</td>\n",
              "      <td>0.101100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1317</td>\n",
              "      <td>0.147000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1318</td>\n",
              "      <td>0.225100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1319</td>\n",
              "      <td>0.112300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.153900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1321</td>\n",
              "      <td>0.096200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1322</td>\n",
              "      <td>0.090500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1323</td>\n",
              "      <td>0.071800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1324</td>\n",
              "      <td>0.478100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>0.280800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1326</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1327</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1328</td>\n",
              "      <td>0.122200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1329</td>\n",
              "      <td>0.105300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.065800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1331</td>\n",
              "      <td>0.072000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1332</td>\n",
              "      <td>0.177900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1333</td>\n",
              "      <td>0.200100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1334</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1335</td>\n",
              "      <td>0.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1336</td>\n",
              "      <td>0.206800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1337</td>\n",
              "      <td>0.736500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1338</td>\n",
              "      <td>0.073100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1339</td>\n",
              "      <td>0.314500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.231100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1341</td>\n",
              "      <td>0.176700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1342</td>\n",
              "      <td>0.141000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1343</td>\n",
              "      <td>0.108300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1344</td>\n",
              "      <td>0.181900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1345</td>\n",
              "      <td>0.061800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1346</td>\n",
              "      <td>0.161100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1347</td>\n",
              "      <td>0.192100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1348</td>\n",
              "      <td>0.114200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1349</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.236800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1351</td>\n",
              "      <td>0.071200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1352</td>\n",
              "      <td>0.084600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1353</td>\n",
              "      <td>0.086100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1354</td>\n",
              "      <td>0.158300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1355</td>\n",
              "      <td>0.081800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1356</td>\n",
              "      <td>0.240900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1357</td>\n",
              "      <td>0.169600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1358</td>\n",
              "      <td>0.442400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1359</td>\n",
              "      <td>0.146400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.188900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1361</td>\n",
              "      <td>0.171900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1362</td>\n",
              "      <td>0.278200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1363</td>\n",
              "      <td>0.136900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1364</td>\n",
              "      <td>0.101300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1365</td>\n",
              "      <td>0.073300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1366</td>\n",
              "      <td>0.115000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1367</td>\n",
              "      <td>0.273700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1368</td>\n",
              "      <td>0.196800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1369</td>\n",
              "      <td>0.101400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.392500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1371</td>\n",
              "      <td>0.287200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1372</td>\n",
              "      <td>0.101500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1373</td>\n",
              "      <td>0.122000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1374</td>\n",
              "      <td>0.069300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>0.220800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1376</td>\n",
              "      <td>0.060500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1377</td>\n",
              "      <td>0.103300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1378</td>\n",
              "      <td>0.160400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1379</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.112700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1381</td>\n",
              "      <td>0.271600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1382</td>\n",
              "      <td>0.236100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1383</td>\n",
              "      <td>0.393400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1384</td>\n",
              "      <td>0.073100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1385</td>\n",
              "      <td>0.155600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1386</td>\n",
              "      <td>0.102100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1387</td>\n",
              "      <td>0.082700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1388</td>\n",
              "      <td>0.139000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1389</td>\n",
              "      <td>0.058600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.350800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1391</td>\n",
              "      <td>0.055800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1392</td>\n",
              "      <td>0.309600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1393</td>\n",
              "      <td>0.346700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1394</td>\n",
              "      <td>0.097400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1395</td>\n",
              "      <td>0.124800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1396</td>\n",
              "      <td>0.072700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1397</td>\n",
              "      <td>0.126900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1398</td>\n",
              "      <td>0.194700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1399</td>\n",
              "      <td>0.082100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.056300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1401</td>\n",
              "      <td>0.419000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1402</td>\n",
              "      <td>0.097300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1403</td>\n",
              "      <td>0.074100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.119500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1405</td>\n",
              "      <td>0.205700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1406</td>\n",
              "      <td>0.066000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1407</td>\n",
              "      <td>0.097900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1408</td>\n",
              "      <td>0.122500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1409</td>\n",
              "      <td>0.135600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.505400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1411</td>\n",
              "      <td>0.111200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1412</td>\n",
              "      <td>0.063200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1413</td>\n",
              "      <td>0.177100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1414</td>\n",
              "      <td>0.306300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1415</td>\n",
              "      <td>0.150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1416</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1417</td>\n",
              "      <td>0.070300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1418</td>\n",
              "      <td>0.120300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1419</td>\n",
              "      <td>0.077800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.152100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1421</td>\n",
              "      <td>0.097300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1422</td>\n",
              "      <td>0.063400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1423</td>\n",
              "      <td>0.333600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1424</td>\n",
              "      <td>0.230700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>0.128800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1426</td>\n",
              "      <td>0.105500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1427</td>\n",
              "      <td>0.107900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1428</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1429</td>\n",
              "      <td>0.208200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.088600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1431</td>\n",
              "      <td>0.233200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1432</td>\n",
              "      <td>0.319100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1433</td>\n",
              "      <td>0.106800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1434</td>\n",
              "      <td>0.068100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1435</td>\n",
              "      <td>0.124100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1436</td>\n",
              "      <td>0.338600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1437</td>\n",
              "      <td>0.136800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1438</td>\n",
              "      <td>0.140500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1439</td>\n",
              "      <td>0.213300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1441</td>\n",
              "      <td>0.188100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1442</td>\n",
              "      <td>0.109700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1443</td>\n",
              "      <td>0.197400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1444</td>\n",
              "      <td>0.204200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1445</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1446</td>\n",
              "      <td>0.207900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1447</td>\n",
              "      <td>0.074900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1448</td>\n",
              "      <td>0.208800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1449</td>\n",
              "      <td>0.127400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.297600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1451</td>\n",
              "      <td>0.213800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1452</td>\n",
              "      <td>0.073800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1453</td>\n",
              "      <td>0.491900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1454</td>\n",
              "      <td>0.271600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1455</td>\n",
              "      <td>0.106200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1456</td>\n",
              "      <td>0.073800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1457</td>\n",
              "      <td>0.412800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1458</td>\n",
              "      <td>0.162900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1459</td>\n",
              "      <td>0.118000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1461</td>\n",
              "      <td>0.210500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1462</td>\n",
              "      <td>0.154500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1463</td>\n",
              "      <td>0.091400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1464</td>\n",
              "      <td>0.199100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1465</td>\n",
              "      <td>0.284300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1466</td>\n",
              "      <td>0.111800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1467</td>\n",
              "      <td>0.197200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1468</td>\n",
              "      <td>0.066600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1469</td>\n",
              "      <td>0.127800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.201500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1471</td>\n",
              "      <td>0.070500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1472</td>\n",
              "      <td>0.167100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1473</td>\n",
              "      <td>0.109000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1474</td>\n",
              "      <td>0.156000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>0.220300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1476</td>\n",
              "      <td>0.090900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1477</td>\n",
              "      <td>0.262700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1478</td>\n",
              "      <td>0.098800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1479</td>\n",
              "      <td>0.069500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.411400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1481</td>\n",
              "      <td>0.273500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1482</td>\n",
              "      <td>0.101100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1483</td>\n",
              "      <td>0.107900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1484</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1485</td>\n",
              "      <td>0.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1486</td>\n",
              "      <td>0.069800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1487</td>\n",
              "      <td>0.197300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1488</td>\n",
              "      <td>0.172300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1489</td>\n",
              "      <td>0.300200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.154600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1491</td>\n",
              "      <td>0.122600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1492</td>\n",
              "      <td>0.071000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1493</td>\n",
              "      <td>0.219200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1494</td>\n",
              "      <td>0.075600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1495</td>\n",
              "      <td>0.112700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1496</td>\n",
              "      <td>0.362900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1497</td>\n",
              "      <td>0.125200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1498</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1499</td>\n",
              "      <td>0.109900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1501</td>\n",
              "      <td>0.144900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1502</td>\n",
              "      <td>0.480500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1503</td>\n",
              "      <td>0.126400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1504</td>\n",
              "      <td>0.056100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1505</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1506</td>\n",
              "      <td>0.067800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1507</td>\n",
              "      <td>0.102900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1508</td>\n",
              "      <td>0.134400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1509</td>\n",
              "      <td>0.126500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.152800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1511</td>\n",
              "      <td>0.125900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1512</td>\n",
              "      <td>0.127600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1513</td>\n",
              "      <td>0.173200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1514</td>\n",
              "      <td>0.116700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1515</td>\n",
              "      <td>0.139500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1516</td>\n",
              "      <td>0.169000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1517</td>\n",
              "      <td>0.101100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1518</td>\n",
              "      <td>0.455100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1519</td>\n",
              "      <td>0.116900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.069000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1521</td>\n",
              "      <td>0.292700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1522</td>\n",
              "      <td>0.105100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1523</td>\n",
              "      <td>0.051600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1524</td>\n",
              "      <td>0.144500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>0.371200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1526</td>\n",
              "      <td>0.066100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1527</td>\n",
              "      <td>0.140800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1528</td>\n",
              "      <td>0.071400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1529</td>\n",
              "      <td>0.075100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.203800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1531</td>\n",
              "      <td>0.103800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1532</td>\n",
              "      <td>0.180500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1533</td>\n",
              "      <td>0.365800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1534</td>\n",
              "      <td>0.074200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1535</td>\n",
              "      <td>0.247300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1536</td>\n",
              "      <td>0.072200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1537</td>\n",
              "      <td>0.332500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1538</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1539</td>\n",
              "      <td>0.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1541</td>\n",
              "      <td>0.263500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1542</td>\n",
              "      <td>0.072600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1543</td>\n",
              "      <td>0.090100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1544</td>\n",
              "      <td>0.230300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1545</td>\n",
              "      <td>0.105600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1546</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1547</td>\n",
              "      <td>0.134800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1548</td>\n",
              "      <td>0.219800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1549</td>\n",
              "      <td>0.168400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.141700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1551</td>\n",
              "      <td>0.353600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1552</td>\n",
              "      <td>0.147900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1553</td>\n",
              "      <td>0.073100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1554</td>\n",
              "      <td>0.200200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1555</td>\n",
              "      <td>0.066200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1556</td>\n",
              "      <td>0.133900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1557</td>\n",
              "      <td>0.069200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1558</td>\n",
              "      <td>0.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1559</td>\n",
              "      <td>0.136700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.080400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1561</td>\n",
              "      <td>0.166500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1562</td>\n",
              "      <td>0.076800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1563</td>\n",
              "      <td>0.307300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1564</td>\n",
              "      <td>0.114600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1565</td>\n",
              "      <td>0.153900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1566</td>\n",
              "      <td>0.298900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1567</td>\n",
              "      <td>0.163000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1568</td>\n",
              "      <td>0.101400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1569</td>\n",
              "      <td>0.137600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.182000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1571</td>\n",
              "      <td>0.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1572</td>\n",
              "      <td>0.081100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1573</td>\n",
              "      <td>0.116500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1574</td>\n",
              "      <td>0.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>0.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1576</td>\n",
              "      <td>0.278600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1577</td>\n",
              "      <td>0.106100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1578</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1579</td>\n",
              "      <td>0.090800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.231100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1581</td>\n",
              "      <td>0.106700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1582</td>\n",
              "      <td>0.203500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1583</td>\n",
              "      <td>0.359400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1584</td>\n",
              "      <td>0.122200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1585</td>\n",
              "      <td>0.270500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1586</td>\n",
              "      <td>0.130800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1587</td>\n",
              "      <td>0.071200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1588</td>\n",
              "      <td>0.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1589</td>\n",
              "      <td>0.306500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.069200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1591</td>\n",
              "      <td>0.230400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1592</td>\n",
              "      <td>0.819400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1593</td>\n",
              "      <td>0.175600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1594</td>\n",
              "      <td>0.157500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1595</td>\n",
              "      <td>0.325900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1596</td>\n",
              "      <td>0.118800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1597</td>\n",
              "      <td>0.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1598</td>\n",
              "      <td>0.106300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1599</td>\n",
              "      <td>0.059800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.090200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1601</td>\n",
              "      <td>0.133400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1602</td>\n",
              "      <td>0.068300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1603</td>\n",
              "      <td>0.184000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1604</td>\n",
              "      <td>0.799500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1605</td>\n",
              "      <td>0.343300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1606</td>\n",
              "      <td>0.261600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1607</td>\n",
              "      <td>0.360300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1608</td>\n",
              "      <td>0.080600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1609</td>\n",
              "      <td>0.105900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.236100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1611</td>\n",
              "      <td>0.119500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1612</td>\n",
              "      <td>0.102600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1613</td>\n",
              "      <td>0.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1614</td>\n",
              "      <td>0.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1615</td>\n",
              "      <td>0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1616</td>\n",
              "      <td>0.504300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1617</td>\n",
              "      <td>0.259600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1618</td>\n",
              "      <td>0.363200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1619</td>\n",
              "      <td>0.249000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.068600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1621</td>\n",
              "      <td>0.114600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1622</td>\n",
              "      <td>0.079000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1623</td>\n",
              "      <td>0.166300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1624</td>\n",
              "      <td>0.127300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>0.120600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1626</td>\n",
              "      <td>0.315300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1627</td>\n",
              "      <td>0.092300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1628</td>\n",
              "      <td>0.134100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1629</td>\n",
              "      <td>0.093100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.666300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1631</td>\n",
              "      <td>0.238200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1632</td>\n",
              "      <td>0.108200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1633</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1634</td>\n",
              "      <td>0.117200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1635</td>\n",
              "      <td>0.084500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1636</td>\n",
              "      <td>0.204600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1637</td>\n",
              "      <td>0.227900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.201200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1639</td>\n",
              "      <td>0.522300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.150200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1641</td>\n",
              "      <td>0.114600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1642</td>\n",
              "      <td>0.131200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1643</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1644</td>\n",
              "      <td>0.115500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1645</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1646</td>\n",
              "      <td>0.190400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1647</td>\n",
              "      <td>0.316500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1648</td>\n",
              "      <td>0.117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1649</td>\n",
              "      <td>0.071900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.163400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1651</td>\n",
              "      <td>0.115400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1652</td>\n",
              "      <td>0.090400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1653</td>\n",
              "      <td>0.178500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1654</td>\n",
              "      <td>0.137400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1655</td>\n",
              "      <td>0.068700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1656</td>\n",
              "      <td>0.243400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1657</td>\n",
              "      <td>0.103300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1658</td>\n",
              "      <td>0.178100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1659</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.099600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1661</td>\n",
              "      <td>0.113600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1662</td>\n",
              "      <td>0.210700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1663</td>\n",
              "      <td>0.067700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1664</td>\n",
              "      <td>0.264500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1665</td>\n",
              "      <td>0.120200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1666</td>\n",
              "      <td>0.315600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1667</td>\n",
              "      <td>0.381800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1668</td>\n",
              "      <td>0.073700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1669</td>\n",
              "      <td>0.066900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>0.081000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1671</td>\n",
              "      <td>0.112700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1672</td>\n",
              "      <td>0.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1673</td>\n",
              "      <td>0.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1674</td>\n",
              "      <td>0.072300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>0.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1676</td>\n",
              "      <td>0.069900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1677</td>\n",
              "      <td>0.097800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1678</td>\n",
              "      <td>0.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1679</td>\n",
              "      <td>0.105900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.086400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1681</td>\n",
              "      <td>0.186200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1682</td>\n",
              "      <td>0.100200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1683</td>\n",
              "      <td>0.089400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1684</td>\n",
              "      <td>0.158400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1685</td>\n",
              "      <td>0.211700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1686</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1687</td>\n",
              "      <td>0.088500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1688</td>\n",
              "      <td>0.072500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1689</td>\n",
              "      <td>0.071500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.088200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1691</td>\n",
              "      <td>0.149600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1692</td>\n",
              "      <td>0.161000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1693</td>\n",
              "      <td>0.081100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1694</td>\n",
              "      <td>0.063100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1695</td>\n",
              "      <td>0.151700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1696</td>\n",
              "      <td>0.071800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1697</td>\n",
              "      <td>0.085500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1698</td>\n",
              "      <td>0.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1699</td>\n",
              "      <td>0.086700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.130500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1701</td>\n",
              "      <td>0.084800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1702</td>\n",
              "      <td>0.091300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1703</td>\n",
              "      <td>0.062300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1704</td>\n",
              "      <td>0.159100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1705</td>\n",
              "      <td>0.116300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1706</td>\n",
              "      <td>0.063300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1707</td>\n",
              "      <td>0.125400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1708</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1709</td>\n",
              "      <td>0.500200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>0.084600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1711</td>\n",
              "      <td>0.086300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1712</td>\n",
              "      <td>0.166500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1713</td>\n",
              "      <td>0.079900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1714</td>\n",
              "      <td>0.085100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1715</td>\n",
              "      <td>0.085500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1716</td>\n",
              "      <td>0.085300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1717</td>\n",
              "      <td>0.134300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1718</td>\n",
              "      <td>0.093500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1719</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>0.089900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1721</td>\n",
              "      <td>0.116600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1722</td>\n",
              "      <td>0.079300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1723</td>\n",
              "      <td>0.104000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1724</td>\n",
              "      <td>0.070200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>0.097800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1726</td>\n",
              "      <td>0.068600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1727</td>\n",
              "      <td>0.219500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1728</td>\n",
              "      <td>0.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1729</td>\n",
              "      <td>0.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>0.082000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1731</td>\n",
              "      <td>0.112800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1732</td>\n",
              "      <td>0.304400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1733</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1734</td>\n",
              "      <td>0.166700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1735</td>\n",
              "      <td>0.064300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1736</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1737</td>\n",
              "      <td>0.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1738</td>\n",
              "      <td>0.141100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1739</td>\n",
              "      <td>0.107100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>0.083300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1741</td>\n",
              "      <td>0.161800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1742</td>\n",
              "      <td>0.092600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1743</td>\n",
              "      <td>0.103900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1744</td>\n",
              "      <td>0.109700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1745</td>\n",
              "      <td>0.100500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1746</td>\n",
              "      <td>0.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1747</td>\n",
              "      <td>0.090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1748</td>\n",
              "      <td>0.073000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1749</td>\n",
              "      <td>0.123500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.103100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1751</td>\n",
              "      <td>0.168400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1752</td>\n",
              "      <td>0.115100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1753</td>\n",
              "      <td>0.086100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1754</td>\n",
              "      <td>0.131100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1755</td>\n",
              "      <td>0.137600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1756</td>\n",
              "      <td>0.059900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1757</td>\n",
              "      <td>0.066700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1758</td>\n",
              "      <td>0.080600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1759</td>\n",
              "      <td>0.060500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>0.061600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1761</td>\n",
              "      <td>0.109100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1762</td>\n",
              "      <td>0.116900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1763</td>\n",
              "      <td>0.093600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1764</td>\n",
              "      <td>0.489600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1765</td>\n",
              "      <td>0.085700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1766</td>\n",
              "      <td>0.092500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1767</td>\n",
              "      <td>0.092300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1768</td>\n",
              "      <td>0.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1769</td>\n",
              "      <td>0.091500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1771</td>\n",
              "      <td>0.109500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1772</td>\n",
              "      <td>0.055800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1773</td>\n",
              "      <td>0.063800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1774</td>\n",
              "      <td>0.099400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>0.092700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1776</td>\n",
              "      <td>0.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1777</td>\n",
              "      <td>0.085800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1778</td>\n",
              "      <td>0.063200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1779</td>\n",
              "      <td>0.112300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>0.187000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1781</td>\n",
              "      <td>0.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1782</td>\n",
              "      <td>0.106900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1783</td>\n",
              "      <td>0.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1784</td>\n",
              "      <td>0.069300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1785</td>\n",
              "      <td>0.134800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1786</td>\n",
              "      <td>0.058300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1787</td>\n",
              "      <td>0.091300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1788</td>\n",
              "      <td>0.069400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1789</td>\n",
              "      <td>0.054900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>0.068300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1791</td>\n",
              "      <td>0.080100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1792</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1793</td>\n",
              "      <td>0.171800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1794</td>\n",
              "      <td>0.106500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1795</td>\n",
              "      <td>0.107900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1796</td>\n",
              "      <td>0.095700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1797</td>\n",
              "      <td>0.101200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1798</td>\n",
              "      <td>0.067700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1799</td>\n",
              "      <td>0.082600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.141200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1801</td>\n",
              "      <td>0.109200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1802</td>\n",
              "      <td>0.110900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1803</td>\n",
              "      <td>0.127300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1804</td>\n",
              "      <td>0.233900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1805</td>\n",
              "      <td>0.088300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1806</td>\n",
              "      <td>0.127900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1807</td>\n",
              "      <td>0.119800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1808</td>\n",
              "      <td>0.098300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1809</td>\n",
              "      <td>0.090600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>0.072600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1811</td>\n",
              "      <td>0.071200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1812</td>\n",
              "      <td>0.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1813</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1814</td>\n",
              "      <td>0.108000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1815</td>\n",
              "      <td>0.072700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1816</td>\n",
              "      <td>0.143800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1817</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1818</td>\n",
              "      <td>0.122200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1819</td>\n",
              "      <td>0.112300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.106800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1821</td>\n",
              "      <td>0.111100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1822</td>\n",
              "      <td>0.081900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1823</td>\n",
              "      <td>0.111100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1824</td>\n",
              "      <td>0.099900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>0.068900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1826</td>\n",
              "      <td>0.078300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1827</td>\n",
              "      <td>0.118500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1828</td>\n",
              "      <td>0.106100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1829</td>\n",
              "      <td>0.123600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>0.107800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1831</td>\n",
              "      <td>0.073600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1832</td>\n",
              "      <td>0.086700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1833</td>\n",
              "      <td>0.199400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1834</td>\n",
              "      <td>0.122200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1835</td>\n",
              "      <td>0.082700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1836</td>\n",
              "      <td>0.062900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1837</td>\n",
              "      <td>0.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1838</td>\n",
              "      <td>0.083000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1839</td>\n",
              "      <td>0.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>0.068500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1841</td>\n",
              "      <td>0.129900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1842</td>\n",
              "      <td>0.104200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1843</td>\n",
              "      <td>0.066700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1844</td>\n",
              "      <td>0.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1845</td>\n",
              "      <td>0.071800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1846</td>\n",
              "      <td>0.074400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1847</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1848</td>\n",
              "      <td>0.123000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1849</td>\n",
              "      <td>0.089300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.066900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1851</td>\n",
              "      <td>0.058600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1852</td>\n",
              "      <td>0.102600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1853</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1854</td>\n",
              "      <td>0.117700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1855</td>\n",
              "      <td>0.089100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1856</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1857</td>\n",
              "      <td>0.164700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1858</td>\n",
              "      <td>0.075800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1859</td>\n",
              "      <td>0.128800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1861</td>\n",
              "      <td>0.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1862</td>\n",
              "      <td>0.112200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1863</td>\n",
              "      <td>0.310700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1864</td>\n",
              "      <td>0.097800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1865</td>\n",
              "      <td>0.091800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1866</td>\n",
              "      <td>0.062200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1867</td>\n",
              "      <td>0.108500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1868</td>\n",
              "      <td>0.089400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1869</td>\n",
              "      <td>0.102300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>0.119100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1871</td>\n",
              "      <td>0.073700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.090500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1873</td>\n",
              "      <td>0.149500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1874</td>\n",
              "      <td>0.093400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>0.095100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1876</td>\n",
              "      <td>0.126600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1877</td>\n",
              "      <td>0.089100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1878</td>\n",
              "      <td>0.133100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1879</td>\n",
              "      <td>0.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>0.127200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1881</td>\n",
              "      <td>0.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1882</td>\n",
              "      <td>0.192000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1883</td>\n",
              "      <td>0.083300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1884</td>\n",
              "      <td>0.058200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1885</td>\n",
              "      <td>0.068300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1886</td>\n",
              "      <td>0.278100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1887</td>\n",
              "      <td>0.090500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1888</td>\n",
              "      <td>0.126000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1889</td>\n",
              "      <td>0.102200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>0.096600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1891</td>\n",
              "      <td>0.100800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1892</td>\n",
              "      <td>0.103200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1893</td>\n",
              "      <td>0.108100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1894</td>\n",
              "      <td>0.059600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1895</td>\n",
              "      <td>0.206600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1896</td>\n",
              "      <td>0.106800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1897</td>\n",
              "      <td>0.124400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1898</td>\n",
              "      <td>0.079700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1899</td>\n",
              "      <td>0.068100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.180600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1901</td>\n",
              "      <td>0.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1902</td>\n",
              "      <td>0.087300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1903</td>\n",
              "      <td>0.076500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1904</td>\n",
              "      <td>0.097500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1905</td>\n",
              "      <td>0.060400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1906</td>\n",
              "      <td>0.119700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1907</td>\n",
              "      <td>0.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1908</td>\n",
              "      <td>0.098900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1909</td>\n",
              "      <td>0.091400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>0.091500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1911</td>\n",
              "      <td>0.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1912</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1913</td>\n",
              "      <td>0.087200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1914</td>\n",
              "      <td>0.084300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1915</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1916</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1917</td>\n",
              "      <td>0.115600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1918</td>\n",
              "      <td>0.132900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1919</td>\n",
              "      <td>0.112700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>0.331900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1921</td>\n",
              "      <td>0.162800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1922</td>\n",
              "      <td>0.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1923</td>\n",
              "      <td>0.178200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1924</td>\n",
              "      <td>0.075300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>0.117700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1926</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1927</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1928</td>\n",
              "      <td>0.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1929</td>\n",
              "      <td>0.063800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>0.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1931</td>\n",
              "      <td>0.077900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1932</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1933</td>\n",
              "      <td>0.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1934</td>\n",
              "      <td>0.135300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1935</td>\n",
              "      <td>0.307800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1936</td>\n",
              "      <td>0.068000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1937</td>\n",
              "      <td>0.065100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1938</td>\n",
              "      <td>0.087100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1939</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>0.168900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1941</td>\n",
              "      <td>0.092500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1942</td>\n",
              "      <td>0.227100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1943</td>\n",
              "      <td>0.102000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1944</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1945</td>\n",
              "      <td>0.120800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1946</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1947</td>\n",
              "      <td>0.071900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1948</td>\n",
              "      <td>0.136400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1949</td>\n",
              "      <td>0.087500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.118800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1951</td>\n",
              "      <td>0.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1952</td>\n",
              "      <td>0.071500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1953</td>\n",
              "      <td>0.229800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1954</td>\n",
              "      <td>0.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1955</td>\n",
              "      <td>0.135800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1956</td>\n",
              "      <td>0.177500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1957</td>\n",
              "      <td>0.088400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1958</td>\n",
              "      <td>0.197900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1959</td>\n",
              "      <td>0.117900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>0.086700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1961</td>\n",
              "      <td>0.162300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1962</td>\n",
              "      <td>0.102400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1963</td>\n",
              "      <td>0.094800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1964</td>\n",
              "      <td>0.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1965</td>\n",
              "      <td>0.072300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1966</td>\n",
              "      <td>0.149200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1967</td>\n",
              "      <td>0.096000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1968</td>\n",
              "      <td>0.122300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1969</td>\n",
              "      <td>0.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>0.105500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1971</td>\n",
              "      <td>0.062700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1972</td>\n",
              "      <td>0.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1973</td>\n",
              "      <td>0.087300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1974</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>0.074400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1976</td>\n",
              "      <td>0.122200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1977</td>\n",
              "      <td>0.107500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1978</td>\n",
              "      <td>0.101200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1979</td>\n",
              "      <td>0.070500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>0.090500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1981</td>\n",
              "      <td>0.121300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1982</td>\n",
              "      <td>0.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1983</td>\n",
              "      <td>0.082700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1984</td>\n",
              "      <td>0.097400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1985</td>\n",
              "      <td>0.111100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1986</td>\n",
              "      <td>0.074500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1987</td>\n",
              "      <td>0.132600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1988</td>\n",
              "      <td>0.081200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1989</td>\n",
              "      <td>0.095100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>0.089000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1991</td>\n",
              "      <td>0.099100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1992</td>\n",
              "      <td>0.129700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1993</td>\n",
              "      <td>0.142700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1994</td>\n",
              "      <td>0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1995</td>\n",
              "      <td>0.091700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1996</td>\n",
              "      <td>0.126500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1997</td>\n",
              "      <td>0.085900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1998</td>\n",
              "      <td>0.126500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1999</td>\n",
              "      <td>0.297100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.125200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2001</td>\n",
              "      <td>0.072600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2002</td>\n",
              "      <td>0.055200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2003</td>\n",
              "      <td>0.080300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2004</td>\n",
              "      <td>0.149800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2005</td>\n",
              "      <td>0.083100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2006</td>\n",
              "      <td>0.069200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2007</td>\n",
              "      <td>0.201700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2008</td>\n",
              "      <td>0.062700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2009</td>\n",
              "      <td>0.111900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>0.099000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2011</td>\n",
              "      <td>0.076600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2012</td>\n",
              "      <td>0.076500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2013</td>\n",
              "      <td>0.063500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2014</td>\n",
              "      <td>0.199700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2015</td>\n",
              "      <td>0.066100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2016</td>\n",
              "      <td>0.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2017</td>\n",
              "      <td>0.098300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2018</td>\n",
              "      <td>0.209800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2019</td>\n",
              "      <td>0.086900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>0.123700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2021</td>\n",
              "      <td>0.150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2022</td>\n",
              "      <td>0.104300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2023</td>\n",
              "      <td>0.076800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2024</td>\n",
              "      <td>0.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>0.081900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2026</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2027</td>\n",
              "      <td>0.145400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2028</td>\n",
              "      <td>0.078200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2029</td>\n",
              "      <td>0.156300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>0.088000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2031</td>\n",
              "      <td>0.169900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2032</td>\n",
              "      <td>0.084100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2033</td>\n",
              "      <td>0.097100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2034</td>\n",
              "      <td>0.094000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2035</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2036</td>\n",
              "      <td>0.066100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2037</td>\n",
              "      <td>0.069000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2038</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2039</td>\n",
              "      <td>0.178300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>0.125100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2041</td>\n",
              "      <td>0.100100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2042</td>\n",
              "      <td>0.248500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2043</td>\n",
              "      <td>0.295700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2044</td>\n",
              "      <td>0.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2045</td>\n",
              "      <td>0.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2046</td>\n",
              "      <td>0.081800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2047</td>\n",
              "      <td>0.072000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2048</td>\n",
              "      <td>0.061300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2049</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.065100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2051</td>\n",
              "      <td>0.135600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2052</td>\n",
              "      <td>0.132800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2053</td>\n",
              "      <td>0.147800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2054</td>\n",
              "      <td>0.074900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2055</td>\n",
              "      <td>0.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2056</td>\n",
              "      <td>0.060100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2057</td>\n",
              "      <td>0.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2058</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2059</td>\n",
              "      <td>0.267400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>0.085400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2061</td>\n",
              "      <td>0.074200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2062</td>\n",
              "      <td>0.103300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2063</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2064</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2065</td>\n",
              "      <td>0.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2066</td>\n",
              "      <td>0.102500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2067</td>\n",
              "      <td>0.104000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2068</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2069</td>\n",
              "      <td>0.149200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2070</td>\n",
              "      <td>0.076900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2071</td>\n",
              "      <td>0.091700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2072</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2073</td>\n",
              "      <td>0.124200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2074</td>\n",
              "      <td>0.120600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>0.297400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2076</td>\n",
              "      <td>0.127300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2077</td>\n",
              "      <td>0.087400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2078</td>\n",
              "      <td>0.082500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2079</td>\n",
              "      <td>0.089000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>0.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2081</td>\n",
              "      <td>0.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2082</td>\n",
              "      <td>0.172900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2083</td>\n",
              "      <td>0.076900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2084</td>\n",
              "      <td>0.138700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2085</td>\n",
              "      <td>0.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2086</td>\n",
              "      <td>0.151900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2087</td>\n",
              "      <td>0.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2088</td>\n",
              "      <td>0.068200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2089</td>\n",
              "      <td>0.115900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2090</td>\n",
              "      <td>0.127700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2091</td>\n",
              "      <td>0.064100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2092</td>\n",
              "      <td>0.088200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2093</td>\n",
              "      <td>0.255200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2094</td>\n",
              "      <td>0.097100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2095</td>\n",
              "      <td>0.142500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2096</td>\n",
              "      <td>0.186400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2097</td>\n",
              "      <td>0.107000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2098</td>\n",
              "      <td>0.069900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2099</td>\n",
              "      <td>0.126900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.067400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2101</td>\n",
              "      <td>0.117900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2102</td>\n",
              "      <td>0.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2103</td>\n",
              "      <td>0.108500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2104</td>\n",
              "      <td>0.133900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2105</td>\n",
              "      <td>0.091500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.064100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2107</td>\n",
              "      <td>0.192200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2108</td>\n",
              "      <td>0.134300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2109</td>\n",
              "      <td>0.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2110</td>\n",
              "      <td>0.088000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2111</td>\n",
              "      <td>0.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2112</td>\n",
              "      <td>0.435000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2113</td>\n",
              "      <td>0.103200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2114</td>\n",
              "      <td>0.227700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2115</td>\n",
              "      <td>0.102300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2116</td>\n",
              "      <td>0.111600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2117</td>\n",
              "      <td>0.063500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2118</td>\n",
              "      <td>0.080400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2119</td>\n",
              "      <td>0.078100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>0.121500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2121</td>\n",
              "      <td>0.094900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2122</td>\n",
              "      <td>0.069700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2123</td>\n",
              "      <td>0.085700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2124</td>\n",
              "      <td>0.225900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>0.060300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2126</td>\n",
              "      <td>0.087900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2127</td>\n",
              "      <td>0.068700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2128</td>\n",
              "      <td>0.088100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2129</td>\n",
              "      <td>0.254300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2130</td>\n",
              "      <td>0.096100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2131</td>\n",
              "      <td>0.159200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2132</td>\n",
              "      <td>0.127000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2133</td>\n",
              "      <td>0.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2134</td>\n",
              "      <td>0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2135</td>\n",
              "      <td>0.095100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2136</td>\n",
              "      <td>0.101500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2137</td>\n",
              "      <td>0.083600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2138</td>\n",
              "      <td>0.131700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2139</td>\n",
              "      <td>0.082600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>0.102800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2141</td>\n",
              "      <td>0.078100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2142</td>\n",
              "      <td>0.207700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2143</td>\n",
              "      <td>0.104200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2144</td>\n",
              "      <td>0.080300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2145</td>\n",
              "      <td>0.100900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2146</td>\n",
              "      <td>0.114900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2147</td>\n",
              "      <td>0.062400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2148</td>\n",
              "      <td>0.106200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2149</td>\n",
              "      <td>0.093900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.116500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2151</td>\n",
              "      <td>0.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2152</td>\n",
              "      <td>0.076700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2153</td>\n",
              "      <td>0.192700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2154</td>\n",
              "      <td>0.081600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2155</td>\n",
              "      <td>0.107500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2156</td>\n",
              "      <td>0.072600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2157</td>\n",
              "      <td>0.209900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2158</td>\n",
              "      <td>0.280800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2159</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>0.105900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2161</td>\n",
              "      <td>0.058800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2162</td>\n",
              "      <td>0.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2163</td>\n",
              "      <td>0.069500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2164</td>\n",
              "      <td>0.097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2165</td>\n",
              "      <td>0.090500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2166</td>\n",
              "      <td>0.161100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2167</td>\n",
              "      <td>0.076900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2168</td>\n",
              "      <td>0.195800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2169</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2170</td>\n",
              "      <td>0.117900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2171</td>\n",
              "      <td>0.098400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2172</td>\n",
              "      <td>0.095700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2173</td>\n",
              "      <td>0.072700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2174</td>\n",
              "      <td>0.080700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>0.289900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2176</td>\n",
              "      <td>0.105100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2177</td>\n",
              "      <td>0.108400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2178</td>\n",
              "      <td>0.133400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2179</td>\n",
              "      <td>0.066200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>0.125300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2181</td>\n",
              "      <td>0.094200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2182</td>\n",
              "      <td>0.073200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2183</td>\n",
              "      <td>0.083700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2184</td>\n",
              "      <td>0.145500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2185</td>\n",
              "      <td>0.117100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2186</td>\n",
              "      <td>0.093600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2187</td>\n",
              "      <td>0.080500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2188</td>\n",
              "      <td>0.108900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2189</td>\n",
              "      <td>0.240100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2190</td>\n",
              "      <td>0.085000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2191</td>\n",
              "      <td>0.133800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2192</td>\n",
              "      <td>0.132400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2193</td>\n",
              "      <td>0.060400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2194</td>\n",
              "      <td>0.115100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2195</td>\n",
              "      <td>0.061500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2196</td>\n",
              "      <td>0.064100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2197</td>\n",
              "      <td>0.099300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2198</td>\n",
              "      <td>0.090100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2199</td>\n",
              "      <td>0.091200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.120100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2201</td>\n",
              "      <td>0.124600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2202</td>\n",
              "      <td>0.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2203</td>\n",
              "      <td>0.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2204</td>\n",
              "      <td>0.077800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2205</td>\n",
              "      <td>0.149400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2206</td>\n",
              "      <td>0.116000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2207</td>\n",
              "      <td>0.080600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2208</td>\n",
              "      <td>0.094800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2209</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>0.169000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2211</td>\n",
              "      <td>0.552200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2212</td>\n",
              "      <td>0.069800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2213</td>\n",
              "      <td>0.189200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2214</td>\n",
              "      <td>0.081500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2215</td>\n",
              "      <td>0.268200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2216</td>\n",
              "      <td>0.219700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2217</td>\n",
              "      <td>0.193600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2218</td>\n",
              "      <td>0.079300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2219</td>\n",
              "      <td>0.124900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2221</td>\n",
              "      <td>0.105800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2222</td>\n",
              "      <td>0.085100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2223</td>\n",
              "      <td>0.071300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2224</td>\n",
              "      <td>0.091100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>0.084900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2226</td>\n",
              "      <td>0.085700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2227</td>\n",
              "      <td>0.088600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2228</td>\n",
              "      <td>0.082900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2229</td>\n",
              "      <td>0.102700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2230</td>\n",
              "      <td>0.060100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2231</td>\n",
              "      <td>0.083200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2232</td>\n",
              "      <td>0.107200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2233</td>\n",
              "      <td>0.104200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2234</td>\n",
              "      <td>0.069000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2235</td>\n",
              "      <td>0.131700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2236</td>\n",
              "      <td>0.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2237</td>\n",
              "      <td>0.108700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2238</td>\n",
              "      <td>0.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2239</td>\n",
              "      <td>0.063600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>0.083400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2241</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2242</td>\n",
              "      <td>0.114400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2243</td>\n",
              "      <td>0.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2244</td>\n",
              "      <td>0.095400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2245</td>\n",
              "      <td>0.091500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2246</td>\n",
              "      <td>0.119900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2247</td>\n",
              "      <td>0.068200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2248</td>\n",
              "      <td>0.057000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2249</td>\n",
              "      <td>0.122600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2251</td>\n",
              "      <td>0.069300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2252</td>\n",
              "      <td>0.073000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2253</td>\n",
              "      <td>0.091500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2254</td>\n",
              "      <td>0.073700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2255</td>\n",
              "      <td>0.070300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2256</td>\n",
              "      <td>0.102100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2257</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2258</td>\n",
              "      <td>0.073300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2259</td>\n",
              "      <td>0.060300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>0.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2261</td>\n",
              "      <td>0.114000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2262</td>\n",
              "      <td>0.072300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2263</td>\n",
              "      <td>0.086100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2264</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2265</td>\n",
              "      <td>0.063900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2266</td>\n",
              "      <td>0.090200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2267</td>\n",
              "      <td>0.063800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2268</td>\n",
              "      <td>0.125100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2269</td>\n",
              "      <td>0.081600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2270</td>\n",
              "      <td>0.063200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2271</td>\n",
              "      <td>0.057200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2272</td>\n",
              "      <td>0.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2273</td>\n",
              "      <td>0.133800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2274</td>\n",
              "      <td>0.071900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2276</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2277</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2278</td>\n",
              "      <td>0.073600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2279</td>\n",
              "      <td>0.075600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>0.061300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2281</td>\n",
              "      <td>0.079300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2282</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2283</td>\n",
              "      <td>0.073000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2284</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2285</td>\n",
              "      <td>0.063400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2286</td>\n",
              "      <td>0.079600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2287</td>\n",
              "      <td>0.138400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2288</td>\n",
              "      <td>0.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2289</td>\n",
              "      <td>0.066800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2290</td>\n",
              "      <td>0.081200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2291</td>\n",
              "      <td>0.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2292</td>\n",
              "      <td>0.136200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2293</td>\n",
              "      <td>0.095600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2294</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2295</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2296</td>\n",
              "      <td>0.069300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2297</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2298</td>\n",
              "      <td>0.171500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2299</td>\n",
              "      <td>0.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.062000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2301</td>\n",
              "      <td>0.071200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2302</td>\n",
              "      <td>0.079600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2303</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2304</td>\n",
              "      <td>0.078000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2305</td>\n",
              "      <td>0.082600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2306</td>\n",
              "      <td>0.056100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2307</td>\n",
              "      <td>0.083600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2308</td>\n",
              "      <td>0.060500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2309</td>\n",
              "      <td>0.072300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2310</td>\n",
              "      <td>0.096200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2311</td>\n",
              "      <td>0.106400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2312</td>\n",
              "      <td>0.093100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2313</td>\n",
              "      <td>0.045300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2314</td>\n",
              "      <td>0.086700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2315</td>\n",
              "      <td>0.097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2316</td>\n",
              "      <td>0.070500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2317</td>\n",
              "      <td>0.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2318</td>\n",
              "      <td>0.069700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2319</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2320</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2321</td>\n",
              "      <td>0.110800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2322</td>\n",
              "      <td>0.092200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2323</td>\n",
              "      <td>0.075800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2324</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>0.056100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2326</td>\n",
              "      <td>0.127400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2327</td>\n",
              "      <td>0.080900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2328</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2329</td>\n",
              "      <td>0.063100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2330</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2331</td>\n",
              "      <td>0.084200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2332</td>\n",
              "      <td>0.074800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2333</td>\n",
              "      <td>0.074600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2334</td>\n",
              "      <td>0.097100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2335</td>\n",
              "      <td>0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2336</td>\n",
              "      <td>0.063800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2337</td>\n",
              "      <td>0.066800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2338</td>\n",
              "      <td>0.069200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2339</td>\n",
              "      <td>0.078300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2341</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2342</td>\n",
              "      <td>0.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2343</td>\n",
              "      <td>0.062100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2344</td>\n",
              "      <td>0.086800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2345</td>\n",
              "      <td>0.073700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2346</td>\n",
              "      <td>0.062200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2347</td>\n",
              "      <td>0.062200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2348</td>\n",
              "      <td>0.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2349</td>\n",
              "      <td>0.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2351</td>\n",
              "      <td>0.077300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2352</td>\n",
              "      <td>0.076800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2353</td>\n",
              "      <td>0.100600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2354</td>\n",
              "      <td>0.071500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2355</td>\n",
              "      <td>0.081500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2356</td>\n",
              "      <td>0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2357</td>\n",
              "      <td>0.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2358</td>\n",
              "      <td>0.322200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2359</td>\n",
              "      <td>0.096500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2361</td>\n",
              "      <td>0.099400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2362</td>\n",
              "      <td>0.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2363</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2364</td>\n",
              "      <td>0.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2365</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2366</td>\n",
              "      <td>0.079700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2367</td>\n",
              "      <td>0.059500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2368</td>\n",
              "      <td>0.076200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2369</td>\n",
              "      <td>0.091200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2370</td>\n",
              "      <td>0.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2371</td>\n",
              "      <td>0.081600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2372</td>\n",
              "      <td>0.062100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2373</td>\n",
              "      <td>0.061900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2374</td>\n",
              "      <td>0.083500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>0.042900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2376</td>\n",
              "      <td>0.320500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2377</td>\n",
              "      <td>0.067800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2378</td>\n",
              "      <td>0.059900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2379</td>\n",
              "      <td>0.091000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>0.076500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2381</td>\n",
              "      <td>0.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2382</td>\n",
              "      <td>0.047400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2383</td>\n",
              "      <td>0.059600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2384</td>\n",
              "      <td>0.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2385</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2386</td>\n",
              "      <td>0.077600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2387</td>\n",
              "      <td>0.074500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2388</td>\n",
              "      <td>0.080400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2389</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2390</td>\n",
              "      <td>0.056400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2391</td>\n",
              "      <td>0.073700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2392</td>\n",
              "      <td>0.091500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2393</td>\n",
              "      <td>0.073200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2394</td>\n",
              "      <td>0.064600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2395</td>\n",
              "      <td>0.046800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2396</td>\n",
              "      <td>0.114100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2397</td>\n",
              "      <td>0.063300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2398</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2399</td>\n",
              "      <td>0.072400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.069700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2401</td>\n",
              "      <td>0.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2402</td>\n",
              "      <td>0.114800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2403</td>\n",
              "      <td>0.087200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2404</td>\n",
              "      <td>0.066900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2405</td>\n",
              "      <td>0.055200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2406</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2407</td>\n",
              "      <td>0.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2408</td>\n",
              "      <td>0.079300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2409</td>\n",
              "      <td>0.073600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2410</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2411</td>\n",
              "      <td>0.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2412</td>\n",
              "      <td>0.082400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2413</td>\n",
              "      <td>0.103700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2414</td>\n",
              "      <td>0.080500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2415</td>\n",
              "      <td>0.076600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2416</td>\n",
              "      <td>0.083100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2417</td>\n",
              "      <td>0.079400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2418</td>\n",
              "      <td>0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2419</td>\n",
              "      <td>0.064700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2420</td>\n",
              "      <td>0.069500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2421</td>\n",
              "      <td>0.072700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2422</td>\n",
              "      <td>0.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2423</td>\n",
              "      <td>0.095000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2424</td>\n",
              "      <td>0.075300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>0.076500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2426</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2427</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2428</td>\n",
              "      <td>0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2429</td>\n",
              "      <td>0.083000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2430</td>\n",
              "      <td>0.062600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2431</td>\n",
              "      <td>0.086100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2432</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2433</td>\n",
              "      <td>0.058700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2434</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2435</td>\n",
              "      <td>0.077600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2436</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2437</td>\n",
              "      <td>0.074300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2438</td>\n",
              "      <td>0.064700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2439</td>\n",
              "      <td>0.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2440</td>\n",
              "      <td>0.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2441</td>\n",
              "      <td>0.073900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2442</td>\n",
              "      <td>0.058800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2443</td>\n",
              "      <td>0.064100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2444</td>\n",
              "      <td>0.255000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2445</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2446</td>\n",
              "      <td>0.072200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2447</td>\n",
              "      <td>0.057200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2448</td>\n",
              "      <td>0.062700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2449</td>\n",
              "      <td>0.083900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2451</td>\n",
              "      <td>0.062700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2452</td>\n",
              "      <td>0.059100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2453</td>\n",
              "      <td>0.071800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2454</td>\n",
              "      <td>0.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2455</td>\n",
              "      <td>0.062900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2456</td>\n",
              "      <td>0.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2457</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2458</td>\n",
              "      <td>0.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2459</td>\n",
              "      <td>0.066700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2460</td>\n",
              "      <td>0.072600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2461</td>\n",
              "      <td>0.059300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2462</td>\n",
              "      <td>0.088300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2463</td>\n",
              "      <td>0.072600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2464</td>\n",
              "      <td>0.077900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2465</td>\n",
              "      <td>0.075100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2466</td>\n",
              "      <td>0.075300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2467</td>\n",
              "      <td>0.061200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2468</td>\n",
              "      <td>0.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2469</td>\n",
              "      <td>0.081900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2470</td>\n",
              "      <td>0.074600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2471</td>\n",
              "      <td>0.103800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2472</td>\n",
              "      <td>0.059500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2473</td>\n",
              "      <td>0.092200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2474</td>\n",
              "      <td>0.063000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>0.059900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2476</td>\n",
              "      <td>0.078300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2477</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2478</td>\n",
              "      <td>0.084200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2479</td>\n",
              "      <td>0.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2480</td>\n",
              "      <td>0.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2481</td>\n",
              "      <td>0.081000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2482</td>\n",
              "      <td>0.062600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2483</td>\n",
              "      <td>0.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2484</td>\n",
              "      <td>0.099500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2485</td>\n",
              "      <td>0.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2486</td>\n",
              "      <td>0.068200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2487</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2488</td>\n",
              "      <td>0.085500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2489</td>\n",
              "      <td>0.076500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2490</td>\n",
              "      <td>0.062900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2491</td>\n",
              "      <td>0.051200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2492</td>\n",
              "      <td>0.091000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2493</td>\n",
              "      <td>0.077900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2494</td>\n",
              "      <td>0.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2495</td>\n",
              "      <td>0.081400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2496</td>\n",
              "      <td>0.059000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2497</td>\n",
              "      <td>0.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2498</td>\n",
              "      <td>0.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2499</td>\n",
              "      <td>0.074600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2501</td>\n",
              "      <td>0.113300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2502</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2503</td>\n",
              "      <td>0.059900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2504</td>\n",
              "      <td>0.068600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2505</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2506</td>\n",
              "      <td>0.072700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2507</td>\n",
              "      <td>0.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2508</td>\n",
              "      <td>0.078100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2509</td>\n",
              "      <td>0.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2510</td>\n",
              "      <td>0.062100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2511</td>\n",
              "      <td>0.076600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2512</td>\n",
              "      <td>0.061900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2513</td>\n",
              "      <td>0.092800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2514</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2515</td>\n",
              "      <td>0.065100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2516</td>\n",
              "      <td>0.066900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2517</td>\n",
              "      <td>0.073200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2518</td>\n",
              "      <td>0.092900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2519</td>\n",
              "      <td>0.093300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2520</td>\n",
              "      <td>0.059200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2521</td>\n",
              "      <td>0.081900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2522</td>\n",
              "      <td>0.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2523</td>\n",
              "      <td>0.072200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2524</td>\n",
              "      <td>0.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2525</td>\n",
              "      <td>0.074700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2526</td>\n",
              "      <td>0.092800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2527</td>\n",
              "      <td>0.075100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2528</td>\n",
              "      <td>0.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2529</td>\n",
              "      <td>0.059200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2530</td>\n",
              "      <td>0.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2531</td>\n",
              "      <td>0.061300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2532</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2533</td>\n",
              "      <td>0.077700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2534</td>\n",
              "      <td>0.075300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2535</td>\n",
              "      <td>0.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2536</td>\n",
              "      <td>0.090900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2537</td>\n",
              "      <td>0.091100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2538</td>\n",
              "      <td>0.060500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2539</td>\n",
              "      <td>0.068900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2540</td>\n",
              "      <td>0.118500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2541</td>\n",
              "      <td>0.084600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2542</td>\n",
              "      <td>0.051200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2543</td>\n",
              "      <td>0.083300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2544</td>\n",
              "      <td>0.064200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2545</td>\n",
              "      <td>0.070600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2546</td>\n",
              "      <td>0.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2547</td>\n",
              "      <td>0.081400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2548</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2549</td>\n",
              "      <td>0.065600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.077700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2551</td>\n",
              "      <td>0.059400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2552</td>\n",
              "      <td>0.072000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2553</td>\n",
              "      <td>0.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2554</td>\n",
              "      <td>0.073200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2555</td>\n",
              "      <td>0.071000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2556</td>\n",
              "      <td>0.074700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2557</td>\n",
              "      <td>0.105200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2558</td>\n",
              "      <td>0.066800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2559</td>\n",
              "      <td>0.074700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2560</td>\n",
              "      <td>0.126500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2561</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2562</td>\n",
              "      <td>0.083900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2563</td>\n",
              "      <td>0.105000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2564</td>\n",
              "      <td>0.074700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2565</td>\n",
              "      <td>0.091200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2566</td>\n",
              "      <td>0.094600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2567</td>\n",
              "      <td>0.059600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2568</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2569</td>\n",
              "      <td>0.077600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2570</td>\n",
              "      <td>0.078600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2571</td>\n",
              "      <td>0.072700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2572</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2573</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2574</td>\n",
              "      <td>0.073800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2575</td>\n",
              "      <td>0.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2576</td>\n",
              "      <td>0.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2577</td>\n",
              "      <td>0.082600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2578</td>\n",
              "      <td>0.061400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2579</td>\n",
              "      <td>0.056800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2580</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2581</td>\n",
              "      <td>0.066100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2582</td>\n",
              "      <td>0.061700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2583</td>\n",
              "      <td>0.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2584</td>\n",
              "      <td>0.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2585</td>\n",
              "      <td>0.085300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2586</td>\n",
              "      <td>0.069000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2587</td>\n",
              "      <td>0.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2588</td>\n",
              "      <td>0.094900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2589</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2590</td>\n",
              "      <td>0.065100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2591</td>\n",
              "      <td>0.088600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2592</td>\n",
              "      <td>0.062900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2593</td>\n",
              "      <td>0.066600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2594</td>\n",
              "      <td>0.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2595</td>\n",
              "      <td>0.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2596</td>\n",
              "      <td>0.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2597</td>\n",
              "      <td>0.064800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2598</td>\n",
              "      <td>0.078100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2599</td>\n",
              "      <td>0.066800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.072500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2601</td>\n",
              "      <td>0.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2602</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2603</td>\n",
              "      <td>0.066000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2604</td>\n",
              "      <td>0.065900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2605</td>\n",
              "      <td>0.059800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2606</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2607</td>\n",
              "      <td>0.066700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2608</td>\n",
              "      <td>0.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2609</td>\n",
              "      <td>0.067700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2610</td>\n",
              "      <td>0.096700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2611</td>\n",
              "      <td>0.060200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2612</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2613</td>\n",
              "      <td>0.080700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2614</td>\n",
              "      <td>0.070700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2615</td>\n",
              "      <td>0.090400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2616</td>\n",
              "      <td>0.060400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2617</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2618</td>\n",
              "      <td>0.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2619</td>\n",
              "      <td>0.065400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2620</td>\n",
              "      <td>0.067500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2621</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2622</td>\n",
              "      <td>0.058800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2623</td>\n",
              "      <td>0.070600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2624</td>\n",
              "      <td>0.093600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2625</td>\n",
              "      <td>0.072700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2626</td>\n",
              "      <td>0.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2627</td>\n",
              "      <td>0.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2628</td>\n",
              "      <td>0.102500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2629</td>\n",
              "      <td>0.121900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2630</td>\n",
              "      <td>0.079400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2631</td>\n",
              "      <td>0.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2632</td>\n",
              "      <td>0.093700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2633</td>\n",
              "      <td>0.194200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2634</td>\n",
              "      <td>0.074100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2635</td>\n",
              "      <td>0.074400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2636</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2637</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2638</td>\n",
              "      <td>0.082500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2639</td>\n",
              "      <td>0.076500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2640</td>\n",
              "      <td>0.070200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2641</td>\n",
              "      <td>0.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2642</td>\n",
              "      <td>0.059500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2643</td>\n",
              "      <td>0.065400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2644</td>\n",
              "      <td>0.106700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2645</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2646</td>\n",
              "      <td>0.071400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2647</td>\n",
              "      <td>0.102100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2648</td>\n",
              "      <td>0.069400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2649</td>\n",
              "      <td>0.063000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.082000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2651</td>\n",
              "      <td>0.072900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2652</td>\n",
              "      <td>0.074700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2653</td>\n",
              "      <td>0.064100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2654</td>\n",
              "      <td>0.101200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2655</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2656</td>\n",
              "      <td>0.068000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2657</td>\n",
              "      <td>0.074100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2658</td>\n",
              "      <td>0.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2659</td>\n",
              "      <td>0.086900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2660</td>\n",
              "      <td>0.048500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2661</td>\n",
              "      <td>0.089700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2662</td>\n",
              "      <td>0.073700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2663</td>\n",
              "      <td>0.074500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2664</td>\n",
              "      <td>0.057100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2665</td>\n",
              "      <td>0.096400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2666</td>\n",
              "      <td>0.066600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2667</td>\n",
              "      <td>0.072800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2668</td>\n",
              "      <td>0.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2669</td>\n",
              "      <td>0.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2670</td>\n",
              "      <td>0.049600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2671</td>\n",
              "      <td>0.076800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2672</td>\n",
              "      <td>0.062900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2673</td>\n",
              "      <td>0.065200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2674</td>\n",
              "      <td>0.078800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2675</td>\n",
              "      <td>0.063100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2676</td>\n",
              "      <td>0.060100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2677</td>\n",
              "      <td>0.052200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2678</td>\n",
              "      <td>0.060400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2679</td>\n",
              "      <td>0.103200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2680</td>\n",
              "      <td>0.044800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2681</td>\n",
              "      <td>0.076000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2682</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2683</td>\n",
              "      <td>0.084100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2684</td>\n",
              "      <td>0.067600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2685</td>\n",
              "      <td>0.081300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2686</td>\n",
              "      <td>0.066900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2687</td>\n",
              "      <td>0.078500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2688</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2689</td>\n",
              "      <td>0.066700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2690</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2691</td>\n",
              "      <td>0.081200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2692</td>\n",
              "      <td>0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2693</td>\n",
              "      <td>0.095400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2694</td>\n",
              "      <td>0.073700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2695</td>\n",
              "      <td>0.099700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2696</td>\n",
              "      <td>0.044500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2697</td>\n",
              "      <td>0.108100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2698</td>\n",
              "      <td>0.065600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2699</td>\n",
              "      <td>0.066000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2701</td>\n",
              "      <td>0.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2702</td>\n",
              "      <td>0.117700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2703</td>\n",
              "      <td>0.071900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2704</td>\n",
              "      <td>0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2705</td>\n",
              "      <td>0.065300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2706</td>\n",
              "      <td>0.055900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2707</td>\n",
              "      <td>0.063100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2708</td>\n",
              "      <td>0.096400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2709</td>\n",
              "      <td>0.068500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2710</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2711</td>\n",
              "      <td>0.229300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2712</td>\n",
              "      <td>0.071400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2713</td>\n",
              "      <td>0.059200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2714</td>\n",
              "      <td>0.075400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2715</td>\n",
              "      <td>0.067800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2716</td>\n",
              "      <td>0.081900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2717</td>\n",
              "      <td>0.090700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2718</td>\n",
              "      <td>0.081800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2719</td>\n",
              "      <td>0.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2720</td>\n",
              "      <td>0.061600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2721</td>\n",
              "      <td>0.085900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2722</td>\n",
              "      <td>0.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2723</td>\n",
              "      <td>0.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2724</td>\n",
              "      <td>0.075300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2725</td>\n",
              "      <td>0.063400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2726</td>\n",
              "      <td>0.083500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2727</td>\n",
              "      <td>0.060900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2728</td>\n",
              "      <td>0.075300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2729</td>\n",
              "      <td>0.082000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2730</td>\n",
              "      <td>0.075600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2731</td>\n",
              "      <td>0.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2732</td>\n",
              "      <td>0.087900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2733</td>\n",
              "      <td>0.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2734</td>\n",
              "      <td>0.087700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2735</td>\n",
              "      <td>0.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2736</td>\n",
              "      <td>0.081100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2737</td>\n",
              "      <td>0.089600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2738</td>\n",
              "      <td>0.055200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2739</td>\n",
              "      <td>0.067700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2740</td>\n",
              "      <td>0.077900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2741</td>\n",
              "      <td>0.068000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2742</td>\n",
              "      <td>0.058400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2743</td>\n",
              "      <td>0.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2744</td>\n",
              "      <td>0.093100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2745</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2746</td>\n",
              "      <td>0.087900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2747</td>\n",
              "      <td>0.115400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2748</td>\n",
              "      <td>0.074300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2749</td>\n",
              "      <td>0.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2751</td>\n",
              "      <td>0.073900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2752</td>\n",
              "      <td>0.058000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2753</td>\n",
              "      <td>0.070900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2754</td>\n",
              "      <td>0.091800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2755</td>\n",
              "      <td>0.059100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2756</td>\n",
              "      <td>0.062700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2757</td>\n",
              "      <td>0.072600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2758</td>\n",
              "      <td>0.069800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2759</td>\n",
              "      <td>0.076800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2760</td>\n",
              "      <td>0.074300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2761</td>\n",
              "      <td>0.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2762</td>\n",
              "      <td>0.077700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2763</td>\n",
              "      <td>0.075800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2764</td>\n",
              "      <td>0.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2765</td>\n",
              "      <td>0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2766</td>\n",
              "      <td>0.096100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2767</td>\n",
              "      <td>0.071200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2768</td>\n",
              "      <td>0.092500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2769</td>\n",
              "      <td>0.079200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2770</td>\n",
              "      <td>0.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2771</td>\n",
              "      <td>0.055500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2772</td>\n",
              "      <td>0.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2773</td>\n",
              "      <td>0.127400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2774</td>\n",
              "      <td>0.074700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2775</td>\n",
              "      <td>0.090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2776</td>\n",
              "      <td>0.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2777</td>\n",
              "      <td>0.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2778</td>\n",
              "      <td>0.083100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2779</td>\n",
              "      <td>0.066000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2780</td>\n",
              "      <td>0.085100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2781</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2782</td>\n",
              "      <td>0.066100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2783</td>\n",
              "      <td>0.070200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2784</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2785</td>\n",
              "      <td>0.097000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2786</td>\n",
              "      <td>0.058300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2787</td>\n",
              "      <td>0.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2788</td>\n",
              "      <td>0.086600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2789</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2790</td>\n",
              "      <td>0.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2791</td>\n",
              "      <td>0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2792</td>\n",
              "      <td>0.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2793</td>\n",
              "      <td>0.061500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2794</td>\n",
              "      <td>0.076800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2795</td>\n",
              "      <td>0.033600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2796</td>\n",
              "      <td>0.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2797</td>\n",
              "      <td>0.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2798</td>\n",
              "      <td>0.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2799</td>\n",
              "      <td>0.091900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.077600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2801</td>\n",
              "      <td>0.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2802</td>\n",
              "      <td>0.068300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2803</td>\n",
              "      <td>0.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2804</td>\n",
              "      <td>0.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2805</td>\n",
              "      <td>0.060700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2806</td>\n",
              "      <td>0.062900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2807</td>\n",
              "      <td>0.066400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2808</td>\n",
              "      <td>0.073300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2809</td>\n",
              "      <td>0.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2810</td>\n",
              "      <td>0.132200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSeaIIdVnYZb"
      },
      "source": [
        "# **Step 8.** Save Trainer Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWc-3iYuVKpq"
      },
      "outputs": [],
      "source": [
        "with open(\"trainer_stats.json\", \"w\") as f:\n",
        "    json.dump(trainer_stats, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJTKdAmRnYZc"
      },
      "source": [
        "# **Step 9.** Save Finetuned Model & Push to HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzDLfiN-VKpq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e140969d78744a9497ff0bae05b23123",
            "d17aa2054e444660bd2ff184701c9393",
            "c06c8ef9b72d45bab4c9b85381a08da3",
            "a9331c29470c4880b8f488b68159a8aa",
            "8bd71e2d9fa84a9391cf4dd8a5b67a33",
            "a00ef4cb68b94c799b5013c14324645c",
            "7774aa79a2c84a53a85386f715548594",
            "affbb29279c0492f8ad7457832efc7a3",
            "d02bc81adbb34488bc95ef343ba4985f",
            "f6413ab0825a4710918a6406a5f3c7a2",
            "2a372d91d153475c896f91869b0701af"
          ]
        },
        "outputId": "3a032281-abb9-46f4-909a-b44dd0919ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 5.7G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 61.63 out of 83.48 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 54.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = False.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
            "Unsloth: [1] Converting model at llama-3-8b-instruct-aidoctor into bf16 GGUF format.\n",
            "The output location will be /content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: llama-3-8b-instruct-aidoctor\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 8192\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 32\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 12 threads.\n",
            "2025-01-27 17:25:44.189285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-27 17:25:44.213488: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-27 17:25:44.219383: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-27 17:25:45.720287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128255\n",
            "INFO:gguf.vocab:Setting chat_template to {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf: n_tensors = 291, total_size = 16.1G\n",
            "Writing: 100%|██████████| 16.1G/16.1G [01:16<00:00, 210Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 4567 (d6d24cd9)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf' to '/content/llama-3-8b-instruct-aidoctor/unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n",
            "llama_model_loader: loaded meta data with 30 key-value pairs and 291 tensors from /content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3 8b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = Instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 32\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128255\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
            "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type bf16:  226 tensors\n",
            "[   1/ 291]                        output.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n",
            "[   2/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                    token_embd.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q4_K .. size =  1002.00 MiB ->   281.81 MiB\n",
            "[   4/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   5/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   6/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   7/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   8/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[   9/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  10/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  11/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  13/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  14/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  15/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  16/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  17/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  18/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  19/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  20/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  22/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  23/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  24/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  25/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  26/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  27/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  29/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  31/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  32/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  33/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  34/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  35/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  36/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  38/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  40/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  41/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  42/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  43/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  44/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  45/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  47/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  49/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  50/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  51/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  52/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  53/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  54/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  56/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  58/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  59/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  60/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  61/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  62/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  63/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  65/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  67/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  68/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  69/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  70/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  71/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  72/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  74/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  76/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  77/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  78/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  79/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  80/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  81/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  83/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  85/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  86/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  87/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  88/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  89/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  90/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  92/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  94/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  95/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  96/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  97/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  98/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  99/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 100/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 101/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 103/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 104/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 105/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 106/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 107/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 108/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 109/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 110/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 112/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 113/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 114/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 115/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 116/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 117/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 118/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 119/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 121/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 122/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 123/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 124/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 125/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 126/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 127/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 128/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 130/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 131/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 132/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 133/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 134/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 135/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 136/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 137/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 139/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 140/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 141/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 142/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 143/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 144/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 145/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 146/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 148/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 149/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 150/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 151/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 152/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 153/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 154/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 155/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 157/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 158/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 159/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 160/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 161/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 162/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 163/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 164/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 166/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 167/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 168/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 169/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 170/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 171/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 172/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 173/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 174/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 175/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 176/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 177/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 178/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 179/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 180/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 181/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 182/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 184/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 185/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 186/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 187/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 188/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 189/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 190/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 191/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 193/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 194/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 195/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 196/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 197/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 198/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 199/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 200/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 202/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 203/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 204/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 205/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 206/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 207/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 208/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 212/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 213/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 214/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 215/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 216/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 217/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 220/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 221/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 222/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 223/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 224/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 225/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 226/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 227/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 229/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 230/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 231/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 232/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 233/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 234/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 235/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 236/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 238/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 239/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 240/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 241/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 242/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 243/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 244/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 245/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 247/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 248/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 249/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 250/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 251/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 252/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 253/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 254/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 256/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 257/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 258/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 259/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 260/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 261/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 262/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 263/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 265/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 266/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 267/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 268/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 269/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 270/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 271/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 272/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 274/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 275/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 276/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 277/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 278/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 279/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 280/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 281/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 282/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 284/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 285/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 286/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 287/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 288/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 289/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "llama_model_quantize_impl: model size  = 15317.02 MB\n",
            "llama_model_quantize_impl: quant size  =  4685.30 MB\n",
            "\n",
            "main: quantize time = 140898.50 ms\n",
            "main:    total time = 140898.50 ms\n",
            "Unsloth: Conversion completed! Output location: /content/llama-3-8b-instruct-aidoctor/unsloth.Q4_K_M.gguf\n",
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 61.84 out of 83.48 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 65.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Done.\n",
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: [1] Converting model at llama-3-8b-instruct-aidoctor into bf16 GGUF format.\n",
            "The output location will be /content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: llama-3-8b-instruct-aidoctor\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 8192\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 32\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 12 threads.\n",
            "2025-01-27 17:30:45.711016: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-27 17:30:45.736950: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-27 17:30:45.744192: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-27 17:30:47.237831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128255\n",
            "INFO:gguf.vocab:Setting chat_template to {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf: n_tensors = 291, total_size = 16.1G\n",
            "Writing: 100%|██████████| 16.1G/16.1G [01:14<00:00, 217Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 4567 (d6d24cd9)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf' to '/content/llama-3-8b-instruct-aidoctor/unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n",
            "llama_model_loader: loaded meta data with 30 key-value pairs and 291 tensors from /content/llama-3-8b-instruct-aidoctor/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3 8b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = Instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 32\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128255\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
            "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type bf16:  226 tensors\n",
            "[   1/ 291]                        output.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n",
            "[   2/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                    token_embd.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q4_K .. size =  1002.00 MiB ->   281.81 MiB\n",
            "[   4/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   5/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   6/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   7/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   8/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[   9/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  10/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  11/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  13/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  14/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  15/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  16/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  17/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  18/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  19/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  20/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  22/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  23/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  24/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  25/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  26/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  27/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  29/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  31/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  32/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  33/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  34/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  35/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  36/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  38/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  40/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  41/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  42/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  43/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  44/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  45/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  47/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  49/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  50/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  51/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  52/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  53/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  54/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  56/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  58/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  59/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  60/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  61/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  62/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  63/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  65/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  67/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  68/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  69/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  70/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  71/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  72/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  74/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  76/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  77/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  78/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  79/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  80/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  81/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  83/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  85/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  86/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  87/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  88/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  89/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  90/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  92/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  94/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  95/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  96/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  97/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  98/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  99/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 100/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 101/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 103/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 104/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 105/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 106/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 107/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 108/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 109/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 110/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 112/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 113/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 114/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 115/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 116/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 117/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 118/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 119/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 121/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 122/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 123/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 124/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 125/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 126/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 127/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 128/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 130/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 131/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 132/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 133/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 134/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 135/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 136/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 137/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 139/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 140/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 141/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 142/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 143/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 144/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 145/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 146/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 148/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 149/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 150/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 151/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 152/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 153/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 154/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 155/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 157/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 158/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 159/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 160/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 161/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 162/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 163/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 164/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 166/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 167/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 168/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 169/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 170/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 171/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 172/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 173/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 174/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 175/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 176/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 177/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 178/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 179/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 180/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 181/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 182/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 184/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 185/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 186/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 187/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 188/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 189/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 190/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 191/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 193/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 194/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 195/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 196/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 197/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 198/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 199/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 200/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 202/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 203/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 204/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 205/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 206/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 207/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 208/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 212/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 213/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 214/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 215/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 216/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 217/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 220/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 221/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 222/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 223/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 224/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 225/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 226/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 227/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 229/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 230/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 231/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 232/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 233/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 234/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 235/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 236/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 238/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 239/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 240/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 241/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 242/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 243/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 244/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 245/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 247/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 248/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 249/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 250/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 251/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 252/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 253/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 254/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 256/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 257/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 258/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 259/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 260/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 261/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 262/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 263/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 265/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 266/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 267/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 268/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 269/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 270/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 271/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 272/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 274/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 275/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 276/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 277/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 278/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 279/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 280/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 281/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 282/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 284/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 285/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 286/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 287/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 288/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 289/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "llama_model_quantize_impl: model size  = 15317.02 MB\n",
            "llama_model_quantize_impl: quant size  =  4685.30 MB\n",
            "\n",
            "main: quantize time = 142129.18 ms\n",
            "main:    total time = 142129.18 ms\n",
            "Unsloth: Conversion completed! Output location: /content/llama-3-8b-instruct-aidoctor/unsloth.Q4_K_M.gguf\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e140969d78744a9497ff0bae05b23123"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/ahsannadir/llama-3-8b-instruct-aidoctor\n"
          ]
        }
      ],
      "source": [
        "model.save_pretrained_gguf(config.get(\"model_config\").get(\"finetuned_model\"), tokenizer, quantization_method = \"q4_k_m\")\n",
        "model.push_to_hub_gguf(config.get(\"model_config\").get(\"finetuned_model\"), tokenizer, quantization_method = \"q4_k_m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgyNn-lLnYZc"
      },
      "source": [
        "# **Step 10.** Test your pretrained model in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozVcalyP_JLs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361,
          "referenced_widgets": [
            "b5f7722ae1bf4d48bd5cfc9470e46267",
            "f8be6d91db134101816a0ed9fba24195",
            "9138dd9a62fe416fb6a08c33bb80c13c",
            "3fa02ee9760c422ca380506aae052e9e",
            "3c678c001f304638aa4d8adeaf7037e9",
            "3abe6ca8ce8c4718be53a2e8fad1365d",
            "2839055ea6f944f081089962e03872fe",
            "c8019ad34dd8499f8e235f1170121d5c",
            "ca6a30aaf7c14c3da09d0d590d91f26d",
            "7c49fc806f5c470bb8a7fe91bd48867a",
            "4b24c6be19b44f24849a83ef256e84b0"
          ]
        },
        "outputId": "6fe65562-91e7-4d63-ba7a-9c79c8d3bdc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.1.7: Fast Llama patching. Transformers: 4.47.1.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post1. FA2 = True]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5f7722ae1bf4d48bd5cfc9470e46267"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ENTER PROMPT: I may have constipation,pain_during_bowel_movements,pain_in_anal_region,bloody_stool,irritation_in_anus\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"systemYou are a highly qualified AI doctor. Your task is to assist users by analyzing their symptoms to detect possible diseases, recommend the appropriate medical specialist, and provide precautions. Ensure your responses are accurate, professional, and empathetic.userI may have constipation,pain_during_bowel_movements,pain_in_anal_region,bloody_stool,irritation_in_anusassistantI'm so sorry to hear that you're experiencing these symptoms. It's possible that you may have Hemorrhoids.\\n\\nHemorrhoids are swollen veins in the lower rectum or anus that can cause bleeding, itching, and pain. There are two main types: internal and external. Internal hemorrhoids are located inside the rectum and may not cause symptoms unless they become irritated or inflamed. External hemorrhoids occur outside the anus and can cause pain, itching, and bleeding.\\n\\nBased on your symptoms, it's possible that you have external hemorrhoids. However, it's important to note that there are other conditions that can cause similar symptoms, such as anal fissures, anal cancer, or inflammatory bowel disease.\\n\\nI recommend that you consult a doctor, preferably a gastroenterologist or a general surgeon, to get a proper diagnosis and treatment plan. They may perform a physical examination, take a medical history, and conduct tests such as a sigmoidoscopy or colonoscopy to rule out other conditions.\\n\\nIn the meantime, here are some precautions you can take to alleviate your symptoms:\\n\\n1. Increase your fiber intake: Fiber can help soften your stool and make it easier to pass. You can do this by eating foods rich in fiber such as whole grains,\"]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Loading the fine-tuned model and the tokenizer for inference\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = config.get(\"model_config\").get(\"finetuned_model\"),\n",
        "        max_seq_length = config.get(\"model_config\").get(\"max_seq_length\"),\n",
        "        dtype = config.get(\"model_config\").get(\"dtype\"),\n",
        "        load_in_4bit = config.get(\"model_config\").get(\"load_in_4bit\"),\n",
        "    )\n",
        "\n",
        "# Using FastLanguageModel for fast inference\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "system_prompt = f\"You are a highly qualified AI doctor. Your task is to assist users by analyzing their symptoms to detect possible diseases, recommend the appropriate medical specialist, and provide precautions. Ensure your responses are accurate, professional, and empathetic.\"\n",
        "\n",
        "# Tokenizing the input and generating the output\n",
        "prompt = input('ENTER PROMPT: ')\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    f\"<|start_header_id|>system<|end_header_id|>{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>{prompt}<|end_header_id|>\"\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/llama-3-8b-instruct-aidoctor.zip /content/llama-3-8b-instruct-aidoctor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN2E7bMQ1ine",
        "outputId": "38d1b54f-053c-4b16-db4e-bdc4c625aa5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/llama-3-8b-instruct-aidoctor/ (stored 0%)\n",
            "  adding: content/llama-3-8b-instruct-aidoctor/model-00003-of-00004.safetensors\n",
            "\n",
            "\n",
            "zip error: Interrupted (aborting)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/ai-doctor-02.zip /content/llama.cpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taMZ_dEy2oah",
        "outputId": "06c11db4-bbd6-456f-a64b-13b451f48d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/llama.cpp/ (stored 0%)\n",
            "  adding: content/llama.cpp/Sources/ (stored 0%)\n",
            "  adding: content/llama.cpp/Sources/llama/ (stored 0%)\n",
            "  adding: content/llama.cpp/Sources/llama/module.modulemap (deflated 19%)\n",
            "  adding: content/llama.cpp/Sources/llama/llama.h (stored 0%)\n",
            "  adding: content/llama.cpp/pyproject.toml (deflated 48%)\n",
            "  adding: content/llama.cpp/.pre-commit-config.yaml (deflated 47%)\n",
            "  adding: content/llama.cpp/.gitmodules (deflated 21%)\n",
            "  adding: content/llama.cpp/ci/ (stored 0%)\n",
            "  adding: content/llama.cpp/ci/README.md (deflated 48%)\n",
            "  adding: content/llama.cpp/ci/run.sh (deflated 89%)\n",
            "  adding: content/llama.cpp/llama-quantize (deflated 62%)\n",
            "  adding: content/llama.cpp/llama-cli (deflated 62%)\n",
            "  adding: content/llama.cpp/pyrightconfig.json (deflated 47%)\n",
            "  adding: content/llama.cpp/requirements/ (stored 0%)\n",
            "  adding: content/llama.cpp/requirements/requirements-convert_hf_to_gguf_update.txt (deflated 10%)\n",
            "  adding: content/llama.cpp/requirements/requirements-test-tokenizer-random.txt (stored 0%)\n",
            "  adding: content/llama.cpp/requirements/requirements-convert_llama_ggml_to_gguf.txt (stored 0%)\n",
            "  adding: content/llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (deflated 10%)\n",
            "  adding: content/llama.cpp/requirements/requirements-all.txt (deflated 66%)\n",
            "  adding: content/llama.cpp/requirements/requirements-convert_legacy_llama.txt (deflated 13%)\n",
            "  adding: content/llama.cpp/requirements/requirements-pydantic.txt (stored 0%)\n",
            "  adding: content/llama.cpp/requirements/requirements-compare-llama-bench.txt (stored 0%)\n",
            "  adding: content/llama.cpp/requirements/requirements-convert_lora_to_gguf.txt (deflated 13%)\n",
            "  adding: content/llama.cpp/convert_hf_to_gguf_update.py (deflated 72%)\n",
            "  adding: content/llama.cpp/include/ (stored 0%)\n",
            "  adding: content/llama.cpp/include/llama-cpp.h (deflated 68%)\n",
            "  adding: content/llama.cpp/include/llama.h (deflated 78%)\n",
            "  adding: content/llama.cpp/LICENSE (deflated 41%)\n",
            "  adding: content/llama.cpp/.git/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/config (deflated 40%)\n",
            "  adding: content/llama.cpp/.git/hooks/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/llama.cpp/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/llama.cpp/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/llama.cpp/.git/hooks/fsmonitor-watchman.sample (deflated 62%)\n",
            "  adding: content/llama.cpp/.git/hooks/pre-push.sample (deflated 49%)\n",
            "  adding: content/llama.cpp/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/llama.cpp/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/llama.cpp/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/llama.cpp/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/llama.cpp/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/llama.cpp/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/llama.cpp/.git/hooks/push-to-checkout.sample (deflated 55%)\n",
            "  adding: content/llama.cpp/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/llama.cpp/.git/HEAD (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/config (deflated 36%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/update.sample (deflated 68%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/fsmonitor-watchman.sample (deflated 62%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/pre-push.sample (deflated 49%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/push-to-checkout.sample (deflated 55%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/HEAD (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/info/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/info/exclude (deflated 28%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/branches/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/packed-refs (deflated 38%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/description (deflated 14%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/refs/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/refs/heads/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/refs/heads/master (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/refs/tags/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/refs/remotes/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/objects/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/objects/info/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/objects/pack/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/objects/pack/pack-95f4f169b8b9789d781e248597ec1690d30ec72a.pack (deflated 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/objects/pack/pack-95f4f169b8b9789d781e248597ec1690d30ec72a.idx (deflated 2%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/logs/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/logs/HEAD (deflated 52%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/logs/refs/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/logs/refs/heads/master (deflated 30%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/logs/refs/remotes/origin/HEAD (deflated 30%)\n",
            "  adding: content/llama.cpp/.git/modules/kompute/index (deflated 61%)\n",
            "  adding: content/llama.cpp/.git/info/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/info/exclude (deflated 28%)\n",
            "  adding: content/llama.cpp/.git/branches/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/packed-refs (deflated 54%)\n",
            "  adding: content/llama.cpp/.git/description (deflated 14%)\n",
            "  adding: content/llama.cpp/.git/refs/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/refs/heads/master (stored 0%)\n",
            "  adding: content/llama.cpp/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/llama.cpp/.git/objects/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/objects/info/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/objects/pack/pack-7d658e0e9b40e5ea5900e23497763535f4142a69.idx (deflated 1%)\n",
            "  adding: content/llama.cpp/.git/objects/pack/pack-7d658e0e9b40e5ea5900e23497763535f4142a69.pack (deflated 1%)\n",
            "  adding: content/llama.cpp/.git/logs/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/logs/HEAD (deflated 28%)\n",
            "  adding: content/llama.cpp/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/logs/refs/heads/master (deflated 28%)\n",
            "  adding: content/llama.cpp/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/llama.cpp/.git/logs/refs/remotes/origin/HEAD (deflated 28%)\n",
            "  adding: content/llama.cpp/.git/index (deflated 62%)\n",
            "  adding: content/llama.cpp/.ecrc (deflated 9%)\n",
            "  adding: content/llama.cpp/CODEOWNERS (deflated 55%)\n",
            "  adding: content/llama.cpp/.devops/ (stored 0%)\n",
            "  adding: content/llama.cpp/.devops/cpu.Dockerfile (deflated 63%)\n",
            "  adding: content/llama.cpp/.devops/tools.sh (deflated 62%)\n",
            "  adding: content/llama.cpp/.devops/intel.Dockerfile (deflated 62%)\n",
            "  adding: content/llama.cpp/.devops/vulkan.Dockerfile (deflated 62%)\n",
            "  adding: content/llama.cpp/.devops/nix/ (stored 0%)\n",
            "  adding: content/llama.cpp/.devops/nix/docker.nix (deflated 46%)\n",
            "  adding: content/llama.cpp/.devops/nix/nixpkgs-instances.nix (deflated 54%)\n",
            "  adding: content/llama.cpp/.devops/nix/jetson-support.nix (deflated 62%)\n",
            "  adding: content/llama.cpp/.devops/nix/python-scripts.nix (deflated 51%)\n",
            "  adding: content/llama.cpp/.devops/nix/apps.nix (deflated 51%)\n",
            "  adding: content/llama.cpp/.devops/nix/scope.nix (deflated 61%)\n",
            "  adding: content/llama.cpp/.devops/nix/devshells.nix (deflated 65%)\n",
            "  adding: content/llama.cpp/.devops/nix/package-gguf-py.nix (deflated 48%)\n",
            "  adding: content/llama.cpp/.devops/nix/sif.nix (deflated 40%)\n",
            "  adding: content/llama.cpp/.devops/nix/package.nix (deflated 60%)\n",
            "  adding: content/llama.cpp/.devops/llama-cpp.srpm.spec (deflated 51%)\n",
            "  adding: content/llama.cpp/.devops/musa.Dockerfile (deflated 62%)\n",
            "  adding: content/llama.cpp/.devops/llama-cpp-cuda.srpm.spec (deflated 51%)\n",
            "  adding: content/llama.cpp/.devops/rocm.Dockerfile (deflated 59%)\n",
            "  adding: content/llama.cpp/.devops/cloud-v-pipeline (deflated 53%)\n",
            "  adding: content/llama.cpp/.devops/llama-cli-cann.Dockerfile (deflated 71%)\n",
            "  adding: content/llama.cpp/.devops/cuda.Dockerfile (deflated 60%)\n",
            "  adding: content/llama.cpp/.flake8 (deflated 43%)\n",
            "  adding: content/llama.cpp/gguf-py/ (stored 0%)\n",
            "  adding: content/llama.cpp/gguf-py/pyproject.toml (deflated 50%)\n",
            "  adding: content/llama.cpp/gguf-py/LICENSE (deflated 41%)\n",
            "  adding: content/llama.cpp/gguf-py/tests/ (stored 0%)\n",
            "  adding: content/llama.cpp/gguf-py/tests/__init__.py (stored 0%)\n",
            "  adding: content/llama.cpp/gguf-py/tests/test_quants.py (deflated 73%)\n",
            "  adding: content/llama.cpp/gguf-py/tests/test_metadata.py (deflated 78%)\n",
            "  adding: content/llama.cpp/gguf-py/README.md (deflated 60%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/ (stored 0%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/lazy.py (deflated 69%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/py.typed (stored 0%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/utility.py (deflated 70%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/gguf_writer.py (deflated 79%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/gguf_reader.py (deflated 71%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/quants.py (deflated 75%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__init__.py (deflated 57%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/gguf.py (deflated 42%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/tensor_mapping.py (deflated 87%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/metadata.py (deflated 81%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/scripts/ (stored 0%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/scripts/gguf_new_metadata.py (deflated 71%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/scripts/__init__.py (deflated 60%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/scripts/gguf_dump.py (deflated 75%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/scripts/gguf_hash.py (deflated 64%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/scripts/gguf_set_metadata.py (deflated 60%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/scripts/gguf_convert_endian.py (deflated 63%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/ (stored 0%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/utility.cpython-311.pyc (deflated 49%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/__init__.cpython-311.pyc (deflated 37%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/tensor_mapping.cpython-311.pyc (deflated 71%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/constants.cpython-311.pyc (deflated 73%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/metadata.cpython-311.pyc (deflated 61%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/vocab.cpython-311.pyc (deflated 58%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/lazy.cpython-311.pyc (deflated 53%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/gguf_writer.cpython-311.pyc (deflated 72%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/quants.cpython-311.pyc (deflated 69%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/__pycache__/gguf_reader.cpython-311.pyc (deflated 54%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/vocab.py (deflated 76%)\n",
            "  adding: content/llama.cpp/gguf-py/gguf/constants.py (deflated 86%)\n",
            "  adding: content/llama.cpp/gguf-py/examples/ (stored 0%)\n",
            "  adding: content/llama.cpp/gguf-py/examples/reader.py (deflated 57%)\n",
            "  adding: content/llama.cpp/gguf-py/examples/writer.py (deflated 57%)\n",
            "  adding: content/llama.cpp/scripts/ (stored 0%)\n",
            "  adding: content/llama.cpp/scripts/get-hellaswag.sh (deflated 36%)\n",
            "  adding: content/llama.cpp/scripts/debug-test.sh (deflated 60%)\n",
            "  adding: content/llama.cpp/scripts/gen-authors.sh (deflated 30%)\n",
            "  adding: content/llama.cpp/scripts/ci-run.sh (deflated 51%)\n",
            "  adding: content/llama.cpp/scripts/qnt-all.sh (deflated 44%)\n",
            "  adding: content/llama.cpp/scripts/get-winogrande.sh (deflated 38%)\n",
            "  adding: content/llama.cpp/scripts/get-flags.mk (deflated 61%)\n",
            "  adding: content/llama.cpp/scripts/hf.sh (deflated 61%)\n",
            "  adding: content/llama.cpp/scripts/get-wikitext-103.sh (deflated 27%)\n",
            "  adding: content/llama.cpp/scripts/compare-llama-bench.py (deflated 69%)\n",
            "  adding: content/llama.cpp/scripts/get_hf_chat_template.py (deflated 60%)\n",
            "  adding: content/llama.cpp/scripts/xxd.cmake (deflated 43%)\n",
            "  adding: content/llama.cpp/scripts/get-pg.sh (deflated 50%)\n",
            "  adding: content/llama.cpp/scripts/sync-ggml-am.sh (deflated 76%)\n",
            "  adding: content/llama.cpp/scripts/run-all-ppl.sh (deflated 40%)\n",
            "  adding: content/llama.cpp/scripts/check-requirements.sh (deflated 57%)\n",
            "  adding: content/llama.cpp/scripts/build-info.sh (deflated 53%)\n",
            "  adding: content/llama.cpp/scripts/install-oneapi.bat (deflated 56%)\n",
            "  adding: content/llama.cpp/scripts/run-all-perf.sh (deflated 41%)\n",
            "  adding: content/llama.cpp/scripts/compare-commits.sh (deflated 51%)\n",
            "  adding: content/llama.cpp/scripts/sync-ggml.sh (deflated 80%)\n",
            "  adding: content/llama.cpp/scripts/sync-ggml.last (stored 0%)\n",
            "  adding: content/llama.cpp/scripts/gen-unicode-data.py (deflated 69%)\n",
            "  adding: content/llama.cpp/scripts/get-wikitext-2.sh (deflated 34%)\n",
            "  adding: content/llama.cpp/scripts/verify-checksum-models.py (deflated 59%)\n",
            "  adding: content/llama.cpp/docs/ (stored 0%)\n",
            "  adding: content/llama.cpp/docs/install.md (deflated 53%)\n",
            "  adding: content/llama.cpp/docs/build.md (deflated 64%)\n",
            "  adding: content/llama.cpp/docs/android.md (deflated 51%)\n",
            "  adding: content/llama.cpp/docs/cuda-fedora.md (deflated 65%)\n",
            "  adding: content/llama.cpp/docs/backend/ (stored 0%)\n",
            "  adding: content/llama.cpp/docs/backend/CANN.md (deflated 68%)\n",
            "  adding: content/llama.cpp/docs/backend/SYCL.md (deflated 70%)\n",
            "  adding: content/llama.cpp/docs/backend/BLIS.md (deflated 44%)\n",
            "  adding: content/llama.cpp/docs/docker.md (deflated 76%)\n",
            "  adding: content/llama.cpp/docs/development/ (stored 0%)\n",
            "  adding: content/llama.cpp/docs/development/HOWTO-add-model.md (deflated 60%)\n",
            "  adding: content/llama.cpp/docs/development/token_generation_performance_tips.md (deflated 51%)\n",
            "  adding: content/llama.cpp/docs/development/llama-star/ (stored 0%)\n",
            "  adding: content/llama.cpp/docs/development/llama-star/idea-arch.pdf (deflated 27%)\n",
            "  adding: content/llama.cpp/docs/development/llama-star/idea-arch.key (deflated 24%)\n",
            "  adding: content/llama.cpp/docs/development/debugging-tests.md (deflated 56%)\n",
            "  adding: content/llama.cpp/tests/ (stored 0%)\n",
            "  adding: content/llama.cpp/tests/test-arg-parser.cpp (deflated 76%)\n",
            "  adding: content/llama.cpp/tests/test-llama-grammar.cpp (deflated 86%)\n",
            "  adding: content/llama.cpp/tests/test-tokenizer-random.py (deflated 73%)\n",
            "  adding: content/llama.cpp/tests/test-grammar-integration.cpp (deflated 84%)\n",
            "  adding: content/llama.cpp/tests/test-rope.cpp (deflated 74%)\n",
            "  adding: content/llama.cpp/tests/run-json-schema-to-grammar.mjs (deflated 39%)\n",
            "  adding: content/llama.cpp/tests/test-lora-conversion-inference.sh (deflated 73%)\n",
            "  adding: content/llama.cpp/tests/test-model-load-cancel.cpp (deflated 51%)\n",
            "  adding: content/llama.cpp/tests/test-c.c (deflated 7%)\n",
            "  adding: content/llama.cpp/tests/test-tokenizer-0.py (deflated 68%)\n",
            "  adding: content/llama.cpp/tests/test-tokenizer-1-bpe.cpp (deflated 70%)\n",
            "  adding: content/llama.cpp/tests/get-model.cpp (deflated 45%)\n",
            "  adding: content/llama.cpp/tests/test-tokenizer-0.sh (deflated 58%)\n",
            "  adding: content/llama.cpp/tests/CMakeLists.txt (deflated 80%)\n",
            "  adding: content/llama.cpp/tests/test-log.cpp (deflated 67%)\n",
            "  adding: content/llama.cpp/tests/test-sampling.cpp (deflated 82%)\n",
            "  adding: content/llama.cpp/tests/get-model.h (stored 0%)\n",
            "  adding: content/llama.cpp/tests/test-chat-template.cpp (deflated 85%)\n",
            "  adding: content/llama.cpp/tests/test-opt.cpp (deflated 84%)\n",
            "  adding: content/llama.cpp/tests/test-barrier.cpp (deflated 65%)\n",
            "  adding: content/llama.cpp/tests/test-backend-ops.cpp (deflated 84%)\n",
            "  adding: content/llama.cpp/tests/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/tests/test-grammar-parser.cpp (deflated 86%)\n",
            "  adding: content/llama.cpp/tests/test-json-schema-to-grammar.cpp (deflated 88%)\n",
            "  adding: content/llama.cpp/tests/test-quantize-perf.cpp (deflated 80%)\n",
            "  adding: content/llama.cpp/tests/test-tokenizer-0.cpp (deflated 74%)\n",
            "  adding: content/llama.cpp/tests/test-quantize-fns.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/tests/test-double-float.cpp (deflated 53%)\n",
            "  adding: content/llama.cpp/tests/test-tokenizer-1-spm.cpp (deflated 68%)\n",
            "  adding: content/llama.cpp/tests/test-gguf.cpp (deflated 84%)\n",
            "  adding: content/llama.cpp/tests/test-autorelease.cpp (deflated 50%)\n",
            "  adding: content/llama.cpp/.clang-format (deflated 62%)\n",
            "  adding: content/llama.cpp/CONTRIBUTING.md (deflated 55%)\n",
            "  adding: content/llama.cpp/mypy.ini (deflated 37%)\n",
            "  adding: content/llama.cpp/.github/ (stored 0%)\n",
            "  adding: content/llama.cpp/.github/pull_request_template.md (deflated 11%)\n",
            "  adding: content/llama.cpp/.github/ISSUE_TEMPLATE/ (stored 0%)\n",
            "  adding: content/llama.cpp/.github/ISSUE_TEMPLATE/030-research.yml (deflated 59%)\n",
            "  adding: content/llama.cpp/.github/ISSUE_TEMPLATE/040-refactor.yml (deflated 56%)\n",
            "  adding: content/llama.cpp/.github/ISSUE_TEMPLATE/config.yml (deflated 53%)\n",
            "  adding: content/llama.cpp/.github/ISSUE_TEMPLATE/011-bug-results.yml (deflated 60%)\n",
            "  adding: content/llama.cpp/.github/ISSUE_TEMPLATE/010-bug-compilation.yml (deflated 62%)\n",
            "  adding: content/llama.cpp/.github/ISSUE_TEMPLATE/020-enhancement.yml (deflated 63%)\n",
            "  adding: content/llama.cpp/.github/ISSUE_TEMPLATE/019-bug-misc.yml (deflated 62%)\n",
            "  adding: content/llama.cpp/.github/labeler.yml (deflated 79%)\n",
            "  adding: content/llama.cpp/.github/workflows/ (stored 0%)\n",
            "  adding: content/llama.cpp/.github/workflows/docker.yml (deflated 72%)\n",
            "  adding: content/llama.cpp/.github/workflows/server.yml (deflated 73%)\n",
            "  adding: content/llama.cpp/.github/workflows/close-issue.yml (deflated 51%)\n",
            "  adding: content/llama.cpp/.github/workflows/bench.yml.disabled (deflated 71%)\n",
            "  adding: content/llama.cpp/.github/workflows/build.yml (deflated 84%)\n",
            "  adding: content/llama.cpp/.github/workflows/python-check-requirements.yml (deflated 61%)\n",
            "  adding: content/llama.cpp/.github/workflows/editorconfig.yml (deflated 49%)\n",
            "  adding: content/llama.cpp/.github/workflows/python-lint.yml (deflated 50%)\n",
            "  adding: content/llama.cpp/.github/workflows/gguf-publish.yml (deflated 47%)\n",
            "  adding: content/llama.cpp/.github/workflows/labeler.yml (deflated 41%)\n",
            "  adding: content/llama.cpp/.github/workflows/python-type-check.yml (deflated 58%)\n",
            "  adding: content/llama.cpp/cmake/ (stored 0%)\n",
            "  adding: content/llama.cpp/cmake/arm64-windows-msvc.cmake (deflated 42%)\n",
            "  adding: content/llama.cpp/cmake/common.cmake (deflated 64%)\n",
            "  adding: content/llama.cpp/cmake/arm64-apple-clang.cmake (deflated 51%)\n",
            "  adding: content/llama.cpp/cmake/arm64-windows-llvm.cmake (deflated 51%)\n",
            "  adding: content/llama.cpp/cmake/llama.pc.in (deflated 27%)\n",
            "  adding: content/llama.cpp/cmake/build-info.cmake (deflated 65%)\n",
            "  adding: content/llama.cpp/cmake/llama-config.cmake.in (deflated 55%)\n",
            "  adding: content/llama.cpp/cmake/git-vars.cmake (deflated 61%)\n",
            "  adding: content/llama.cpp/cmake/x64-windows-llvm.cmake (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/include/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-blas.h (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-kompute.h (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-opt.h (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-metal.h (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-backend.h (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml.h (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-opencl.h (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-cann.h (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-alloc.h (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-cpu.h (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-vulkan.h (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-sycl.h (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-cuda.h (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/include/gguf.h (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-rpc.h (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/include/ggml-cpp.h (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/cmake/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/cmake/ggml-config.cmake.in (deflated 76%)\n",
            "  adding: content/llama.cpp/ggml/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-hip/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-hip/CMakeLists.txt (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-backend-reg.cpp (deflated 78%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/norm.hpp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/ggml-sycl.cpp (deflated 83%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/convert.cpp (deflated 92%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/rope.hpp (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/softmax.hpp (deflated 44%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/outprod.hpp (deflated 29%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/rope.cpp (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/dpct/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/dpct/helper.hpp (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/tsembd.cpp (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/tsembd.hpp (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/mmvq.cpp (deflated 94%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/dequantize.hpp (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/mmq.cpp (deflated 91%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/norm.cpp (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/mmvq.hpp (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/gemm.hpp (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/element_wise.hpp (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/dmmv.cpp (deflated 86%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/concat.cpp (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/conv.cpp (deflated 65%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/mmq.hpp (deflated 49%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/vecdotq.hpp (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/gla.hpp (deflated 27%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/wkv6.hpp (deflated 26%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/dmmv.hpp (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/gla.cpp (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/outprod.cpp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/im2col.hpp (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/common.cpp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/im2col.cpp (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/CMakeLists.txt (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/softmax.cpp (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/wkv6.cpp (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/concat.hpp (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/backend.hpp (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/common.hpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/conv.hpp (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/element_wise.cpp (deflated 92%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/convert.hpp (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-sycl/presets.hpp (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-backend.cpp (deflated 83%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-quants.h (deflated 90%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-quants.c (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/ggml-opencl.cpp (deflated 86%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ggml-opencl_mul_mat_Ab_Bi_8x4.cl (deflated 76%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ggml-opencl_cvt.cl (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ggml-opencl_transpose_32_16.cl (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ggml-opencl_gemv_noshuffle.cl (deflated 89%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ggml-opencl_gemv_noshuffle_general.cl (deflated 89%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ggml-opencl_transpose_32.cl (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ggml-opencl.cl (deflated 89%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ggml-opencl_mm.cl (deflated 87%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/embed_kernel.py (deflated 42%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/kernels/ggml-opencl_transpose_16.cl (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opencl/CMakeLists.txt (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-rpc/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-rpc/ggml-rpc.cpp (deflated 83%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-rpc/CMakeLists.txt (deflated 37%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-blas/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-blas/ggml-blas.cpp (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-blas/CMakeLists.txt (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-opt.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/ggml-vulkan.cpp (deflated 86%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/cmake/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/cmake/host-toolchain.cmake.in (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/CMakeLists.txt (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_vec_q6_k.comp (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/gelu_quick.comp (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/div.comp (deflated 52%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_f32.comp (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/scale.comp (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/generic_binary_head.comp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/test_coopmat_support.comp (deflated 3%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_vec.comp (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q5_0.comp (deflated 54%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul.comp (deflated 52%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/rope_neox.comp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/rope_norm.comp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/concat.comp (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_funcs.comp (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/leaky_relu.comp (deflated 42%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/argsort.comp (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/wkv6.comp (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q8_0.comp (deflated 53%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_vec_base.comp (deflated 70%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/generic_unary_head.comp (deflated 76%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/upscale.comp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/flash_attn_cm2.comp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mm.comp (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/im2col.comp (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_iq4_nl.comp (deflated 51%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_funcs_cm2.comp (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/vulkan-shaders-gen.cpp (deflated 78%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/square.comp (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/rope_head.comp (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/gelu.comp (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/copy.comp (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_split_k_reduce.comp (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/group_norm.comp (deflated 65%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/cos.comp (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_vec_q4_k.comp (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/get_rows.comp (deflated 56%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/rms_norm.comp (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q4_1.comp (deflated 53%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/contig_copy.comp (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_vec_p021.comp (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q6_k.comp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mm_cm2.comp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_vec_q3_k.comp (deflated 73%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_head.comp (deflated 35%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/soft_max.comp (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/add.comp (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/copy_to_quant.comp (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/pad.comp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/CMakeLists.txt (deflated 34%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/tanh.comp (deflated 40%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_vec_nc.comp (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/relu.comp (deflated 40%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/repeat.comp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q5_1.comp (deflated 54%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/get_rows_quant.comp (deflated 56%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q5_k.comp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/copy_from_quant.comp (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_vec_q5_k.comp (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q4_k.comp (deflated 73%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/pool2d.comp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/silu.comp (deflated 41%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q2_k.comp (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/sum_rows.comp (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q4_0.comp (deflated 51%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/clamp.comp (deflated 41%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/types.comp (deflated 81%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/diag_mask_inf.comp (deflated 48%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/generic_head.comp (deflated 24%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/norm.comp (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/sin.comp (deflated 37%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/mul_mat_vec_q2_k.comp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/timestep_embedding.comp (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/acc.comp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/test_coopmat2_support.comp (deflated 3%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-vulkan/vulkan-shaders/dequant_q3_k.comp (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-threading.cpp (deflated 52%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml.c (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/get_row_f16.cpp (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/quantize_float_to_q4_0.cpp (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/get_row_f32.cpp (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/ascendc_kernels.h (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/quantize_f32_q8_0.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/CMakeLists.txt (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/quantize_f16_q8_0.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/get_row_q8_0.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/get_row_q4_0.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/kernels/dup.cpp (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/ggml-cann.cpp (deflated 81%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/.clang-format (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/Doxyfile (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/CMakeLists.txt (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/common.h (deflated 70%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/acl_tensor.h (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/aclnn_ops.h (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/aclnn_ops.cpp (deflated 86%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cann/acl_tensor.cpp (deflated 71%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-impl.h (deflated 73%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/config/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/config/FindSphinx.cmake (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/VERSION (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/LICENSE (deflated 65%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.git (deflated 17%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/pylintrc (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.ccls (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/kompute-config.cmake (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/push_folder_to_branch.sh (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/convert_shaders.py (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/build_release_linux.sh (deflated 41%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/build_release_windows.sh (deflated 29%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/scripts/requirements.txt (deflated 22%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/python-examples.rst (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/advanced-examples.rst (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/build-system.rst (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/raspberry-pi.rst (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/python-package.rst (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/mobile-android.rst (deflated 12%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/ci-tests.rst (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/shaders-to-headers.rst (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/convolutional-net.rst (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/custom-operations.rst (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/async-parallel.rst (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/reference.rst (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/community.rst (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/memory-management.rst (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/python-reference.rst (deflated 52%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/game-engine-godot.rst (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/variable-types.rst (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/overview/matmul-benchmark.rst (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/make.bat (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/conf.py (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/genindex.rst (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/index.rst (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/CMakeLists.txt (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/binder-cpp.jpg (deflated 31%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute.jpg (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-python-video.png (deflated 1%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/komputer-logos.gif (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-vulkan-architecture-tensor.jpg (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-cpp-video.png (deflated 2%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/komputer-2.gif (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/komputer-godot-4.gif (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/suspicious.jfif (deflated 10%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-vulkan-architecture-opcreatetensor.jpg (deflated 53%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/queue-allocation.jpg (deflated 44%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/binder-python.jpg (deflated 28%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/logistic-regression.jpg (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-architecture.jpg (deflated 27%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-vulkan-architecture-manager.jpg (deflated 54%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/android-kompute.jpg (deflated 21%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-vulkan-architecture-algorithm.jpg (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-vulkan-architecture-sequence.jpg (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-vulkan-architecture-opmult.jpg (deflated 52%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/android-editor.jpg (deflated 30%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-vulkan-architecture-operations.jpg (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/images/kompute-vulkan-architecture.jpg (deflated 52%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/assets/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/assets/gcov.css (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/assets/custom.css (deflated 56%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/Doxyfile.in (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docs/Makefile (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.clang-format (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/GOVERNANCE.md (deflated 52%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/CONTRIBUTING.md (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/setup.py (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.github/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.github/workflows/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.github/workflows/cpp_examples.yml (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.github/workflows/python_tests.yml (deflated 46%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.github/workflows/cpp_tests.yml (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/cmake/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/cmake/vulkan_shader_compiler.cmake (deflated 71%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/cmake/bin2h.cmake (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/cmake/bin_file_to_header.cmake (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/cmake/deprecation_warnings.cmake (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/cmake/check_vulkan_version.cmake (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/cmake/code_coverage.cmake (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/cmake/komputeConfig.cmake.in (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/CODE_OF_CONDUCT.md (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/CHANGELOG.md (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/SECURITY.md (deflated 39%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/OpBufferSyncDevice.cpp (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/Algorithm.cpp (deflated 82%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/logger/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/logger/Logger.cpp (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/logger/CMakeLists.txt (deflated 73%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/Manager.hpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/Kompute.hpp (deflated 65%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/logger/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/logger/Logger.hpp (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/Algorithm.hpp (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/Sequence.hpp (deflated 81%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpTensorCopy.hpp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpBase.hpp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpMemoryBarrier.hpp (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpTensorFill.hpp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpBufferSyncDevice.hpp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpMult.hpp (deflated 56%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpTensorSyncLocal.hpp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpAlgoDispatch.hpp (deflated 65%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpBufferSyncLocal.hpp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/operations/OpTensorSyncDevice.hpp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/Core.hpp (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/kompute/Tensor.hpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/include/CMakeLists.txt (deflated 71%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/OpBufferSyncLocal.cpp (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/Core.cpp (deflated 44%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/OpMemoryBarrier.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/Manager.cpp (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/OpAlgoDispatch.cpp (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/Tensor.cpp (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/OpTensorSyncLocal.cpp (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/CMakeLists.txt (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/OpTensorCopy.cpp (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/glsl/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/glsl/ShaderLogisticRegression.comp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/glsl/ShaderOpMult.comp (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/glsl/CMakeLists.txt (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/glsl/ShaderLogisticRegression.hpp.in (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/glsl/ShaderOpMult.hpp.in (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/CMakeLists.txt (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/hlsl/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/shaders/hlsl/computeheadless.comp (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/OpTensorSyncDevice.cpp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/OpTensorFill.cpp (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/src/Sequence.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/MANIFEST.in (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/CMakeLists.txt (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/CNAME (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/README.md (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/vcpkg.json.opt (deflated 23%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/external/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/external/bin/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/external/bin/xxd.c (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.gitignore (deflated 53%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestOpTensorCopy.cpp (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestOpTensorCreate.cpp (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestPushConstant.cpp (deflated 89%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestWorkgroup.cpp (deflated 76%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestSequence.cpp (deflated 82%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestTensor.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestLogisticRegression.cpp (deflated 83%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/CMakeLists.txt (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestSpecializationConstant.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/compiled_shaders_include/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/compiled_shaders_include/kompute_test/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/compiled_shaders_include/kompute_test/shaders/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/compiled_shaders_include/kompute_test/shaders/shadertest_logistic_regression.hpp (deflated 89%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/compiled_shaders_include/kompute_test/shaders/shadertest_op_custom_shader.hpp (deflated 82%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/compiled_shaders_include/kompute_test/shaders/shadertest_workgroup.hpp (deflated 83%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/Utils.hpp (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/glsl/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/glsl/test_logistic_regression_shader.comp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/glsl/test_op_custom_shader.comp (deflated 37%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/glsl/test_shader.comp (deflated 37%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/glsl/CMakeLists.txt (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/glsl/test_workgroup_shader.comp (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/CMakeLists.txt (deflated 21%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/shaders/Utils.cpp (deflated 53%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestAsyncOperations.cpp (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestDestroy.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestMultipleAlgoExecutions.cpp (deflated 83%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestOpShadersFromStringAndFile.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestManager.cpp (deflated 83%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/test/TestOpTensorSync.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/src/utils.hpp (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/src/docstrings.hpp (deflated 81%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/src/main.cpp (deflated 88%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/CMakeLists.txt (deflated 22%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/README.md (deflated 18%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/test_array_multiplication.py (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/test_logistic_regression.py (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/test_tensor_types.py (deflated 86%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/__init__.py (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/requirements-dev.txt (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/test_kompute.py (deflated 78%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/python/test/utils.py (deflated 41%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/Dockerfile (deflated 24%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docker-builders/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docker-builders/Swiftshader.Dockerfile (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docker-builders/VulkanSDK.Dockerfile (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docker-builders/KomputeBuilder.Dockerfile (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/docker-builders/Makefile (deflated 71%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/logistic_regression/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/logistic_regression/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/logistic_regression/src/CMakeLists.txt (deflated 26%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/logistic_regression/src/main.cpp (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/logistic_regression/shader/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/logistic_regression/shader/CMakeLists.txt (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/logistic_regression/shader/my_shader.comp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/logistic_regression/CMakeLists.txt (deflated 49%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/logistic_regression/README.md (deflated 49%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/python_naive_matmul/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/python_naive_matmul/imp3_better_tiling.py (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/python_naive_matmul/imp1_naive.py (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/python_naive_matmul/first_example.py (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/python_naive_matmul/README.md (deflated 37%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/python_naive_matmul/benchmark.py (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/python_naive_matmul/matmul_plot.py (deflated 78%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/python_naive_matmul/imp2_tiled.py (deflated 70%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/array_multiplication/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/array_multiplication/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/array_multiplication/src/CMakeLists.txt (deflated 21%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/array_multiplication/src/main.cpp (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/array_multiplication/shader/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/array_multiplication/shader/CMakeLists.txt (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/array_multiplication/shader/my_shader.comp (deflated 39%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/array_multiplication/CMakeLists.txt (deflated 49%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/array_multiplication/README.md (deflated 48%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/project.godot (deflated 46%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/.gdignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/src/.gdignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/src/KomputeModelML.hpp (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/src/KomputeModelML.cpp (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/src/KomputeGdNative.cpp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/CMakeLists.txt (deflated 53%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/README.md (deflated 44%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/gdnative_shared/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/scripts/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/scripts/CustomModuleExampleScene.gd (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/scripts/DynamicExampleScript.gd (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/scripts/KomputeNativeLibrary.gdnlib (deflated 24%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/scripts/KomputeNativeClass.gdns (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/assets/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/assets/CustomModuleExampleScene.tscn (deflated 34%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/assets/icon.png (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/assets/TextFormat.theme (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/assets/DynamicExampleScene.tscn (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/assets/default_env.tres (deflated 26%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/assets/icon.png.import (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_resources/assets/roboto.ttf (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/README.md (deflated 44%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/.gdignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/README.md (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/kompute_model_ml/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/kompute_model_ml/config.py (deflated 12%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/kompute_model_ml/include/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/kompute_model_ml/include/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/kompute_model_ml/KomputeModelMLNode.h (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/kompute_model_ml/register_types.cpp (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/kompute_model_ml/SCsub (deflated 39%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/kompute_model_ml/register_types.h (deflated 37%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/kompute_model_ml/KomputeModelMLNode.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/custom_module/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/.gitignore (deflated 7%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_engine/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_logistic_regression/godot_engine/.gdignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/project.godot (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/.gdignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/src/KomputeSummator.cpp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/src/.gdignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/src/KomputeGdNative.cpp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/src/KomputeSummator.hpp (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/CMakeLists.txt (deflated 53%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/README.md (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/gdnative_shared/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/scripts/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/scripts/CustomModuleExampleScene.gd (deflated 58%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/scripts/DynamicExampleScript.gd (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/scripts/KomputeNativeLibrary.gdnlib (deflated 24%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/scripts/KomputeNativeClass.gdns (deflated 39%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/assets/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/assets/CustomModuleExampleScene.tscn (deflated 33%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/assets/icon.png (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/assets/DynamicExampleScene.tscn (deflated 48%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/assets/default_env.tres (deflated 26%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_resources/assets/icon.png.import (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/README.md (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/.gdignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/README.md (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/kompute_summator/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/kompute_summator/config.py (deflated 12%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/kompute_summator/KomputeSummatorNode.cpp (deflated 65%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/kompute_summator/include/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/kompute_summator/include/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/kompute_summator/register_types.cpp (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/kompute_summator/KomputeSummatorNode.h (deflated 51%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/kompute_summator/SCsub (deflated 39%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/custom_module/kompute_summator/register_types.h (deflated 37%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/.gitignore (deflated 7%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_engine/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/godot_examples/godot_engine/.gdignore (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/pi4_mesa_build/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/pi4_mesa_build/README.md (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/out.png (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/sh_conv.py (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/import_vgg7.py (deflated 44%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/README.md (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/run_vgg7.py (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/.gitignore (deflated 4%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/w2wbinit.png (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/neural_network_vgg7/sh_common.py (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/gradle.properties (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/gradle/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/gradle/wrapper/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/gradle/wrapper/gradle-wrapper.properties (deflated 34%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/gradlew (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/build.gradle (deflated 46%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/settings.gradle (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/gradlew.bat (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/README.md (deflated 48%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/build.gradle (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/java/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/java/com/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/java/com/ethicalml/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/java/com/ethicalml/kompute/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/java/com/ethicalml/kompute/KomputeJni.kt (deflated 70%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/layout/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/layout/activity_kompute_jni.xml (deflated 90%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-hdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-hdpi/ic_launcher.png (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/values/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/values/colors.xml (deflated 39%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/values/kompute_icon_background.xml (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/values/strings.xml (deflated 21%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/values/styles.xml (deflated 52%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/values/dimens.xml (deflated 38%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-mdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-mdpi/ic_launcher.png (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-anydpi-v26/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-anydpi-v26/kompute_icon.xml (deflated 40%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-xxxhdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-xxxhdpi/ic_launcher.png (deflated 1%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/values-w820dp/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/values-w820dp/dimens.xml (deflated 32%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-xxhdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-xxhdpi/ic_launcher.png (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-xhdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-xhdpi/kompute_icon_foreground.png (deflated 4%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-xhdpi/ic_launcher.png (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/res/mipmap-xhdpi/kompute_icon.png (deflated 4%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/cpp/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/cpp/KomputeJniNative.cpp (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/cpp/shader/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/cpp/shader/CMakeLists.txt (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/cpp/shader/my_shader.comp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/cpp/CMakeLists.txt (deflated 47%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/cpp/KomputeModelML.hpp (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/cpp/KomputeModelML.cpp (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/assets/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/assets/kompute.jpg (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/assets/komputer-2.gif (deflated 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/src/main/AndroidManifest.xml (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/app/proguard-rules.pro (deflated 39%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/examples/android/android-simple/.gitignore (deflated 7%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/.dockerignore (deflated 6%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute/Makefile (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/ggml-kompute.cpp (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/CMakeLists.txt (deflated 79%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_getrows.comp (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul.comp (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_getrows_q4_1.comp (deflated 51%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_rope_neox_f16.comp (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_gelu.comp (deflated 42%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_getrows_q4_0.comp (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul_mv_q_n_pre.comp (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_add.comp (deflated 59%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul_mat_q6_k.comp (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_softmax.comp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul_mat_q4_0.comp (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_rope_norm_f16.comp (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_getrows_f16.comp (deflated 49%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_cpy_f32_f16.comp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_scale.comp (deflated 41%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_addrow.comp (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_rope_norm_f32.comp (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul_mv_q_n.comp (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_cpy_f16_f32.comp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul_mat_q4_1.comp (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/rope_common.comp (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_norm.comp (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_getrows_f32.comp (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_silu.comp (deflated 44%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_rmsnorm.comp (deflated 62%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_cpy_f32_f32.comp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul_mat_q4_k.comp (deflated 73%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul_mat_mat_f32.comp (deflated 54%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_relu.comp (deflated 43%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul_mat_f16.comp (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_cpy_f16_f16.comp (deflated 64%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_mul_mat_q8_0.comp (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_diagmask.comp (deflated 53%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/common.comp (deflated 70%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_scale_8.comp (deflated 44%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_rope_neox_f32.comp (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-kompute/kompute-shaders/op_getrows_q6_k.comp (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-alloc.c (deflated 81%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-threading.h (deflated 36%)\n",
            "  adding: content/llama.cpp/ggml/src/CMakeLists.txt (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-traits.h (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-quants.h (deflated 92%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-aarch64.cpp (deflated 88%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-impl.h (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/amx/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/amx/mmq.cpp (deflated 86%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/amx/amx.h (deflated 28%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/amx/common.h (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/amx/mmq.h (deflated 56%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/amx/amx.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-hbm.cpp (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-traits.cpp (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/cpu-feats-x86.cpp (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/cmake/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/cmake/FindSIMD.cmake (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-quants.c (deflated 88%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/llamafile/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.cpp (deflated 86%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.h (deflated 52%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c (deflated 87%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/CMakeLists.txt (deflated 78%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-hbm.h (deflated 27%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cpu/ggml-cpu-aarch64.h (deflated 26%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-metal/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-metal/ggml-metal.metal (deflated 87%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-metal/ggml-metal-impl.h (deflated 87%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-metal/CMakeLists.txt (deflated 73%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-metal/ggml-metal.m (deflated 88%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-musa/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-musa/CMakeLists.txt (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/gguf.cpp (deflated 83%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-backend-impl.h (deflated 78%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/unary.cuh (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/rope.cu (deflated 86%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn-wmma-f16.cuh (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/pad.cu (deflated 63%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/mmq.cuh (deflated 88%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/tsembd.cu (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/im2col.cu (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/conv-transpose-1d.cu (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/dequantize.cuh (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/rope.cuh (deflated 40%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/upscale.cu (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/wkv6.cuh (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/unary.cu (deflated 91%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/arange.cuh (deflated 7%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/norm.cu (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/argmax.cu (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/concat.cu (deflated 79%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn-vec-f16.cuh (deflated 79%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/cpy.cuh (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/mmv.cuh (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/norm.cuh (deflated 70%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/ggml-cuda.cu (deflated 81%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/out-prod.cu (deflated 66%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/mmvq.cuh (deflated 45%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/concat.cuh (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/mmvq.cu (deflated 87%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/diagmask.cu (deflated 61%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f16.cu (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/argmax.cuh (deflated 13%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/vendors/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/vendors/cuda.h (deflated 51%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/vendors/hip.h (deflated 74%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/vendors/musa.h (deflated 76%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/pool2d.cu (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/binbcast.cuh (deflated 76%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/quantize.cu (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/sumrows.cuh (deflated 33%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/conv-transpose-1d.cuh (deflated 10%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/softmax.cu (deflated 78%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/ (stored 0%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_0-q5_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_0-q4_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_1-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_0-q4_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_1-q4_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_0-q5_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_1.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_1.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_1-f16.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_1-q5_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-f16.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_1-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_1-q4_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-q4_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-q5_0.cu (deflated 14%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_0-q5_1.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_1-f16.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-q4_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q4_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-q5_0.cu (deflated 14%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_1-q4_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-q8_0.cu (deflated 14%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-q5_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_1-f16.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-f16.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q5_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_1-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q4_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-q4_1.cu (deflated 14%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu (deflated 53%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_1-q5_1.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_1-q4_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_0-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-q4_0.cu (deflated 14%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_1-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_1-q5_1.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_1-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q5_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_0-q4_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_0-f16.cu (deflated 14%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-q4_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_0-q5_1.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-q5_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_1-f16.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/generate_cu_files.py (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q5_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_0-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu (deflated 50%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_1-q4_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_0-f16.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_0-q4_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-q4_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q4_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-q4_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_1-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q5_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q5_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu (deflated 54%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q5_1-q5_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu (deflated 42%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-f16.cu (deflated 14%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q5_1-q4_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-q4_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.cu (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu (deflated 55%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_1-q4_1.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-q8_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_1-q4_1.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q4_1.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_1-q5_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_1-q5_0.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-f16.cu (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/cpy.cu (deflated 87%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/pad.cuh (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/tsembd.cuh (deflated 10%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/acc.cu (deflated 65%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/CMakeLists.txt (deflated 70%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/sumrows.cu (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/acc.cuh (deflated 8%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/diagmask.cuh (deflated 9%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/sum.cuh (deflated 32%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/getrows.cu (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f32.cu (deflated 78%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/argsort.cu (deflated 67%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/arange.cu (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn.cuh (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/wkv6.cu (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/count-equal.cu (deflated 60%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/opt-step-adamw.cu (deflated 72%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/cross-entropy-loss.cu (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/im2col.cuh (deflated 7%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/opt-step-adamw.cuh (deflated 9%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/scale.cu (deflated 56%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/cross-entropy-loss.cuh (deflated 40%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/scale.cuh (deflated 7%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f16.cuh (deflated 14%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/common.cuh (deflated 77%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/getrows.cuh (deflated 46%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/sum.cu (deflated 56%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn.cu (deflated 89%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/clamp.cu (deflated 57%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/softmax.cuh (deflated 39%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn-common.cuh (deflated 81%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/convert.cu (deflated 85%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/gla.cu (deflated 69%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn-tile-f32.cuh (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/mmq.cu (deflated 76%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/convert.cuh (deflated 42%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/out-prod.cuh (deflated 14%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/quantize.cuh (deflated 68%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/count-equal.cuh (deflated 9%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/binbcast.cu (deflated 79%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/argsort.cuh (deflated 16%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/fattn-vec-f32.cuh (deflated 80%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/gla.cuh (deflated 15%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/mma.cuh (deflated 86%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/upscale.cuh (deflated 7%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/mmv.cu (deflated 81%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/vecdotq.cuh (deflated 84%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/pool2d.cuh (deflated 7%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-cuda/clamp.cuh (deflated 7%)\n",
            "  adding: content/llama.cpp/ggml/src/ggml-common.h (deflated 83%)\n",
            "  adding: content/llama.cpp/ggml/CMakeLists.txt (deflated 71%)\n",
            "  adding: content/llama.cpp/ggml/.gitignore (deflated 36%)\n",
            "  adding: content/llama.cpp/.editorconfig (deflated 61%)\n",
            "  adding: content/llama.cpp/SECURITY.md (deflated 55%)\n",
            "  adding: content/llama.cpp/grammars/ (stored 0%)\n",
            "  adding: content/llama.cpp/grammars/json.gbnf (deflated 44%)\n",
            "  adding: content/llama.cpp/grammars/arithmetic.gbnf (deflated 33%)\n",
            "  adding: content/llama.cpp/grammars/list.gbnf (deflated 8%)\n",
            "  adding: content/llama.cpp/grammars/README.md (deflated 67%)\n",
            "  adding: content/llama.cpp/grammars/c.gbnf (deflated 64%)\n",
            "  adding: content/llama.cpp/grammars/chess.gbnf (deflated 44%)\n",
            "  adding: content/llama.cpp/grammars/english.gbnf (deflated 31%)\n",
            "  adding: content/llama.cpp/grammars/json_arr.gbnf (deflated 46%)\n",
            "  adding: content/llama.cpp/grammars/japanese.gbnf (deflated 33%)\n",
            "  adding: content/llama.cpp/llama-export-lora (deflated 62%)\n",
            "  adding: content/llama.cpp/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/src/llama-kv-cache.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/src/llama-arch.cpp (deflated 92%)\n",
            "  adding: content/llama.cpp/src/llama-kv-cache.h (deflated 72%)\n",
            "  adding: content/llama.cpp/src/llama-mmap.cpp (deflated 77%)\n",
            "  adding: content/llama.cpp/src/llama-model.h (deflated 84%)\n",
            "  adding: content/llama.cpp/src/llama-arch.h (deflated 77%)\n",
            "  adding: content/llama.cpp/src/llama-model-loader.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/src/llama-sampling.h (deflated 59%)\n",
            "  adding: content/llama.cpp/src/llama-hparams.cpp (deflated 71%)\n",
            "  adding: content/llama.cpp/src/llama-grammar.h (deflated 70%)\n",
            "  adding: content/llama.cpp/src/unicode-data.h (deflated 60%)\n",
            "  adding: content/llama.cpp/src/llama-context.cpp (deflated 82%)\n",
            "  adding: content/llama.cpp/src/llama-impl.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/src/llama-model.cpp (deflated 89%)\n",
            "  adding: content/llama.cpp/src/llama-impl.h (deflated 64%)\n",
            "  adding: content/llama.cpp/src/llama-vocab.h (deflated 78%)\n",
            "  adding: content/llama.cpp/src/llama-sampling.cpp (deflated 81%)\n",
            "  adding: content/llama.cpp/src/llama-mmap.h (deflated 66%)\n",
            "  adding: content/llama.cpp/src/unicode.h (deflated 68%)\n",
            "  adding: content/llama.cpp/src/llama-batch.cpp (deflated 78%)\n",
            "  adding: content/llama.cpp/src/llama-adapter.cpp (deflated 74%)\n",
            "  adding: content/llama.cpp/src/CMakeLists.txt (deflated 63%)\n",
            "  adding: content/llama.cpp/src/llama.cpp (deflated 89%)\n",
            "  adding: content/llama.cpp/src/llama-model-loader.h (deflated 71%)\n",
            "  adding: content/llama.cpp/src/unicode-data.cpp (deflated 78%)\n",
            "  adding: content/llama.cpp/src/unicode.cpp (deflated 81%)\n",
            "  adding: content/llama.cpp/src/llama-context.h (deflated 68%)\n",
            "  adding: content/llama.cpp/src/llama-chat.cpp (deflated 82%)\n",
            "  adding: content/llama.cpp/src/llama-quant.cpp (deflated 78%)\n",
            "  adding: content/llama.cpp/src/llama-vocab.cpp (deflated 81%)\n",
            "  adding: content/llama.cpp/src/llama-chat.h (deflated 72%)\n",
            "  adding: content/llama.cpp/src/llama-cparams.cpp (stored 0%)\n",
            "  adding: content/llama.cpp/src/llama-batch.h (deflated 66%)\n",
            "  adding: content/llama.cpp/src/llama-hparams.h (deflated 67%)\n",
            "  adding: content/llama.cpp/src/llama-quant.h (stored 0%)\n",
            "  adding: content/llama.cpp/src/llama-cparams.h (deflated 54%)\n",
            "  adding: content/llama.cpp/src/llama-adapter.h (deflated 68%)\n",
            "  adding: content/llama.cpp/src/llama-grammar.cpp (deflated 81%)\n",
            "  adding: content/llama.cpp/flake.lock (deflated 66%)\n",
            "  adding: content/llama.cpp/CMakeLists.txt (deflated 69%)\n",
            "  adding: content/llama.cpp/Package.swift (deflated 49%)\n",
            "  adding: content/llama.cpp/README.md (deflated 65%)\n",
            "  adding: content/llama.cpp/common/ (stored 0%)\n",
            "  adding: content/llama.cpp/common/json-schema-to-grammar.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/common/minja.hpp (deflated 82%)\n",
            "  adding: content/llama.cpp/common/log.h (deflated 70%)\n",
            "  adding: content/llama.cpp/common/speculative.h (deflated 62%)\n",
            "  adding: content/llama.cpp/common/console.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/common/arg.h (deflated 76%)\n",
            "  adding: content/llama.cpp/common/ngram-cache.h (deflated 66%)\n",
            "  adding: content/llama.cpp/common/cmake/ (stored 0%)\n",
            "  adding: content/llama.cpp/common/cmake/build-info-gen-cpp.cmake (deflated 63%)\n",
            "  adding: content/llama.cpp/common/build-info.cpp (deflated 32%)\n",
            "  adding: content/llama.cpp/common/base64.hpp (deflated 76%)\n",
            "  adding: content/llama.cpp/common/log.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/common/common.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/common/CMakeLists.txt (deflated 62%)\n",
            "  adding: content/llama.cpp/common/common.h (deflated 72%)\n",
            "  adding: content/llama.cpp/common/build-info.cpp.in (deflated 53%)\n",
            "  adding: content/llama.cpp/common/ngram-cache.cpp (deflated 78%)\n",
            "  adding: content/llama.cpp/common/json-schema-to-grammar.h (deflated 56%)\n",
            "  adding: content/llama.cpp/common/sampling.h (deflated 68%)\n",
            "  adding: content/llama.cpp/common/stb_image.h (deflated 75%)\n",
            "  adding: content/llama.cpp/common/json.hpp (deflated 85%)\n",
            "  adding: content/llama.cpp/common/arg.cpp (deflated 82%)\n",
            "  adding: content/llama.cpp/common/chat-template.hpp (deflated 78%)\n",
            "  adding: content/llama.cpp/common/sampling.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/common/speculative.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/common/console.h (deflated 44%)\n",
            "  adding: content/llama.cpp/pocs/ (stored 0%)\n",
            "  adding: content/llama.cpp/pocs/vdot/ (stored 0%)\n",
            "  adding: content/llama.cpp/pocs/vdot/vdot.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/pocs/vdot/CMakeLists.txt (deflated 59%)\n",
            "  adding: content/llama.cpp/pocs/vdot/q8dot.cpp (deflated 70%)\n",
            "  adding: content/llama.cpp/pocs/CMakeLists.txt (deflated 21%)\n",
            "  adding: content/llama.cpp/AUTHORS (deflated 61%)\n",
            "  adding: content/llama.cpp/convert_lora_to_gguf.py (deflated 72%)\n",
            "  adding: content/llama.cpp/models/ (stored 0%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-phi-3.gguf (deflated 74%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-deepseek-llm.gguf.out (deflated 70%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-qwen2.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-deepseek-llm.gguf (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-mpt.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-roberta-bpe.gguf.out (deflated 72%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-llama-spm.gguf.out (deflated 76%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-gpt-2.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-chameleon.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-chameleon.gguf.out (deflated 78%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-refact.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-gpt-neox.gguf (deflated 70%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-deepseek-r1-qwen.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-deepseek-coder.gguf.out (deflated 71%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-qwen2.gguf.out (deflated 67%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-bert-bge.gguf (deflated 77%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-deepseek-coder.gguf (deflated 70%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-starcoder.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-starcoder.gguf.out (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-llama-bpe.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-qwen2.gguf (deflated 71%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-command-r.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/.editorconfig (stored 0%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-llama-spm.gguf (deflated 74%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-llama-bpe.gguf (deflated 72%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-refact.gguf (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-bert-bge.gguf.out (deflated 74%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-mpt.gguf.out (deflated 68%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-llama-spm.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-falcon.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-deepseek-r1-qwen.gguf.out (deflated 67%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-gpt-2.gguf (deflated 71%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-baichuan.gguf (deflated 74%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-phi-3.gguf.out (deflated 76%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-mpt.gguf (deflated 70%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-falcon.gguf (deflated 70%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-command-r.gguf.out (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-starcoder.gguf (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-aquila.gguf (deflated 72%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-refact.gguf.out (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-deepseek-coder.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-gpt-2.gguf.out (deflated 71%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-phi-3.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-llama-bpe.gguf.out (deflated 67%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-falcon.gguf.out (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-roberta-bpe.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-command-r.gguf (deflated 67%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-deepseek-llm.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/models/ggml-vocab-bert-bge.gguf.inp (deflated 69%)\n",
            "  adding: content/llama.cpp/prompts/ (stored 0%)\n",
            "  adding: content/llama.cpp/prompts/mnemonics.txt (deflated 52%)\n",
            "  adding: content/llama.cpp/prompts/chat-with-vicuna-v1.txt (deflated 43%)\n",
            "  adding: content/llama.cpp/prompts/parallel-questions.txt (deflated 50%)\n",
            "  adding: content/llama.cpp/prompts/chat-with-vicuna-v0.txt (deflated 44%)\n",
            "  adding: content/llama.cpp/prompts/chat.txt (deflated 53%)\n",
            "  adding: content/llama.cpp/prompts/alpaca.txt (deflated 18%)\n",
            "  adding: content/llama.cpp/prompts/dan.txt (deflated 53%)\n",
            "  adding: content/llama.cpp/prompts/chat-with-qwen.txt (stored 0%)\n",
            "  adding: content/llama.cpp/prompts/assistant.txt (deflated 60%)\n",
            "  adding: content/llama.cpp/prompts/chat-with-bob.txt (deflated 38%)\n",
            "  adding: content/llama.cpp/prompts/LLM-questions.txt (deflated 76%)\n",
            "  adding: content/llama.cpp/prompts/dan-modified.txt (deflated 53%)\n",
            "  adding: content/llama.cpp/prompts/chat-with-baichuan.txt (deflated 3%)\n",
            "  adding: content/llama.cpp/prompts/reason-act.txt (deflated 53%)\n",
            "  adding: content/llama.cpp/requirements.txt (deflated 60%)\n",
            "  adding: content/llama.cpp/.gitignore (deflated 52%)\n",
            "  adding: content/llama.cpp/media/ (stored 0%)\n",
            "  adding: content/llama.cpp/media/llama0-banner.png (deflated 8%)\n",
            "  adding: content/llama.cpp/media/llama1-banner.png (deflated 21%)\n",
            "  adding: content/llama.cpp/media/matmul.svg (deflated 93%)\n",
            "  adding: content/llama.cpp/media/llama0-logo.png (deflated 2%)\n",
            "  adding: content/llama.cpp/media/matmul.png (deflated 15%)\n",
            "  adding: content/llama.cpp/media/llama1-logo.png (deflated 18%)\n",
            "  adding: content/llama.cpp/poetry.lock (deflated 71%)\n",
            "  adding: content/llama.cpp/convert_hf_to_gguf.py (deflated 82%)\n",
            "  adding: content/llama.cpp/spm-headers/ (stored 0%)\n",
            "  adding: content/llama.cpp/spm-headers/ggml-metal.h (deflated 58%)\n",
            "  adding: content/llama.cpp/spm-headers/ggml-backend.h (deflated 80%)\n",
            "  adding: content/llama.cpp/spm-headers/ggml.h (deflated 84%)\n",
            "  adding: content/llama.cpp/spm-headers/ggml-alloc.h (deflated 68%)\n",
            "  adding: content/llama.cpp/spm-headers/ggml-cpu.h (deflated 77%)\n",
            "  adding: content/llama.cpp/spm-headers/llama.h (deflated 78%)\n",
            "  adding: content/llama.cpp/spm-headers/ggml-cpp.h (deflated 74%)\n",
            "  adding: content/llama.cpp/CMakePresets.json (deflated 84%)\n",
            "  adding: content/llama.cpp/.clang-tidy (deflated 54%)\n",
            "  adding: content/llama.cpp/examples/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.vim (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/pydantic_models_to_grammar.py (deflated 82%)\n",
            "  adding: content/llama.cpp/examples/passkey/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/passkey/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/passkey/README.md (deflated 38%)\n",
            "  adding: content/llama.cpp/examples/passkey/passkey.cpp (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/pydantic_models_to_grammar_examples.py (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/retrieval/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/retrieval/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/retrieval/README.md (deflated 50%)\n",
            "  adding: content/llama.cpp/examples/retrieval/retrieval.cpp (deflated 70%)\n",
            "  adding: content/llama.cpp/examples/reason-act.sh (deflated 32%)\n",
            "  adding: content/llama.cpp/examples/json_schema_to_grammar.py (deflated 75%)\n",
            "  adding: content/llama.cpp/examples/lookup/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/lookup/lookup.cpp (deflated 72%)\n",
            "  adding: content/llama.cpp/examples/lookup/lookup-create.cpp (deflated 55%)\n",
            "  adding: content/llama.cpp/examples/lookup/lookup-merge.cpp (deflated 64%)\n",
            "  adding: content/llama.cpp/examples/lookup/lookup-stats.cpp (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/lookup/CMakeLists.txt (deflated 79%)\n",
            "  adding: content/llama.cpp/examples/lookup/README.md (deflated 43%)\n",
            "  adding: content/llama.cpp/examples/chat-vicuna.sh (deflated 44%)\n",
            "  adding: content/llama.cpp/examples/perplexity/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/perplexity/CMakeLists.txt (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/perplexity/README.md (deflated 70%)\n",
            "  adding: content/llama.cpp/examples/perplexity/perplexity.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/examples/Miku.sh (deflated 54%)\n",
            "  adding: content/llama.cpp/examples/server-llama2-13B.sh (deflated 38%)\n",
            "  adding: content/llama.cpp/examples/server_embd.py (deflated 55%)\n",
            "  adding: content/llama.cpp/examples/embedding/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/embedding/embedding.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/embedding/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/embedding/README.md (deflated 63%)\n",
            "  adding: content/llama.cpp/examples/llama.android/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/gradle.properties (deflated 48%)\n",
            "  adding: content/llama.cpp/examples/llama.android/settings.gradle.kts (deflated 48%)\n",
            "  adding: content/llama.cpp/examples/llama.android/gradle/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/gradle/wrapper/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/gradle/wrapper/gradle-wrapper.properties (deflated 35%)\n",
            "  adding: content/llama.cpp/examples/llama.android/gradle/wrapper/gradle-wrapper.jar (deflated 10%)\n",
            "  adding: content/llama.cpp/examples/llama.android/gradlew (deflated 60%)\n",
            "  adding: content/llama.cpp/examples/llama.android/build.gradle.kts (deflated 42%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/consumer-rules.pro (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/androidTest/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/androidTest/java/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/androidTest/java/android/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/androidTest/java/android/llama/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/androidTest/java/android/llama/cpp/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/androidTest/java/android/llama/cpp/ExampleInstrumentedTest.kt (deflated 49%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/java/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/java/android/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/java/android/llama/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/java/android/llama/cpp/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/java/android/llama/cpp/LLamaAndroid.kt (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/cpp/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/cpp/llama-android.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/cpp/CMakeLists.txt (deflated 53%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/main/AndroidManifest.xml (deflated 17%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/test/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/test/java/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/test/java/android/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/test/java/android/llama/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/test/java/android/llama/cpp/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/src/test/java/android/llama/cpp/ExampleUnitTest.kt (deflated 33%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/build.gradle.kts (deflated 60%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/llama/proguard-rules.pro (deflated 44%)\n",
            "  adding: content/llama.cpp/examples/llama.android/README.md (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/llama/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/llama/MainActivity.kt (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/llama/ui/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/llama/ui/theme/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/llama/ui/theme/Color.kt (deflated 45%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/llama/ui/theme/Theme.kt (deflated 65%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/llama/ui/theme/Type.kt (deflated 68%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/llama/MainViewModel.kt (deflated 70%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/java/com/example/llama/Downloadable.kt (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-hdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-hdpi/ic_launcher.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-hdpi/ic_launcher_round.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/values/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/values/colors.xml (deflated 58%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/values/strings.xml (deflated 20%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/values/themes.xml (deflated 17%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-mdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-mdpi/ic_launcher.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-mdpi/ic_launcher_round.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-anydpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-anydpi/ic_launcher_round.xml (deflated 53%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-anydpi/ic_launcher.xml (deflated 53%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/drawable/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/drawable/ic_launcher_background.xml (deflated 93%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/drawable/ic_launcher_foreground.xml (deflated 63%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/xml/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/xml/data_extraction_rules.xml (deflated 49%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/xml/backup_rules.xml (deflated 43%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-xxxhdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-xxxhdpi/ic_launcher.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-xxxhdpi/ic_launcher_round.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-xxhdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-xxhdpi/ic_launcher.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-xxhdpi/ic_launcher_round.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-xhdpi/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-xhdpi/ic_launcher.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/res/mipmap-xhdpi/ic_launcher_round.webp (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/src/main/AndroidManifest.xml (deflated 61%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/build.gradle.kts (deflated 66%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.android/app/proguard-rules.pro (deflated 44%)\n",
            "  adding: content/llama.cpp/examples/llama.android/.gitignore (deflated 34%)\n",
            "  adding: content/llama.cpp/examples/json_schema_pydantic_example.py (deflated 58%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/gguf-hash.cpp (deflated 81%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/CMakeLists.txt (deflated 54%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/README.md (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/xxhash/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/xxhash/xxhash.c (deflated 48%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/xxhash/xxhash.h (deflated 77%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/xxhash/clib.json (deflated 33%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/rotate-bits/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/rotate-bits/rotate-bits.h (deflated 67%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/rotate-bits/package.json (deflated 38%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/sha1/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/sha1/sha1.c (deflated 66%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/sha1/sha1.h (deflated 54%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/sha1/package.json (deflated 35%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/sha256/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/sha256/sha256.c (deflated 63%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/sha256/sha256.h (deflated 47%)\n",
            "  adding: content/llama.cpp/examples/gguf-hash/deps/sha256/package.json (deflated 41%)\n",
            "  adding: content/llama.cpp/examples/save-load-state/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/save-load-state/CMakeLists.txt (deflated 32%)\n",
            "  adding: content/llama.cpp/examples/save-load-state/save-load-state.cpp (deflated 79%)\n",
            "  adding: content/llama.cpp/examples/cvector-generator/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/cvector-generator/negative.txt (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/cvector-generator/positive.txt (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/cvector-generator/completions.txt (deflated 65%)\n",
            "  adding: content/llama.cpp/examples/cvector-generator/CMakeLists.txt (deflated 32%)\n",
            "  adding: content/llama.cpp/examples/cvector-generator/pca.hpp (deflated 70%)\n",
            "  adding: content/llama.cpp/examples/cvector-generator/README.md (deflated 55%)\n",
            "  adding: content/llama.cpp/examples/cvector-generator/cvector-generator.cpp (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/cvector-generator/mean.hpp (deflated 63%)\n",
            "  adding: content/llama.cpp/examples/chat-13B.sh (deflated 45%)\n",
            "  adding: content/llama.cpp/examples/simple-chat/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/simple-chat/simple-chat.cpp (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/simple-chat/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/simple-chat/README.md (deflated 32%)\n",
            "  adding: content/llama.cpp/examples/gguf-split/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gguf-split/gguf-split.cpp (deflated 77%)\n",
            "  adding: content/llama.cpp/examples/gguf-split/tests.sh (deflated 70%)\n",
            "  adding: content/llama.cpp/examples/gguf-split/CMakeLists.txt (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/gguf-split/README.md (deflated 41%)\n",
            "  adding: content/llama.cpp/examples/chat.sh (deflated 34%)\n",
            "  adding: content/llama.cpp/examples/quantize-stats/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/quantize-stats/CMakeLists.txt (deflated 36%)\n",
            "  adding: content/llama.cpp/examples/quantize-stats/quantize-stats.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/examples/llm.vim (deflated 45%)\n",
            "  adding: content/llama.cpp/examples/batched.swift/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/batched.swift/Sources/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/batched.swift/Sources/main.swift (deflated 67%)\n",
            "  adding: content/llama.cpp/examples/batched.swift/Package.swift (deflated 51%)\n",
            "  adding: content/llama.cpp/examples/batched.swift/README.md (deflated 11%)\n",
            "  adding: content/llama.cpp/examples/batched.swift/.gitignore (deflated 29%)\n",
            "  adding: content/llama.cpp/examples/batched.swift/Makefile (deflated 38%)\n",
            "  adding: content/llama.cpp/examples/eval-callback/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/eval-callback/eval-callback.cpp (deflated 67%)\n",
            "  adding: content/llama.cpp/examples/eval-callback/CMakeLists.txt (deflated 42%)\n",
            "  adding: content/llama.cpp/examples/eval-callback/README.md (deflated 82%)\n",
            "  adding: content/llama.cpp/examples/batched-bench/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/batched-bench/batched-bench.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/batched-bench/CMakeLists.txt (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/batched-bench/README.md (deflated 62%)\n",
            "  adding: content/llama.cpp/examples/rpc/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/rpc/rpc-server.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/rpc/CMakeLists.txt (deflated 19%)\n",
            "  adding: content/llama.cpp/examples/rpc/README.md (deflated 55%)\n",
            "  adding: content/llama.cpp/examples/CMakeLists.txt (deflated 68%)\n",
            "  adding: content/llama.cpp/examples/chat-13B.bat (deflated 52%)\n",
            "  adding: content/llama.cpp/examples/quantize/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/quantize/quantize.cpp (deflated 77%)\n",
            "  adding: content/llama.cpp/examples/quantize/tests.sh (deflated 62%)\n",
            "  adding: content/llama.cpp/examples/quantize/CMakeLists.txt (deflated 35%)\n",
            "  adding: content/llama.cpp/examples/quantize/README.md (deflated 67%)\n",
            "  adding: content/llama.cpp/examples/lookahead/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/lookahead/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/lookahead/README.md (deflated 28%)\n",
            "  adding: content/llama.cpp/examples/lookahead/lookahead.cpp (deflated 76%)\n",
            "  adding: content/llama.cpp/examples/tts/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/tts/tts.cpp (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/tts/CMakeLists.txt (deflated 28%)\n",
            "  adding: content/llama.cpp/examples/tts/README.md (deflated 64%)\n",
            "  adding: content/llama.cpp/examples/tts/tts-outetts.py (deflated 68%)\n",
            "  adding: content/llama.cpp/examples/tts/convert_pt_to_hf.py (deflated 63%)\n",
            "  adding: content/llama.cpp/examples/convert-llama2c-to-ggml/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/convert-llama2c-to-ggml/CMakeLists.txt (deflated 33%)\n",
            "  adding: content/llama.cpp/examples/convert-llama2c-to-ggml/README.md (deflated 55%)\n",
            "  adding: content/llama.cpp/examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp (deflated 77%)\n",
            "  adding: content/llama.cpp/examples/server/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/webui/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/webui/src/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/webui/src/katex-gpt.js (deflated 58%)\n",
            "  adding: content/llama.cpp/examples/server/webui/src/highlight-config.js (deflated 79%)\n",
            "  adding: content/llama.cpp/examples/server/webui/src/main.js (deflated 69%)\n",
            "  adding: content/llama.cpp/examples/server/webui/src/styles.scss (deflated 55%)\n",
            "  adding: content/llama.cpp/examples/server/webui/vite.config.js (deflated 51%)\n",
            "  adding: content/llama.cpp/examples/server/webui/tailwind.config.js (deflated 42%)\n",
            "  adding: content/llama.cpp/examples/server/webui/index.html (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/server/webui/public/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/webui/public/demo-conversation.json (deflated 56%)\n",
            "  adding: content/llama.cpp/examples/server/webui/package-lock.json (deflated 78%)\n",
            "  adding: content/llama.cpp/examples/server/webui/package.json (deflated 49%)\n",
            "  adding: content/llama.cpp/examples/server/webui/postcss.config.js (deflated 18%)\n",
            "  adding: content/llama.cpp/examples/server/bench/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/bench/prometheus.yml (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/server/bench/script.js (deflated 69%)\n",
            "  adding: content/llama.cpp/examples/server/bench/README.md (deflated 60%)\n",
            "  adding: content/llama.cpp/examples/server/bench/bench.py (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/server/bench/requirements.txt (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/utils.hpp (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/server/tests/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/tests/tests.sh (deflated 21%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_lora.py (deflated 68%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_chat_completion.py (deflated 78%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_ctx_shift.py (deflated 61%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_rerank.py (deflated 62%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_infill.py (deflated 72%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_embedding.py (deflated 78%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_completion.py (deflated 80%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_security.py (deflated 67%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_basic.py (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_speculative.py (deflated 72%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_slot_save.py (deflated 79%)\n",
            "  adding: content/llama.cpp/examples/server/tests/unit/test_tokenize.py (deflated 69%)\n",
            "  adding: content/llama.cpp/examples/server/tests/README.md (deflated 54%)\n",
            "  adding: content/llama.cpp/examples/server/tests/requirements.txt (deflated 16%)\n",
            "  adding: content/llama.cpp/examples/server/tests/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/tests/utils.py (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/server/tests/conftest.py (deflated 39%)\n",
            "  adding: content/llama.cpp/examples/server/chat.sh (deflated 55%)\n",
            "  adding: content/llama.cpp/examples/server/public_simplechat/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/public_simplechat/simplechat.css (deflated 59%)\n",
            "  adding: content/llama.cpp/examples/server/public_simplechat/readme.md (deflated 61%)\n",
            "  adding: content/llama.cpp/examples/server/public_simplechat/simplechat_screens.webp (deflated 1%)\n",
            "  adding: content/llama.cpp/examples/server/public_simplechat/datautils.mjs (deflated 68%)\n",
            "  adding: content/llama.cpp/examples/server/public_simplechat/simplechat.js (deflated 76%)\n",
            "  adding: content/llama.cpp/examples/server/public_simplechat/ui.mjs (deflated 75%)\n",
            "  adding: content/llama.cpp/examples/server/public_simplechat/index.html (deflated 62%)\n",
            "  adding: content/llama.cpp/examples/server/CMakeLists.txt (deflated 50%)\n",
            "  adding: content/llama.cpp/examples/server/README.md (deflated 68%)\n",
            "  adding: content/llama.cpp/examples/server/public/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/public/loading.html (deflated 39%)\n",
            "  adding: content/llama.cpp/examples/server/public/index.html.gz (deflated 0%)\n",
            "  adding: content/llama.cpp/examples/server/chat-llama2.sh (deflated 54%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/theme-playground.css (deflated 83%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/index-new.html (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/completion.js (deflated 67%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/theme-beeninorder.css (deflated 83%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/index.js (deflated 62%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/theme-mangotango.css (deflated 82%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/favicon.ico (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/style.css (deflated 82%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/theme-ketivah.css (deflated 84%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/theme-snowstorm.css (deflated 84%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/loading.html (deflated 39%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/system-prompts.js (deflated 60%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/theme-polarnight.css (deflated 84%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/json-schema-to-grammar.mjs (deflated 75%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/index.html (deflated 75%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/prompt-formats.js (deflated 83%)\n",
            "  adding: content/llama.cpp/examples/server/public_legacy/colorthemes.css (deflated 82%)\n",
            "  adding: content/llama.cpp/examples/server/server.cpp (deflated 81%)\n",
            "  adding: content/llama.cpp/examples/server/themes/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/themes/buttons-top/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/themes/buttons-top/favicon.ico (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/themes/buttons-top/buttons_top.png (deflated 2%)\n",
            "  adding: content/llama.cpp/examples/server/themes/buttons-top/README.md (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/server/themes/buttons-top/index.html (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/server/themes/wild/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/themes/wild/llamapattern.png (deflated 0%)\n",
            "  adding: content/llama.cpp/examples/server/themes/wild/wild.png (deflated 1%)\n",
            "  adding: content/llama.cpp/examples/server/themes/wild/favicon.ico (stored 0%)\n",
            "  adding: content/llama.cpp/examples/server/themes/wild/README.md (deflated 9%)\n",
            "  adding: content/llama.cpp/examples/server/themes/wild/index.html (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/server/themes/wild/llama_cpp.png (deflated 0%)\n",
            "  adding: content/llama.cpp/examples/server/themes/README.md (deflated 21%)\n",
            "  adding: content/llama.cpp/examples/server/chat.mjs (deflated 62%)\n",
            "  adding: content/llama.cpp/examples/server/httplib.h (deflated 81%)\n",
            "  adding: content/llama.cpp/examples/tokenize/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/tokenize/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/tokenize/tokenize.cpp (deflated 70%)\n",
            "  adding: content/llama.cpp/examples/run/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/run/run.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/examples/run/CMakeLists.txt (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/run/README.md (deflated 53%)\n",
            "  adding: content/llama.cpp/examples/run/linenoise.cpp/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/run/linenoise.cpp/LICENSE (deflated 49%)\n",
            "  adding: content/llama.cpp/examples/run/linenoise.cpp/linenoise.h (deflated 62%)\n",
            "  adding: content/llama.cpp/examples/run/linenoise.cpp/linenoise.cpp (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/infill/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/infill/CMakeLists.txt (deflated 29%)\n",
            "  adding: content/llama.cpp/examples/infill/README.md (deflated 56%)\n",
            "  adding: content/llama.cpp/examples/infill/infill.cpp (deflated 76%)\n",
            "  adding: content/llama.cpp/examples/chat-persistent.sh (deflated 64%)\n",
            "  adding: content/llama.cpp/examples/main/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/main/CMakeLists.txt (deflated 28%)\n",
            "  adding: content/llama.cpp/examples/main/main.cpp (deflated 76%)\n",
            "  adding: content/llama.cpp/examples/main/README.md (deflated 66%)\n",
            "  adding: content/llama.cpp/examples/export-lora/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/export-lora/CMakeLists.txt (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/export-lora/export-lora.cpp (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/export-lora/README.md (deflated 59%)\n",
            "  adding: content/llama.cpp/examples/ts-type-to-grammar.sh (deflated 49%)\n",
            "  adding: content/llama.cpp/examples/speculative/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/speculative/CMakeLists.txt (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/speculative/README.md (deflated 50%)\n",
            "  adding: content/llama.cpp/examples/speculative/speculative.cpp (deflated 78%)\n",
            "  adding: content/llama.cpp/examples/gritlm/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gritlm/CMakeLists.txt (deflated 29%)\n",
            "  adding: content/llama.cpp/examples/gritlm/README.md (deflated 57%)\n",
            "  adding: content/llama.cpp/examples/gritlm/gritlm.cpp (deflated 67%)\n",
            "  adding: content/llama.cpp/examples/sycl/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/sycl/build.sh (deflated 49%)\n",
            "  adding: content/llama.cpp/examples/sycl/run-llama2.sh (deflated 43%)\n",
            "  adding: content/llama.cpp/examples/sycl/win-build-sycl.bat (deflated 50%)\n",
            "  adding: content/llama.cpp/examples/sycl/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/sycl/README.md (deflated 59%)\n",
            "  adding: content/llama.cpp/examples/sycl/win-run-llama2.bat (deflated 22%)\n",
            "  adding: content/llama.cpp/examples/sycl/ls-sycl-device.cpp (deflated 19%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/README.md (deflated 38%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui.xcodeproj/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui.xcodeproj/project.pbxproj (deflated 81%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui.xcodeproj/project.xcworkspace/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui.xcodeproj/project.xcworkspace/xcshareddata/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui.xcodeproj/project.xcworkspace/xcshareddata/IDEWorkspaceChecks.plist (deflated 21%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui.xcodeproj/project.xcworkspace/contents.xcworkspacedata (deflated 27%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.cpp.swift/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.cpp.swift/LibLlama.swift (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/.gitignore (deflated 8%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/llama_swiftuiApp.swift (deflated 24%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/Models/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/Models/LlamaState.swift (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/UI/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/UI/LoadCustomButton.swift (deflated 60%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/UI/InputButton.swift (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/UI/ContentView.swift (deflated 72%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/UI/DownloadButton.swift (deflated 72%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/Resources/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/Resources/models/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/Resources/models/.gitignore (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/Assets.xcassets/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/Assets.xcassets/Contents.json (deflated 16%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/Assets.xcassets/AppIcon.appiconset/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama.swiftui/llama.swiftui/Assets.xcassets/AppIcon.appiconset/Contents.json (deflated 34%)\n",
            "  adding: content/llama.cpp/examples/simple/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/simple/simple.cpp (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/simple/CMakeLists.txt (deflated 29%)\n",
            "  adding: content/llama.cpp/examples/simple/README.md (deflated 51%)\n",
            "  adding: content/llama.cpp/examples/llava/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llava/MobileVLM-README.md (deflated 76%)\n",
            "  adding: content/llama.cpp/examples/llava/README-minicpmo2.6.md (deflated 63%)\n",
            "  adding: content/llama.cpp/examples/llava/llava.cpp (deflated 75%)\n",
            "  adding: content/llama.cpp/examples/llava/qwen2_vl_surgery.py (deflated 67%)\n",
            "  adding: content/llama.cpp/examples/llava/convert_image_encoder_to_gguf.py (deflated 72%)\n",
            "  adding: content/llama.cpp/examples/llava/llava_surgery.py (deflated 53%)\n",
            "  adding: content/llama.cpp/examples/llava/README-minicpmv2.6.md (deflated 64%)\n",
            "  adding: content/llama.cpp/examples/llava/llava_surgery_v2.py (deflated 72%)\n",
            "  adding: content/llama.cpp/examples/llava/CMakeLists.txt (deflated 72%)\n",
            "  adding: content/llama.cpp/examples/llava/minicpmv-cli.cpp (deflated 76%)\n",
            "  adding: content/llama.cpp/examples/llava/README.md (deflated 61%)\n",
            "  adding: content/llama.cpp/examples/llava/clip.h (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/llava/clip.cpp (deflated 80%)\n",
            "  adding: content/llama.cpp/examples/llava/README-minicpmv2.5.md (deflated 65%)\n",
            "  adding: content/llama.cpp/examples/llava/requirements.txt (deflated 21%)\n",
            "  adding: content/llama.cpp/examples/llava/qwen2vl-cli.cpp (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/llava/minicpmv-convert-image-encoder-to-gguf.py (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/llava/minicpmv-surgery.py (deflated 59%)\n",
            "  adding: content/llama.cpp/examples/llava/llava.h (deflated 64%)\n",
            "  adding: content/llama.cpp/examples/llava/llava-cli.cpp (deflated 74%)\n",
            "  adding: content/llama.cpp/examples/llava/android/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llava/android/build_64.sh (deflated 24%)\n",
            "  adding: content/llama.cpp/examples/llava/android/adb_run.sh (deflated 73%)\n",
            "  adding: content/llama.cpp/examples/imatrix/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/imatrix/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/imatrix/README.md (deflated 53%)\n",
            "  adding: content/llama.cpp/examples/imatrix/imatrix.cpp (deflated 72%)\n",
            "  adding: content/llama.cpp/examples/convert_legacy_llama.py (deflated 75%)\n",
            "  adding: content/llama.cpp/examples/gbnf-validator/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gbnf-validator/gbnf-validator.cpp (deflated 71%)\n",
            "  adding: content/llama.cpp/examples/gbnf-validator/CMakeLists.txt (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/gen-docs/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gen-docs/gen-docs.cpp (deflated 67%)\n",
            "  adding: content/llama.cpp/examples/gen-docs/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/regex_to_grammar.py (deflated 44%)\n",
            "  adding: content/llama.cpp/examples/simple-cmake-pkg/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/simple-cmake-pkg/CMakeLists.txt (deflated 33%)\n",
            "  adding: content/llama.cpp/examples/simple-cmake-pkg/README.md (deflated 50%)\n",
            "  adding: content/llama.cpp/examples/simple-cmake-pkg/.gitignore (deflated 41%)\n",
            "  adding: content/llama.cpp/examples/jeopardy/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/jeopardy/jeopardy.sh (deflated 44%)\n",
            "  adding: content/llama.cpp/examples/jeopardy/questions.txt (deflated 50%)\n",
            "  adding: content/llama.cpp/examples/jeopardy/README.md (deflated 45%)\n",
            "  adding: content/llama.cpp/examples/jeopardy/qasheet.csv (deflated 51%)\n",
            "  adding: content/llama.cpp/examples/jeopardy/graph.py (deflated 60%)\n",
            "  adding: content/llama.cpp/examples/speculative-simple/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/speculative-simple/CMakeLists.txt (deflated 33%)\n",
            "  adding: content/llama.cpp/examples/speculative-simple/README.md (deflated 45%)\n",
            "  adding: content/llama.cpp/examples/speculative-simple/speculative-simple.cpp (deflated 69%)\n",
            "  adding: content/llama.cpp/examples/gguf/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/gguf/CMakeLists.txt (deflated 27%)\n",
            "  adding: content/llama.cpp/examples/gguf/gguf.cpp (deflated 76%)\n",
            "  adding: content/llama.cpp/examples/parallel/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/parallel/parallel.cpp (deflated 70%)\n",
            "  adding: content/llama.cpp/examples/parallel/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/parallel/README.md (deflated 15%)\n",
            "  adding: content/llama.cpp/examples/llama-bench/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/llama-bench/llama-bench.cpp (deflated 82%)\n",
            "  adding: content/llama.cpp/examples/llama-bench/CMakeLists.txt (deflated 31%)\n",
            "  adding: content/llama.cpp/examples/llama-bench/README.md (deflated 77%)\n",
            "  adding: content/llama.cpp/examples/batched/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/batched/batched.cpp (deflated 70%)\n",
            "  adding: content/llama.cpp/examples/batched/CMakeLists.txt (deflated 30%)\n",
            "  adding: content/llama.cpp/examples/batched/README.md (deflated 55%)\n",
            "  adding: content/llama.cpp/examples/deprecation-warning/ (stored 0%)\n",
            "  adding: content/llama.cpp/examples/deprecation-warning/README.md (deflated 60%)\n",
            "  adding: content/llama.cpp/examples/deprecation-warning/deprecation-warning.cpp (deflated 53%)\n",
            "  adding: content/llama.cpp/.dockerignore (deflated 27%)\n",
            "  adding: content/llama.cpp/convert_llama_ggml_to_gguf.py (deflated 72%)\n",
            "  adding: content/llama.cpp/Makefile (deflated 78%)\n",
            "  adding: content/llama.cpp/flake.nix (deflated 63%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/ai-doctor-02-outputs.zip /content/outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9ukBjbr3siz",
        "outputId": "a5f03020-f797-4416-ec27-5d7e8714570b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/outputs/ (stored 0%)\n",
            "  adding: content/outputs/checkpoint-2500/ (stored 0%)\n",
            "  adding: content/outputs/checkpoint-2500/rng_state.pth (deflated 25%)\n",
            "  adding: content/outputs/checkpoint-2500/scheduler.pt (deflated 55%)\n",
            "  adding: content/outputs/checkpoint-2500/adapter_model.safetensors (deflated 7%)\n",
            "  adding: content/outputs/checkpoint-2500/trainer_state.json (deflated 82%)\n",
            "  adding: content/outputs/checkpoint-2500/adapter_config.json (deflated 56%)\n",
            "  adding: content/outputs/checkpoint-2500/README.md (deflated 66%)\n",
            "  adding: content/outputs/checkpoint-2500/optimizer.pt (deflated 12%)\n",
            "  adding: content/outputs/checkpoint-2500/training_args.bin (deflated 51%)\n",
            "  adding: content/outputs/checkpoint-2500/special_tokens_map.json (deflated 70%)\n",
            "  adding: content/outputs/checkpoint-2500/tokenizer_config.json (deflated 96%)\n",
            "  adding: content/outputs/checkpoint-2500/tokenizer.json (deflated 85%)\n",
            "  adding: content/outputs/runs/ (stored 0%)\n",
            "  adding: content/outputs/runs/Jan27_16-05-58_be83690f0d57/ (stored 0%)\n",
            "  adding: content/outputs/runs/Jan27_16-05-58_be83690f0d57/events.out.tfevents.1737993967.be83690f0d57.3864.0 (deflated 70%)\n",
            "  adding: content/outputs/checkpoint-1000/ (stored 0%)\n",
            "  adding: content/outputs/checkpoint-1000/rng_state.pth (deflated 25%)\n",
            "  adding: content/outputs/checkpoint-1000/scheduler.pt (deflated 55%)\n",
            "  adding: content/outputs/checkpoint-1000/adapter_model.safetensors (deflated 7%)\n",
            "  adding: content/outputs/checkpoint-1000/trainer_state.json (deflated 82%)\n",
            "  adding: content/outputs/checkpoint-1000/adapter_config.json (deflated 56%)\n",
            "  adding: content/outputs/checkpoint-1000/README.md (deflated 66%)\n",
            "  adding: content/outputs/checkpoint-1000/optimizer.pt (deflated 12%)\n",
            "  adding: content/outputs/checkpoint-1000/training_args.bin (deflated 51%)\n",
            "  adding: content/outputs/checkpoint-1000/special_tokens_map.json (deflated 70%)\n",
            "  adding: content/outputs/checkpoint-1000/tokenizer_config.json (deflated 96%)\n",
            "  adding: content/outputs/checkpoint-1000/tokenizer.json (deflated 85%)\n",
            "  adding: content/outputs/checkpoint-2810/ (stored 0%)\n",
            "  adding: content/outputs/checkpoint-2810/rng_state.pth (deflated 25%)\n",
            "  adding: content/outputs/checkpoint-2810/scheduler.pt (deflated 56%)\n",
            "  adding: content/outputs/checkpoint-2810/adapter_model.safetensors (deflated 7%)\n",
            "  adding: content/outputs/checkpoint-2810/trainer_state.json (deflated 82%)\n",
            "  adding: content/outputs/checkpoint-2810/adapter_config.json (deflated 56%)\n",
            "  adding: content/outputs/checkpoint-2810/README.md (deflated 66%)\n",
            "  adding: content/outputs/checkpoint-2810/optimizer.pt (deflated 12%)\n",
            "  adding: content/outputs/checkpoint-2810/training_args.bin (deflated 51%)\n",
            "  adding: content/outputs/checkpoint-2810/special_tokens_map.json (deflated 70%)\n",
            "  adding: content/outputs/checkpoint-2810/tokenizer_config.json (deflated 96%)\n",
            "  adding: content/outputs/checkpoint-2810/tokenizer.json (deflated 85%)\n",
            "  adding: content/outputs/checkpoint-2000/ (stored 0%)\n",
            "  adding: content/outputs/checkpoint-2000/rng_state.pth (deflated 25%)\n",
            "  adding: content/outputs/checkpoint-2000/scheduler.pt (deflated 56%)\n",
            "  adding: content/outputs/checkpoint-2000/adapter_model.safetensors (deflated 7%)\n",
            "  adding: content/outputs/checkpoint-2000/trainer_state.json (deflated 82%)\n",
            "  adding: content/outputs/checkpoint-2000/adapter_config.json (deflated 56%)\n",
            "  adding: content/outputs/checkpoint-2000/README.md (deflated 66%)\n",
            "  adding: content/outputs/checkpoint-2000/optimizer.pt (deflated 12%)\n",
            "  adding: content/outputs/checkpoint-2000/training_args.bin (deflated 51%)\n",
            "  adding: content/outputs/checkpoint-2000/special_tokens_map.json (deflated 70%)\n",
            "  adding: content/outputs/checkpoint-2000/tokenizer_config.json (deflated 96%)\n",
            "  adding: content/outputs/checkpoint-2000/tokenizer.json (deflated 85%)\n",
            "  adding: content/outputs/checkpoint-1500/ (stored 0%)\n",
            "  adding: content/outputs/checkpoint-1500/rng_state.pth (deflated 25%)\n",
            "  adding: content/outputs/checkpoint-1500/scheduler.pt (deflated 56%)\n",
            "  adding: content/outputs/checkpoint-1500/adapter_model.safetensors (deflated 7%)\n",
            "  adding: content/outputs/checkpoint-1500/trainer_state.json (deflated 82%)\n",
            "  adding: content/outputs/checkpoint-1500/adapter_config.json (deflated 56%)\n",
            "  adding: content/outputs/checkpoint-1500/README.md (deflated 66%)\n",
            "  adding: content/outputs/checkpoint-1500/optimizer.pt (deflated 12%)\n",
            "  adding: content/outputs/checkpoint-1500/training_args.bin (deflated 51%)\n",
            "  adding: content/outputs/checkpoint-1500/special_tokens_map.json (deflated 70%)\n",
            "  adding: content/outputs/checkpoint-1500/tokenizer_config.json (deflated 96%)\n",
            "  adding: content/outputs/checkpoint-1500/tokenizer.json (deflated 85%)\n",
            "  adding: content/outputs/checkpoint-500/ (stored 0%)\n",
            "  adding: content/outputs/checkpoint-500/rng_state.pth (deflated 25%)\n",
            "  adding: content/outputs/checkpoint-500/scheduler.pt (deflated 55%)\n",
            "  adding: content/outputs/checkpoint-500/adapter_model.safetensors (deflated 7%)\n",
            "  adding: content/outputs/checkpoint-500/trainer_state.json (deflated 81%)\n",
            "  adding: content/outputs/checkpoint-500/adapter_config.json (deflated 56%)\n",
            "  adding: content/outputs/checkpoint-500/README.md (deflated 66%)\n",
            "  adding: content/outputs/checkpoint-500/optimizer.pt (deflated 12%)\n",
            "  adding: content/outputs/checkpoint-500/training_args.bin (deflated 51%)\n",
            "  adding: content/outputs/checkpoint-500/special_tokens_map.json (deflated 70%)\n",
            "  adding: content/outputs/checkpoint-500/tokenizer_config.json (deflated 96%)\n",
            "  adding: content/outputs/checkpoint-500/tokenizer.json (deflated 85%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/ai-doctor-02-processed_data.zip /content/processed_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Ng8zeu31AB",
        "outputId": "08cc313f-cfcf-418c-e514-c45a03541983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/processed_data/ (stored 0%)\n",
            "  adding: content/processed_data/llama3_dataset/ (stored 0%)\n",
            "  adding: content/processed_data/llama3_dataset/train/ (stored 0%)\n",
            "  adding: content/processed_data/llama3_dataset/train/data-00000-of-00001.arrow (deflated 92%)\n",
            "  adding: content/processed_data/llama3_dataset/train/dataset_info.json (deflated 37%)\n",
            "  adding: content/processed_data/llama3_dataset/train/state.json (deflated 38%)\n",
            "  adding: content/processed_data/llama3_dataset/dataset_dict.json (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh /content/llama-3-8b-instruct-aidoctor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gBhdw2V4BdR",
        "outputId": "27084e84-5ef4-4ba2-e0c8-36b6de9d4539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35G\t/content/llama-3-8b-instruct-aidoctor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xHbA8bx_4TOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7dfdb12c74ca4eeea305f90593c1138b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_e49d9cea7b2c493c80877bf0f6cbeefa"
          }
        },
        "9e9ff66367714ecb8188d80801f53c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0643030eff84999819f51b4c92fe513",
            "placeholder": "​",
            "style": "IPY_MODEL_b898a3d3b1d44894a228ccca88f3e455",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "94694a7098bb4d66b06b5c8ad43ab2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d717d95f1bd049d38f79caa1971bf131",
            "placeholder": "​",
            "style": "IPY_MODEL_8f089f50f25d4425a5fa5ecc7b31bd67",
            "value": ""
          }
        },
        "ed02f7bea2cf43648aacffe7c2603ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_d576220bcfa040fbb8d3b263f0996f21",
            "style": "IPY_MODEL_6659e558d21048d9930f716ff4d1c0db",
            "value": true
          }
        },
        "97246b9da03b4cd38c19205eae614c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_7bf38cfe137e4ae6b0fba6b73d430fb9",
            "style": "IPY_MODEL_5c20541932c84d64b94a349f4d95b1a7",
            "tooltip": ""
          }
        },
        "21c5b73d7b3545dc9f9ee9ff1570e33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4fb9d9d830045e4a8f8a653924a5830",
            "placeholder": "​",
            "style": "IPY_MODEL_0e9e373cae1a4b0296f33c39adaae8d8",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e49d9cea7b2c493c80877bf0f6cbeefa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a0643030eff84999819f51b4c92fe513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b898a3d3b1d44894a228ccca88f3e455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d717d95f1bd049d38f79caa1971bf131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f089f50f25d4425a5fa5ecc7b31bd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d576220bcfa040fbb8d3b263f0996f21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6659e558d21048d9930f716ff4d1c0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bf38cfe137e4ae6b0fba6b73d430fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c20541932c84d64b94a349f4d95b1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b4fb9d9d830045e4a8f8a653924a5830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9e373cae1a4b0296f33c39adaae8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9336ec6fae054724b42572918e5528cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e6d7f0c8bea46ed890b3f4cb2c928ba",
            "placeholder": "​",
            "style": "IPY_MODEL_b24f1432475042eab4eed559e39f27f5",
            "value": "Connecting..."
          }
        },
        "9e6d7f0c8bea46ed890b3f4cb2c928ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24f1432475042eab4eed559e39f27f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5b4197a7ab1462188e489adcc88009d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11ddd49ae7674fa4b6b3215476a28155",
              "IPY_MODEL_148290f9e1704924b1d9553f7a77cf15",
              "IPY_MODEL_0dc600bc6e944c4c9eebee44de5b1e3c"
            ],
            "layout": "IPY_MODEL_29ca68f8993d4f1685dc373a66f83500"
          }
        },
        "11ddd49ae7674fa4b6b3215476a28155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f37058b2a42944d1b8fd54e162d8f123",
            "placeholder": "​",
            "style": "IPY_MODEL_963a19dcd88c4806840e645ce1437437",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "148290f9e1704924b1d9553f7a77cf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d81c916b78d7406498719427f5bedfe3",
            "max": 4498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b77a87881e944b0b72ff3ec25457f0b",
            "value": 4498
          }
        },
        "0dc600bc6e944c4c9eebee44de5b1e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dde4d8916044d48bcd7511af087176c",
            "placeholder": "​",
            "style": "IPY_MODEL_3ef9b06f01ae4d81bc594715b48108de",
            "value": " 4498/4498 [00:00&lt;00:00, 180904.42 examples/s]"
          }
        },
        "29ca68f8993d4f1685dc373a66f83500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37058b2a42944d1b8fd54e162d8f123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963a19dcd88c4806840e645ce1437437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d81c916b78d7406498719427f5bedfe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b77a87881e944b0b72ff3ec25457f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dde4d8916044d48bcd7511af087176c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef9b06f01ae4d81bc594715b48108de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41dec095472b4bb18deabc2c9e491759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0edd1289ccf44e818a02a6f6fb8b5216",
              "IPY_MODEL_8f5ff27e9ed541ce9d000af6c485a6b2",
              "IPY_MODEL_553b468e050849b3b85954db3c45e328"
            ],
            "layout": "IPY_MODEL_f409e24ae3174ce1a816251efa99ca8f"
          }
        },
        "0edd1289ccf44e818a02a6f6fb8b5216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60696cf29e44466aa566313b60d14c84",
            "placeholder": "​",
            "style": "IPY_MODEL_821ef85ba74a468e9d810a4830eda45f",
            "value": "Uploading the dataset shards: 100%"
          }
        },
        "8f5ff27e9ed541ce9d000af6c485a6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c0c57adac56417e8f629935433b942c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85020806ee734f5ea45d8d757872b4a3",
            "value": 1
          }
        },
        "553b468e050849b3b85954db3c45e328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c296d17808014828bda6e03b356d9854",
            "placeholder": "​",
            "style": "IPY_MODEL_a867d494ebe24f2b90686a23d9522bbf",
            "value": " 1/1 [00:00&lt;00:00,  1.78it/s]"
          }
        },
        "f409e24ae3174ce1a816251efa99ca8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60696cf29e44466aa566313b60d14c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821ef85ba74a468e9d810a4830eda45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c0c57adac56417e8f629935433b942c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85020806ee734f5ea45d8d757872b4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c296d17808014828bda6e03b356d9854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a867d494ebe24f2b90686a23d9522bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2094841520545a481405eafe51c8d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85cf8cd9b8b44474b4e84ccdd5c12377",
              "IPY_MODEL_2958b35e8d8b43d791006b3ac99c9cfa",
              "IPY_MODEL_b6ca5135623d49df83ad94e7db800bf2"
            ],
            "layout": "IPY_MODEL_3194c2981cd544a9a0904c80eb142607"
          }
        },
        "85cf8cd9b8b44474b4e84ccdd5c12377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b18abb18c4c44b8dad749aefe6c69505",
            "placeholder": "​",
            "style": "IPY_MODEL_8bbb0b328d2c46ebb5bbc583fd0edb9b",
            "value": "Creating parquet from Arrow format: 100%"
          }
        },
        "2958b35e8d8b43d791006b3ac99c9cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb16b5503fd0431f8e9635ddae281567",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_140be330bbc54c2c998554ea4c8ca879",
            "value": 5
          }
        },
        "b6ca5135623d49df83ad94e7db800bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c29e17ba967f4e44bc84c7851dc38c02",
            "placeholder": "​",
            "style": "IPY_MODEL_91d8936fa4b74f7faf793211ccc05f07",
            "value": " 5/5 [00:00&lt;00:00, 237.08ba/s]"
          }
        },
        "3194c2981cd544a9a0904c80eb142607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b18abb18c4c44b8dad749aefe6c69505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bbb0b328d2c46ebb5bbc583fd0edb9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb16b5503fd0431f8e9635ddae281567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140be330bbc54c2c998554ea4c8ca879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c29e17ba967f4e44bc84c7851dc38c02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d8936fa4b74f7faf793211ccc05f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91e9d39938b144eca849be877c35e5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90219a7e124c4b178ca2d36e6bb3dc1e",
              "IPY_MODEL_36b6d3e0a21844699fb5adb10a24a446",
              "IPY_MODEL_0638ff4b22ec42e49ebc3ea9912109ca"
            ],
            "layout": "IPY_MODEL_4d56883cd1eb4a1790c268ca7f79dee6"
          }
        },
        "90219a7e124c4b178ca2d36e6bb3dc1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_238c1f59e451402d91b79abf1bff7eec",
            "placeholder": "​",
            "style": "IPY_MODEL_90087f381e074a0bbd7b3cac877af981",
            "value": "model.safetensors: 100%"
          }
        },
        "36b6d3e0a21844699fb5adb10a24a446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_720f3f4e46644dcdac97c152bd5faf9d",
            "max": 5702746403,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d805afce5965460a87f771bce8338520",
            "value": 5702746403
          }
        },
        "0638ff4b22ec42e49ebc3ea9912109ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db099a7ab1c74347a0bfdc144d1d9e47",
            "placeholder": "​",
            "style": "IPY_MODEL_be3b88a2a84447f48f944aa645c3ba74",
            "value": " 5.70G/5.70G [02:15&lt;00:00, 42.7MB/s]"
          }
        },
        "4d56883cd1eb4a1790c268ca7f79dee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "238c1f59e451402d91b79abf1bff7eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90087f381e074a0bbd7b3cac877af981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "720f3f4e46644dcdac97c152bd5faf9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d805afce5965460a87f771bce8338520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db099a7ab1c74347a0bfdc144d1d9e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be3b88a2a84447f48f944aa645c3ba74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86c4916b80a9421fb1a48fb5728b4e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c204e3259f6a44d294615444ed3fdf25",
              "IPY_MODEL_145628d4f8a94019a51d61169d4e0e5e",
              "IPY_MODEL_777ab2fb4e2e4fd59568cf3840d67e71"
            ],
            "layout": "IPY_MODEL_17c148ccfc8c45e2ade3ea1736048abf"
          }
        },
        "c204e3259f6a44d294615444ed3fdf25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6966502f0d0d47a38616196346833050",
            "placeholder": "​",
            "style": "IPY_MODEL_77d249451eaf47e2bbb71c091bf85f46",
            "value": "generation_config.json: 100%"
          }
        },
        "145628d4f8a94019a51d61169d4e0e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c81851c4ce4cf595ba6d75998b9321",
            "max": 220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daf0f4781be74fd6ba9c4d8cf0302a9e",
            "value": 220
          }
        },
        "777ab2fb4e2e4fd59568cf3840d67e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1ebe639118400bbbd5c4efd27a26b0",
            "placeholder": "​",
            "style": "IPY_MODEL_37c8aa32c227444f85f80986182fdc64",
            "value": " 220/220 [00:00&lt;00:00, 20.9kB/s]"
          }
        },
        "17c148ccfc8c45e2ade3ea1736048abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6966502f0d0d47a38616196346833050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d249451eaf47e2bbb71c091bf85f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80c81851c4ce4cf595ba6d75998b9321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf0f4781be74fd6ba9c4d8cf0302a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b1ebe639118400bbbd5c4efd27a26b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37c8aa32c227444f85f80986182fdc64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ede9b06919a44f6e863ca4dc0d67682e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2248c8b07e1a4e9eb35bc068ed671cf7",
              "IPY_MODEL_9cee739f893540f3b3257799ac8d4314",
              "IPY_MODEL_5a74886c8f2a402eab007033fa67917c"
            ],
            "layout": "IPY_MODEL_184d2714db2b42c2b8f5e1adc8f975d1"
          }
        },
        "2248c8b07e1a4e9eb35bc068ed671cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc567edc728241299b471c7217cb7418",
            "placeholder": "​",
            "style": "IPY_MODEL_86438563cff24404b09ebb27ff690366",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9cee739f893540f3b3257799ac8d4314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d13bf6e1288240aa80b26f421c3b864b",
            "max": 51052,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c68bd97ca214f058fffdace64a3d548",
            "value": 51052
          }
        },
        "5a74886c8f2a402eab007033fa67917c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d06ff415c63744f58be1d9941b0776d4",
            "placeholder": "​",
            "style": "IPY_MODEL_64ab2e46975c4cb199eb166f248e8df3",
            "value": " 51.1k/51.1k [00:00&lt;00:00, 4.52MB/s]"
          }
        },
        "184d2714db2b42c2b8f5e1adc8f975d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc567edc728241299b471c7217cb7418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86438563cff24404b09ebb27ff690366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d13bf6e1288240aa80b26f421c3b864b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c68bd97ca214f058fffdace64a3d548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d06ff415c63744f58be1d9941b0776d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ab2e46975c4cb199eb166f248e8df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c03d3fcfcb240d6b2729df803e3d4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a3f398f5234435b8e0e0c35221668d0",
              "IPY_MODEL_ac4cb4ddf5604cdaaaad4f5304f41d70",
              "IPY_MODEL_51d4eb371cbf404fada8fc9c6ee59226"
            ],
            "layout": "IPY_MODEL_cfa0aa8422d04e4b9054ee5ca369a107"
          }
        },
        "5a3f398f5234435b8e0e0c35221668d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a971792e64364463a13707c1840cd036",
            "placeholder": "​",
            "style": "IPY_MODEL_1fde592b082b41718d45ada7848b580c",
            "value": "tokenizer.json: 100%"
          }
        },
        "ac4cb4ddf5604cdaaaad4f5304f41d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21b243d21a9474fb9f7b9cc876a8ec1",
            "max": 9085698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91427ea1905e43c0b88089f913b233df",
            "value": 9085698
          }
        },
        "51d4eb371cbf404fada8fc9c6ee59226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbde99507d0b417fa41e7af7e159fec0",
            "placeholder": "​",
            "style": "IPY_MODEL_292e9c1e313b42f6a312c17c7c741bde",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 26.4MB/s]"
          }
        },
        "cfa0aa8422d04e4b9054ee5ca369a107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a971792e64364463a13707c1840cd036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fde592b082b41718d45ada7848b580c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e21b243d21a9474fb9f7b9cc876a8ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91427ea1905e43c0b88089f913b233df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbde99507d0b417fa41e7af7e159fec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292e9c1e313b42f6a312c17c7c741bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1584b5984b4a5f908c5aa0699f1b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d5373b409e94b3984e38a20edf2369f",
              "IPY_MODEL_710b37d67ec54e6892e9b21ababbaf9d",
              "IPY_MODEL_767e711bac95474e9832c24bedb78277"
            ],
            "layout": "IPY_MODEL_9d10f6884a134f77a84c8c7d9f9a4d87"
          }
        },
        "2d5373b409e94b3984e38a20edf2369f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d1b74dcff414934a77f57466c2b1810",
            "placeholder": "​",
            "style": "IPY_MODEL_4e8c383b18794414a6ad85b0168295d6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "710b37d67ec54e6892e9b21ababbaf9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_368c49bdfa7e4373bd1cd912d3c1574d",
            "max": 345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_355979e4f53b4ec28b462a2106b6f141",
            "value": 345
          }
        },
        "767e711bac95474e9832c24bedb78277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_780609f8ed894da78584e671c244ac75",
            "placeholder": "​",
            "style": "IPY_MODEL_a904fc7303be469dae60bbfbe6466ca6",
            "value": " 345/345 [00:00&lt;00:00, 30.3kB/s]"
          }
        },
        "9d10f6884a134f77a84c8c7d9f9a4d87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1b74dcff414934a77f57466c2b1810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8c383b18794414a6ad85b0168295d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "368c49bdfa7e4373bd1cd912d3c1574d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355979e4f53b4ec28b462a2106b6f141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "780609f8ed894da78584e671c244ac75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a904fc7303be469dae60bbfbe6466ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5aa95242276c4678802ada573cb37a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4473ef293228402f9fca32a9c8b2d781",
              "IPY_MODEL_60feab04bc554d36b8c96a52cf8599dc",
              "IPY_MODEL_da247cc9c7d0467caf82dacb1c735604"
            ],
            "layout": "IPY_MODEL_54cdee82b2e24abc9754129d30b8c79e"
          }
        },
        "4473ef293228402f9fca32a9c8b2d781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5bcdadc1020447a83adf85e0190fb8f",
            "placeholder": "​",
            "style": "IPY_MODEL_25977ed6bd70434ca02b07997391b5a7",
            "value": "README.md: 100%"
          }
        },
        "60feab04bc554d36b8c96a52cf8599dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a7375b3c444f95ba705f4a55b8b5f4",
            "max": 275,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbf5837e13144542a6c916f7b0f62f32",
            "value": 275
          }
        },
        "da247cc9c7d0467caf82dacb1c735604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47591d80a2a547b8babd9b9c976ba284",
            "placeholder": "​",
            "style": "IPY_MODEL_a8fe79d37f8843a390de1b9fa6cb0a7b",
            "value": " 275/275 [00:00&lt;00:00, 27.3kB/s]"
          }
        },
        "54cdee82b2e24abc9754129d30b8c79e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5bcdadc1020447a83adf85e0190fb8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25977ed6bd70434ca02b07997391b5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68a7375b3c444f95ba705f4a55b8b5f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf5837e13144542a6c916f7b0f62f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47591d80a2a547b8babd9b9c976ba284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8fe79d37f8843a390de1b9fa6cb0a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5436e03bced4a7882eadbe153214033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00dfaa5bfcde42cab80e69e3d13b4e51",
              "IPY_MODEL_4ca4b081c83443b881199c316697915c",
              "IPY_MODEL_075852d911a24197b19910fdca9bf9b9"
            ],
            "layout": "IPY_MODEL_b0e14bcede7b49d796325951d097b24a"
          }
        },
        "00dfaa5bfcde42cab80e69e3d13b4e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b87d1de2ec48729b1ac83d9e9b1b2a",
            "placeholder": "​",
            "style": "IPY_MODEL_590b6e8c8e8b4a56bb9f0518e4f5d552",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "4ca4b081c83443b881199c316697915c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ce3c60c8be44609a4b3f053cfa9840",
            "max": 409413,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edc79eaa30fa48d3a506ebabaddd5989",
            "value": 409413
          }
        },
        "075852d911a24197b19910fdca9bf9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d66085ea10264bc0892fc95bcab5b7a1",
            "placeholder": "​",
            "style": "IPY_MODEL_4b8014d8b1644ffc8ee419ea499b9e2c",
            "value": " 409k/409k [00:00&lt;00:00, 9.39MB/s]"
          }
        },
        "b0e14bcede7b49d796325951d097b24a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27b87d1de2ec48729b1ac83d9e9b1b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "590b6e8c8e8b4a56bb9f0518e4f5d552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8ce3c60c8be44609a4b3f053cfa9840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc79eaa30fa48d3a506ebabaddd5989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d66085ea10264bc0892fc95bcab5b7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8014d8b1644ffc8ee419ea499b9e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48373ed854884291adead1bb48b3427b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10c30ecaa4694fb59dc346728afc0485",
              "IPY_MODEL_ccda34ab82f24fda9c007eb6edfca4c3",
              "IPY_MODEL_abbc189f0dd149c6a4eae645e65b90da"
            ],
            "layout": "IPY_MODEL_d878cf6fddc54811a83287ea786015a1"
          }
        },
        "10c30ecaa4694fb59dc346728afc0485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbfde19e343b4b44b3c03e8d9b07ee4b",
            "placeholder": "​",
            "style": "IPY_MODEL_22fc5d48287c4707902a520d4a535c83",
            "value": "Generating train split: 100%"
          }
        },
        "ccda34ab82f24fda9c007eb6edfca4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c30520da64ae41f981b5e750878fb331",
            "max": 4498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16f6e0b4a8224ff38ab713e94320118b",
            "value": 4498
          }
        },
        "abbc189f0dd149c6a4eae645e65b90da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f4fa4261a3348158dcf0c1d876d5ba3",
            "placeholder": "​",
            "style": "IPY_MODEL_61cf23180bc349ab993c00d2e9e3916b",
            "value": " 4498/4498 [00:00&lt;00:00, 140698.49 examples/s]"
          }
        },
        "d878cf6fddc54811a83287ea786015a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbfde19e343b4b44b3c03e8d9b07ee4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fc5d48287c4707902a520d4a535c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30520da64ae41f981b5e750878fb331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f6e0b4a8224ff38ab713e94320118b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f4fa4261a3348158dcf0c1d876d5ba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61cf23180bc349ab993c00d2e9e3916b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4add5556045419f9e137cb072f41176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37b823b3a873404aa4e3303258609ce3",
              "IPY_MODEL_5433e28631f24d1ab31ed3306f91dd3d",
              "IPY_MODEL_88ac8fb11c66447095c3682abfb8645e"
            ],
            "layout": "IPY_MODEL_4fa2f4921f7b481bb285e5b807e97f4a"
          }
        },
        "37b823b3a873404aa4e3303258609ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd165494e9f24ec08b34f6ef0b55389d",
            "placeholder": "​",
            "style": "IPY_MODEL_3fe8ce8c5cd24809a26431b801e20bc4",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "5433e28631f24d1ab31ed3306f91dd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4fe071865ab45fe9bff0983818953af",
            "max": 4498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae4e2565dc104fd1a0ad56496233ad4e",
            "value": 4498
          }
        },
        "88ac8fb11c66447095c3682abfb8645e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e88df3b174d542b4a717e8189e6b4472",
            "placeholder": "​",
            "style": "IPY_MODEL_6effde9d9f1c43c8a3605930415e07cb",
            "value": " 4498/4498 [00:02&lt;00:00, 3194.28 examples/s]"
          }
        },
        "4fa2f4921f7b481bb285e5b807e97f4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd165494e9f24ec08b34f6ef0b55389d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe8ce8c5cd24809a26431b801e20bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4fe071865ab45fe9bff0983818953af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae4e2565dc104fd1a0ad56496233ad4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e88df3b174d542b4a717e8189e6b4472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6effde9d9f1c43c8a3605930415e07cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e140969d78744a9497ff0bae05b23123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d17aa2054e444660bd2ff184701c9393",
              "IPY_MODEL_c06c8ef9b72d45bab4c9b85381a08da3",
              "IPY_MODEL_a9331c29470c4880b8f488b68159a8aa"
            ],
            "layout": "IPY_MODEL_8bd71e2d9fa84a9391cf4dd8a5b67a33"
          }
        },
        "d17aa2054e444660bd2ff184701c9393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a00ef4cb68b94c799b5013c14324645c",
            "placeholder": "​",
            "style": "IPY_MODEL_7774aa79a2c84a53a85386f715548594",
            "value": "unsloth.Q4_K_M.gguf: 100%"
          }
        },
        "c06c8ef9b72d45bab4c9b85381a08da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_affbb29279c0492f8ad7457832efc7a3",
            "max": 4920734336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d02bc81adbb34488bc95ef343ba4985f",
            "value": 4920734336
          }
        },
        "a9331c29470c4880b8f488b68159a8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6413ab0825a4710918a6406a5f3c7a2",
            "placeholder": "​",
            "style": "IPY_MODEL_2a372d91d153475c896f91869b0701af",
            "value": " 4.92G/4.92G [01:38&lt;00:00, 45.9MB/s]"
          }
        },
        "8bd71e2d9fa84a9391cf4dd8a5b67a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00ef4cb68b94c799b5013c14324645c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7774aa79a2c84a53a85386f715548594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "affbb29279c0492f8ad7457832efc7a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d02bc81adbb34488bc95ef343ba4985f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6413ab0825a4710918a6406a5f3c7a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a372d91d153475c896f91869b0701af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5f7722ae1bf4d48bd5cfc9470e46267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8be6d91db134101816a0ed9fba24195",
              "IPY_MODEL_9138dd9a62fe416fb6a08c33bb80c13c",
              "IPY_MODEL_3fa02ee9760c422ca380506aae052e9e"
            ],
            "layout": "IPY_MODEL_3c678c001f304638aa4d8adeaf7037e9"
          }
        },
        "f8be6d91db134101816a0ed9fba24195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3abe6ca8ce8c4718be53a2e8fad1365d",
            "placeholder": "​",
            "style": "IPY_MODEL_2839055ea6f944f081089962e03872fe",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9138dd9a62fe416fb6a08c33bb80c13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8019ad34dd8499f8e235f1170121d5c",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca6a30aaf7c14c3da09d0d590d91f26d",
            "value": 4
          }
        },
        "3fa02ee9760c422ca380506aae052e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c49fc806f5c470bb8a7fe91bd48867a",
            "placeholder": "​",
            "style": "IPY_MODEL_4b24c6be19b44f24849a83ef256e84b0",
            "value": " 4/4 [00:07&lt;00:00,  1.60s/it]"
          }
        },
        "3c678c001f304638aa4d8adeaf7037e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3abe6ca8ce8c4718be53a2e8fad1365d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2839055ea6f944f081089962e03872fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8019ad34dd8499f8e235f1170121d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca6a30aaf7c14c3da09d0d590d91f26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c49fc806f5c470bb8a7fe91bd48867a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b24c6be19b44f24849a83ef256e84b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}